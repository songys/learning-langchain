{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG ê¸°ì´ˆ: ê²€ìƒ‰ + ë‹µë³€ ìƒì„±í•˜ê¸°\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ AIê°€ ë‹µë³€ì„ ìƒì„±**í•˜ëŠ” ì™„ì „í•œ RAG ì‹œìŠ¤í…œì„ ë§Œë“¤ì–´ë´…ë‹ˆë‹¤.\n",
    "\n",
    "## ì§€ë‚œ ì‹œê°„ ë³µìŠµ\n",
    "\n",
    "01-03ë²ˆ ë…¸íŠ¸ë¶ì—ì„œëŠ” **ë¬¸ì„œë¥¼ ê²€ìƒ‰**í•˜ëŠ” ë°©ë²•ì„ ë°°ì› ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ì œëŠ” **ê²€ìƒ‰ + ë‹µë³€**ê¹Œì§€ ì™„ì„±í•©ë‹ˆë‹¤!\n",
    "\n",
    "## RAGì˜ ë‘ ë‹¨ê³„\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     RAG = ê²€ìƒ‰ + ìƒì„±                              â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   â“ ì§ˆë¬¸                                                          â”‚\n",
    "â”‚      â”‚                                                            â”‚\n",
    "â”‚      â–¼                                                            â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                              â”‚\n",
    "â”‚   â”‚  1. ê²€ìƒ‰ ë‹¨ê³„    â”‚  \"ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì•„ë¼!\"              â”‚\n",
    "â”‚   â”‚   (Retrieval)   â”‚                                              â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚\n",
    "â”‚            â”‚                                                       â”‚\n",
    "â”‚            â–¼                                                       â”‚\n",
    "â”‚   ğŸ“„ ê´€ë ¨ ë¬¸ì„œë“¤                                                   â”‚\n",
    "â”‚            â”‚                                                       â”‚\n",
    "â”‚            â–¼                                                       â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                              â”‚\n",
    "â”‚   â”‚  2. ìƒì„± ë‹¨ê³„    â”‚  \"ì´ ë¬¸ì„œë¥¼ ì°¸ê³ í•´ì„œ ë‹µë³€í•´ë¼!\"              â”‚\n",
    "â”‚   â”‚  (Generation)   â”‚                                              â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚\n",
    "â”‚            â”‚                                                       â”‚\n",
    "â”‚            â–¼                                                       â”‚\n",
    "â”‚   ğŸ’¬ ìµœì¢… ë‹µë³€                                                     â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## ì™œ RAGê°€ í•„ìš”í• ê¹Œìš”?\n",
    "\n",
    "| AIë§Œ ì‚¬ìš© | RAG ì‚¬ìš© |\n",
    "|----------|----------|\n",
    "| í•™ìŠµ ë°ì´í„°ê¹Œì§€ë§Œ ì•Œê³  ìˆìŒ | ìµœì‹  ë¬¸ì„œë„ ì°¸ì¡° ê°€ëŠ¥ |\n",
    "| \"í™˜ê°(hallucination)\" ë°œìƒ | ê·¼ê±° ìˆëŠ” ë‹µë³€ |\n",
    "| ì¶œì²˜ í™•ì¸ ë¶ˆê°€ | ì¶œì²˜ ì œì‹œ ê°€ëŠ¥ |\n",
    "\n",
    "---\n",
    "\n",
    "# 1. Dockerë¡œ PGVector ì‹¤í–‰\n",
    "\n",
    "```bash\n",
    "docker run --name pgvector-container \\\n",
    "    -e POSTGRES_USER=langchain -e POSTGRES_PASSWORD=langchain \\\n",
    "    -e POSTGRES_DB=langchain -p 6024:5432 -d pgvector/pgvector:pg16\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° Ollama ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-community langchain-postgres langchain-ollama langchain-text-splitters psycopg psycopg-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "!apt-get install -y zstd\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "subprocess.Popen(['ollama', 'serve'])\n",
    "time.sleep(3)\n",
    "\n",
    "!ollama pull llama3.2\n",
    "!ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ì¤€ë¹„ ë° ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶•\n",
    "\n",
    "ì§€ë‚œ ì‹œê°„ì— ë°°ìš´ ë‚´ìš©ì„ í•œ ë²ˆì— ì‹¤í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„±\n",
    "sample_text = '''ê³ ëŒ€ ê·¸ë¦¬ìŠ¤ ì² í•™ì‚¬\n",
    "\n",
    "ì†Œí¬ë¼í…ŒìŠ¤(Socrates, BC 470-399)ëŠ” ì„œì–‘ ì² í•™ì˜ ì°½ì‹œìë¡œ ë¶ˆë¦½ë‹ˆë‹¤.\n",
    "\"ë„ˆ ìì‹ ì„ ì•Œë¼\"ëŠ” ê·¸ì˜ ìœ ëª…í•œ ê°€ë¥´ì¹¨ì…ë‹ˆë‹¤.\n",
    "ì†Œí¬ë¼í…ŒìŠ¤ëŠ” ëŒ€í™”ë¥¼ í†µí•´ ì§„ë¦¬ë¥¼ íƒêµ¬í•˜ëŠ” ë¬¸ë‹µë²•ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "í”Œë¼í†¤(Plato, BC 428-348)ì€ ì†Œí¬ë¼í…ŒìŠ¤ì˜ ì œìì˜€ìŠµë‹ˆë‹¤.\n",
    "ê·¸ëŠ” ì´ë°ì•„ë¡ ì„ ì£¼ì¥í–ˆëŠ”ë°, í˜„ì‹¤ ì„¸ê³„ëŠ” ì´ìƒì ì¸ í˜•íƒœ(ì´ë°ì•„)ì˜ ë¶ˆì™„ì „í•œ ë³µì‚¬ë³¸ì´ë¼ê³  í–ˆìŠµë‹ˆë‹¤.\n",
    "í”Œë¼í†¤ì€ ì•„ì¹´ë°ë¯¸ì•„ë¼ëŠ” í•™êµë¥¼ ì„¸ì› ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë¦¬ìŠ¤í† í…”ë ˆìŠ¤(Aristotle, BC 384-322)ëŠ” í”Œë¼í†¤ì˜ ì œìì˜€ìŠµë‹ˆë‹¤.\n",
    "ê·¸ëŠ” ë…¼ë¦¬í•™, ìƒë¬¼í•™, ìœ¤ë¦¬í•™ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ë¥¼ ì—°êµ¬í–ˆìŠµë‹ˆë‹¤.\n",
    "ì•„ë¦¬ìŠ¤í† í…”ë ˆìŠ¤ëŠ” ì•Œë ‰ì‚°ë” ëŒ€ì™•ì˜ ìŠ¤ìŠ¹ì´ê¸°ë„ í–ˆìŠµë‹ˆë‹¤.\n",
    "'''\n",
    "\n",
    "with open('./test.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(sample_text)\n",
    "\n",
    "print(\"test.txt ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "\n",
    "connection = 'postgresql+psycopg://langchain:langchain@localhost:6024/langchain'\n",
    "\n",
    "# ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• \n",
    "raw_documents = TextLoader('./test.txt', encoding='utf-8').load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ ë° ë²¡í„° ì €ì¥ì†Œ ìƒì„±\n",
    "embeddings_model = OllamaEmbeddings(model='nomic-embed-text')\n",
    "db = PGVector.from_documents(documents, embeddings_model, connection=connection)\n",
    "\n",
    "# Retriever ìƒì„±\n",
    "retriever = db.as_retriever(search_kwargs={'k': 2})\n",
    "\n",
    "print(f\"âœ… ë²¡í„° ì €ì¥ì†Œ ì¤€ë¹„ ì™„ë£Œ (ë¬¸ì„œ {len(documents)}ê°œ)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ë¨¼ì € ê²€ìƒ‰ë§Œ í•´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'ê³ ëŒ€ ê·¸ë¦¬ìŠ¤ ì² í•™ì‚¬ì˜ ì£¼ìš” ì¸ë¬¼ì€ ëˆ„êµ¬ì¸ê°€ìš”?'\n",
    "\n",
    "# ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\n",
    "docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"ì§ˆë¬¸: {query}\\n\")\n",
    "print(\"=== ê²€ìƒ‰ëœ ë¬¸ì„œ ===\")\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ê²€ìƒ‰ + ë‹µë³€ ìƒì„± (ê¸°ë³¸ ë°©ì‹)\n",
    "\n",
    "ì´ì œ ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ AIê°€ ë‹µë³€ì„ ìƒì„±í•˜ê²Œ í•´ë´…ì‹œë‹¤.\n",
    "\n",
    "## í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì´ë€?\n",
    "\n",
    "AIì—ê²Œ \"ì–´ë–»ê²Œ ë‹µë³€í•˜ë¼\"ê³  ì§€ì‹œí•˜ëŠ” í‹€ì…ë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿                        â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                        â”‚\n",
    "â”‚   \"ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•´ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.\"              â”‚\n",
    "â”‚                                                        â”‚\n",
    "â”‚   ì»¨í…ìŠ¤íŠ¸: {ê²€ìƒ‰ëœ ë¬¸ì„œë“¤}                             â”‚\n",
    "â”‚                                                        â”‚\n",
    "â”‚   ì§ˆë¬¸: {ì‚¬ìš©ì ì§ˆë¬¸}                                   â”‚\n",
    "â”‚                                                        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "ì´ë ‡ê²Œ í•˜ë©´ AIê°€ **ê²€ìƒ‰ëœ ë¬¸ì„œë§Œ ì°¸ê³ **í•´ì„œ ë‹µë³€í•©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    '''ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•´ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.\n",
    "ì»¨í…ìŠ¤íŠ¸:{context}\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "'''\n",
    ")\n",
    "\n",
    "# LLM ìƒì„±\n",
    "llm = ChatOllama(model='llama3.2', temperature=0)\n",
    "\n",
    "# ì²´ì¸ ìƒì„± (í”„ë¡¬í”„íŠ¸ â†’ LLM)\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "# ê²€ìƒ‰ëœ ë¬¸ì„œë¡œ ë‹µë³€ ìƒì„±\n",
    "result = llm_chain.invoke({'context': docs, 'question': query})\n",
    "\n",
    "print(\"=== RAG ë‹µë³€ ===\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. @chain ë°ì½”ë ˆì´í„°ë¡œ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•˜ê¸°\n",
    "\n",
    "## @chainì´ë€?\n",
    "\n",
    "**@chain**ì€ í•¨ìˆ˜ë¥¼ LangChainì˜ \"ì²´ì¸\"ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ëŠ” ë§ˆë²• ê°™ì€ ë„êµ¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    @chainì˜ ì—­í•                                â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                â”‚\n",
    "â”‚   ì¼ë°˜ í•¨ìˆ˜:                                                   â”‚\n",
    "â”‚   result = my_function(\"input\")   # ê·¸ëƒ¥ ì‹¤í–‰                 â”‚\n",
    "â”‚                                                                â”‚\n",
    "â”‚   @chain ì ìš© í•¨ìˆ˜:                                           â”‚\n",
    "â”‚   result = my_chain.invoke(\"input\")  # LangChain ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰ â”‚\n",
    "â”‚                                                                â”‚\n",
    "â”‚   ì¥ì :                                                        â”‚\n",
    "â”‚   - ë‹¤ë¥¸ ì²´ì¸ê³¼ ì—°ê²° ê°€ëŠ¥ (|ë¡œ íŒŒì´í”„ë¼ì¸)                      â”‚\n",
    "â”‚   - ìŠ¤íŠ¸ë¦¬ë°, ë¹„ë™ê¸° ë“± LangChain ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥               â”‚\n",
    "â”‚   - ì½”ë“œê°€ ê¹”ë”í•´ì§                                           â”‚\n",
    "â”‚                                                                â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "@chain\n",
    "def qa(input):\n",
    "    \"\"\"\n",
    "    RAG ì§ˆì˜ì‘ë‹µ ì²´ì¸\n",
    "    1. ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œ ê²€ìƒ‰\n",
    "    2. ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„±\n",
    "    \"\"\"\n",
    "    # 1ë‹¨ê³„: ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\n",
    "    docs = retriever.invoke(input)\n",
    "    \n",
    "    # 2ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ì— ë¬¸ì„œì™€ ì§ˆë¬¸ ì±„ìš°ê¸°\n",
    "    formatted = prompt.invoke({'context': docs, 'question': input})\n",
    "    \n",
    "    # 3ë‹¨ê³„: LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±\n",
    "    answer = llm.invoke(formatted)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "print(\"âœ… qa ì²´ì¸ ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa ì²´ì¸ ì‹¤í–‰\n",
    "result = qa.invoke(query)\n",
    "\n",
    "print(f\"ì§ˆë¬¸: {query}\\n\")\n",
    "print(\"=== RAG ë‹µë³€ (@chain ì‚¬ìš©) ===\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. ë‹¤ì–‘í•œ ì§ˆë¬¸ìœ¼ë¡œ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"í”Œë¼í†¤ì´ ì„¸ìš´ í•™êµì˜ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"ì•„ë¦¬ìŠ¤í† í…”ë ˆìŠ¤ëŠ” ëˆ„êµ¬ì˜ ì œìì˜€ë‚˜ìš”?\",\n",
    "    \"ì†Œí¬ë¼í…ŒìŠ¤ì˜ ìœ ëª…í•œ ê°€ë¥´ì¹¨ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ì§ˆë¬¸: {q}\")\n",
    "    print(\"=\"*60)\n",
    "    result = qa.invoke(q)\n",
    "    print(f\"\\në‹µë³€: {result.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì •ë¦¬: RAG ì§ˆì˜ì‘ë‹µ ì²´ì¸\n",
    "\n",
    "### ì „ì²´ ì½”ë“œ ìš”ì•½\n",
    "\n",
    "```python\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    '''ì»¨í…ìŠ¤íŠ¸: {context}\n",
    "    ì§ˆë¬¸: {question}'''\n",
    ")\n",
    "\n",
    "# RAG ì²´ì¸\n",
    "@chain\n",
    "def qa(input):\n",
    "    docs = retriever.invoke(input)     # 1. ê²€ìƒ‰\n",
    "    formatted = prompt.invoke(...)      # 2. í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "    answer = llm.invoke(formatted)      # 3. ë‹µë³€ ìƒì„±\n",
    "    return answer\n",
    "\n",
    "# ì‹¤í–‰\n",
    "result = qa.invoke(\"ì§ˆë¬¸\")\n",
    "```\n",
    "\n",
    "### í•µì‹¬ ê°œë…\n",
    "\n",
    "| ê°œë… | ì„¤ëª… |\n",
    "|------|------|\n",
    "| **Retriever** | ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì•„ì¤Œ |\n",
    "| **Prompt Template** | AIì—ê²Œ ì–´ë–»ê²Œ ë‹µë³€í• ì§€ ì§€ì‹œ |\n",
    "| **@chain** | í•¨ìˆ˜ë¥¼ LangChain ì²´ì¸ìœ¼ë¡œ ë³€í™˜ |\n",
    "| **RAG** | ê²€ìƒ‰(R) + ì¦ê°•(A) + ìƒì„±(G) |\n",
    "\n",
    "## ì½”ë“œ ë³€ê²½ì  (OpenAI â†’ Ollama)\n",
    "\n",
    "```python\n",
    "# ì›ë³¸ (OpenAI)\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "\n",
    "# ë³€ê²½ (Ollama)\n",
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model='llama3.2', temperature=0)\n",
    "```\n",
    "\n",
    "## ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ì´ëŠ” **ì¿¼ë¦¬ ì¬ì‘ì„±(Query Rewriting)** ê¸°ë²•ì„ ë°°ì›ë‹ˆë‹¤. (07-08ë²ˆ ë…¸íŠ¸ë¶)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
