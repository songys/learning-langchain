{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Fusion: 검색 결과 재순위화\n",
    "\n",
    "이 노트북에서는 **여러 검색 결과를 통합하고 재순위화**하는 **RAG Fusion** 기법을 배웁니다.\n",
    "\n",
    "## RAG Fusion이란?\n",
    "\n",
    "**RAG Fusion**은 Multi-Query의 발전된 형태입니다.\n",
    "\n",
    "### Multi-Query vs RAG Fusion\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────┐\n",
    "│                Multi-Query vs RAG Fusion                          │\n",
    "├────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                    │\n",
    "│   Multi-Query:                                                     │\n",
    "│   쿼리 1 → 결과들  ┐                                               │\n",
    "│   쿼리 2 → 결과들  ├──▶ 단순 합치기 (중복만 제거)                  │\n",
    "│   쿼리 3 → 결과들  ┘                                               │\n",
    "│                                                                    │\n",
    "│   RAG Fusion:                                                      │\n",
    "│   쿼리 1 → 결과들 (순위 포함) ┐                                    │\n",
    "│   쿼리 2 → 결과들 (순위 포함) ├──▶ RRF로 점수 계산 ──▶ 재순위화   │\n",
    "│   쿼리 3 → 결과들 (순위 포함) ┘                                    │\n",
    "│                                                                    │\n",
    "└────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "## RRF (Reciprocal Rank Fusion)란?\n",
    "\n",
    "**RRF**는 \"상호 순위 융합\"이라는 뜻입니다.\n",
    "\n",
    "### RRF의 핵심 아이디어\n",
    "\n",
    "> \"여러 검색에서 **상위에 자주 나오는 문서**가 더 관련성이 높다!\"\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────┐\n",
    "│                      RRF 점수 계산 예시                            │\n",
    "├────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                    │\n",
    "│   쿼리 1 검색 결과: [문서A(1위), 문서B(2위), 문서C(3위)]            │\n",
    "│   쿼리 2 검색 결과: [문서B(1위), 문서A(2위), 문서D(3위)]            │\n",
    "│   쿼리 3 검색 결과: [문서A(1위), 문서D(2위), 문서B(3위)]            │\n",
    "│                                                                    │\n",
    "│   RRF 점수 (k=60):                                                 │\n",
    "│   • 문서A: 1/(1+60) + 1/(2+60) + 1/(1+60) = 0.049                  │\n",
    "│   • 문서B: 1/(2+60) + 1/(1+60) + 1/(3+60) = 0.048                  │\n",
    "│   • 문서D: 0 + 1/(3+60) + 1/(2+60) = 0.032                         │\n",
    "│   • 문서C: 1/(3+60) + 0 + 0 = 0.016                                │\n",
    "│                                                                    │\n",
    "│   최종 순위: 문서A > 문서B > 문서D > 문서C                          │\n",
    "│                                                                    │\n",
    "└────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### RRF 공식\n",
    "\n",
    "```\n",
    "RRF 점수 = Σ (1 / (순위 + k))\n",
    "\n",
    "• k = 60 (일반적으로 사용되는 값)\n",
    "• 순위가 높을수록(숫자가 작을수록) 점수가 높음\n",
    "• 여러 검색에서 상위에 나오면 점수가 누적됨\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-community langchain-postgres langchain-ollama langchain-text-splitters psycopg psycopg-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "!apt-get install -y zstd\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "subprocess.Popen(['ollama', 'serve'])\n",
    "time.sleep(3)\n",
    "\n",
    "!ollama pull llama3.2\n",
    "!ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 벡터 저장소 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 문서 생성\n",
    "sample_text = '''고대 그리스 철학사\n",
    "\n",
    "소크라테스(Socrates, BC 470-399)는 서양 철학의 창시자로 불립니다.\n",
    "\"너 자신을 알라\"는 그의 유명한 가르침입니다.\n",
    "소크라테스는 대화를 통해 진리를 탐구하는 문답법을 사용했습니다.\n",
    "\n",
    "플라톤(Plato, BC 428-348)은 소크라테스의 제자였습니다.\n",
    "그는 이데아론을 주장했는데, 현실 세계는 이상적인 형태(이데아)의 불완전한 복사본이라고 했습니다.\n",
    "플라톤은 아카데미아라는 학교를 세웠습니다.\n",
    "\n",
    "아리스토텔레스(Aristotle, BC 384-322)는 플라톤의 제자였습니다.\n",
    "그는 논리학, 생물학, 윤리학 등 다양한 분야를 연구했습니다.\n",
    "아리스토텔레스는 알렉산더 대왕의 스승이기도 했습니다.\n",
    "'''\n",
    "\n",
    "with open('./test.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(sample_text)\n",
    "\n",
    "print(\"test.txt 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "connection = 'postgresql+psycopg://langchain:langchain@localhost:6024/langchain'\n",
    "\n",
    "# 문서 로드 및 분할\n",
    "raw_documents = TextLoader('./test.txt', encoding='utf-8').load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=30)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "\n",
    "# 벡터 저장소 생성\n",
    "embeddings_model = OllamaEmbeddings(model='nomic-embed-text')\n",
    "db = PGVector.from_documents(documents, embeddings_model, connection=connection)\n",
    "retriever = db.as_retriever(search_kwargs={'k': 5})\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model='llama3.2', temperature=0)\n",
    "\n",
    "print(f\"✅ 벡터 저장소 준비 완료 (문서 {len(documents)}개)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 다중 쿼리 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Fusion용 쿼리 생성 프롬프트\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(\n",
    "    '''\n",
    "하나의 입력 쿼리를 기반으로 여러 개의 검색 쿼리를 생성하는 유용한 어시스턴트입니다.\n",
    "다음과 관련된 여러 검색 쿼리를 영문으로 생성합니다: \n",
    "{question}\n",
    "\n",
    "출력(쿼리 4개):\n",
    "''')\n",
    "\n",
    "def parse_queries_output(message):\n",
    "    return message.content.split('\\n')\n",
    "\n",
    "# 쿼리 생성 체인\n",
    "query_gen = prompt_rag_fusion | llm | parse_queries_output\n",
    "\n",
    "print(\"✅ 쿼리 생성 체인 준비 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쿼리 생성 테스트\n",
    "query = '고대 그리스 철학사의 주요 인물은 누구인가요?'\n",
    "\n",
    "generated_queries = query_gen.invoke(query)\n",
    "\n",
    "print(f\"원본 질문: {query}\\n\")\n",
    "print(\"=== 생성된 검색 쿼리 ===\")\n",
    "for i, q in enumerate(generated_queries):\n",
    "    if q.strip():\n",
    "        print(f\"{i+1}. {q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. RRF (Reciprocal Rank Fusion) 구현\n",
    "\n",
    "여러 검색 결과의 순위를 종합하여 최종 순위를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\"\n",
    "    Reciprocal Rank Fusion (RRF) 알고리즘\n",
    "    \n",
    "    여러 검색 결과 목록을 받아서 RRF 점수를 계산하고\n",
    "    점수가 높은 순서대로 문서를 정렬하여 반환합니다.\n",
    "    \n",
    "    Parameters:\n",
    "    - results: 검색 결과 목록들 [[결과1], [결과2], ...]\n",
    "    - k: RRF 공식의 파라미터 (기본값 60)\n",
    "    \n",
    "    Returns:\n",
    "    - 재순위화된 문서 목록\n",
    "    \"\"\"\n",
    "    # 점수와 문서를 저장할 딕셔너리\n",
    "    fused_scores = {}  # {문서내용: 점수}\n",
    "    documents = {}     # {문서내용: 문서객체}\n",
    "    \n",
    "    # 각 검색 결과 순회\n",
    "    for docs in results:\n",
    "        # 각 문서와 순위(0부터 시작) 순회\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = doc.page_content\n",
    "            \n",
    "            # 처음 보는 문서면 초기화\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "                documents[doc_str] = doc\n",
    "            \n",
    "            # RRF 점수 누적: 1 / (순위 + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "    \n",
    "    # 점수 기준 내림차순 정렬\n",
    "    reranked_doc_strs = sorted(\n",
    "        fused_scores, \n",
    "        key=lambda d: fused_scores[d], \n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    # 정렬된 문서 객체 반환\n",
    "    return [documents[doc_str] for doc_str in reranked_doc_strs]\n",
    "\n",
    "print(\"✅ RRF 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. RAG Fusion 검색 체인 구축\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                  RAG Fusion 검색 체인 구조                          │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│   query_gen        retriever.batch       reciprocal_rank_fusion    │\n",
    "│   ──────────▶     ──────────────▶       ───────────────────▶       │\n",
    "│                                                                     │\n",
    "│   쿼리 4개 생성     4개 쿼리 동시 검색     RRF로 순위 재조정          │\n",
    "│                                                                     │\n",
    "│   [쿼리1]           [결과1: A,B,C]       점수 계산 후                │\n",
    "│   [쿼리2]    ──▶   [결과2: B,A,D]  ──▶  최종 순서 결정              │\n",
    "│   [쿼리3]           [결과3: A,D,B]       [A > B > D > C]            │\n",
    "│   [쿼리4]           [결과4: C,A,B]                                  │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Fusion 검색 체인\n",
    "retrieval_chain = query_gen | retriever.batch | reciprocal_rank_fusion\n",
    "\n",
    "print(\"✅ RAG Fusion 검색 체인 준비 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Fusion 검색 테스트\n",
    "result = retrieval_chain.invoke(query)\n",
    "\n",
    "print(f\"검색된 문서 수: {len(result)}개\\n\")\n",
    "print(\"=== 재순위화된 검색 결과 (RRF 점수 순) ===\")\n",
    "print(f\"\\n[1위 문서]\")\n",
    "print(result[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. RAG Fusion 완성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 답변 생성용 프롬프트\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    '''\n",
    "다음 컨텍스트만 사용해 질문에 답하세요.\n",
    "컨텍스트:{context}\n",
    "\n",
    "질문: {question}\n",
    "'''\n",
    ")\n",
    "\n",
    "@chain\n",
    "def rag_fusion(input):\n",
    "    \"\"\"\n",
    "    RAG Fusion 체인\n",
    "    \n",
    "    1. 입력 질문으로 여러 검색 쿼리 생성\n",
    "    2. 여러 쿼리로 동시 검색\n",
    "    3. RRF로 검색 결과 재순위화\n",
    "    4. 최상위 문서들로 답변 생성\n",
    "    \"\"\"\n",
    "    # RAG Fusion 검색\n",
    "    docs = retrieval_chain.invoke(input)\n",
    "    \n",
    "    # 답변 생성\n",
    "    formatted = prompt.invoke({'context': docs, 'question': input})\n",
    "    answer = llm.invoke(formatted)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "print(\"✅ RAG Fusion 체인 준비 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Fusion 실행\n",
    "print(\"=== RAG Fusion 실행 ===\")\n",
    "print(f\"질문: {query}\\n\")\n",
    "\n",
    "result = rag_fusion.invoke(query)\n",
    "\n",
    "print(\"=== 답변 ===\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 다양한 질문으로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"플라톤의 철학 사상은 무엇인가요?\",\n",
    "    \"소크라테스와 플라톤의 관계는?\",\n",
    "    \"아리스토텔레스는 무엇을 연구했나요?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"질문: {q}\")\n",
    "    print(\"=\"*60)\n",
    "    result = rag_fusion.invoke(q)\n",
    "    print(f\"\\n답변: {result.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 정리: RAG Fusion\n",
    "\n",
    "### Multi-Query vs RAG Fusion 비교\n",
    "\n",
    "| 항목 | Multi-Query | RAG Fusion |\n",
    "|------|-------------|------------|\n",
    "| 검색 방식 | 여러 쿼리로 검색 | 여러 쿼리로 검색 |\n",
    "| 결과 처리 | 단순 중복 제거 | RRF로 재순위화 |\n",
    "| 장점 | 구현 간단 | 더 관련성 높은 결과 |\n",
    "| 적용 사례 | 일반적인 검색 | 정확도가 중요한 검색 |\n",
    "\n",
    "### RRF 공식\n",
    "\n",
    "```\n",
    "RRF(d) = Σ 1/(rank_i + k)\n",
    "\n",
    "d: 문서\n",
    "rank_i: i번째 검색에서의 순위\n",
    "k: 상수 (보통 60)\n",
    "```\n",
    "\n",
    "### 핵심 코드\n",
    "\n",
    "```python\n",
    "def reciprocal_rank_fusion(results, k=60):\n",
    "    fused_scores = {}\n",
    "    for docs in results:\n",
    "        for rank, doc in enumerate(docs):\n",
    "            fused_scores[doc] += 1 / (rank + k)\n",
    "    return sorted(fused_scores, reverse=True)\n",
    "\n",
    "# RAG Fusion 검색 체인\n",
    "retrieval_chain = query_gen | retriever.batch | reciprocal_rank_fusion\n",
    "```\n",
    "\n",
    "## 코드 변경점 (OpenAI → Ollama)\n",
    "\n",
    "```python\n",
    "# 원본\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "\n",
    "# 변경\n",
    "llm = ChatOllama(model='llama3.2', temperature=0)\n",
    "```\n",
    "\n",
    "## 다음 단계\n",
    "\n",
    "**가상의 답변 문서를 먼저 생성**하여 검색하는 **HyDE (Hypothetical Document Embeddings)** 기법을 배웁니다. (15-17번 노트북)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
