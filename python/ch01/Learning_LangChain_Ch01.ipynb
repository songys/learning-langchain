{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1장."
      ],
      "metadata": {
        "id": "cVJcOx1Sq5Vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-openai langchain-community\n",
        "!pip install langchain-text-splitters langchain-postgres"
      ],
      "metadata": {
        "id": "CcLcoaLgSv2M",
        "collapsed": true,
        "outputId": "be49f1b2-e8fc-4856-fd36-6e9eb9486dac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.7-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.8 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.8)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.7)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.16.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.46)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.8)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.1.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (26.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.8->langchain) (0.14.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (3.6.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.8->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain) (1.12.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_openai-1.1.7-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-openai, langchain-classic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-classic-1.0.1 langchain-community-0.4.1 langchain-openai-1.1.7 langchain-text-splitters-1.1.0 marshmallow-3.26.2 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n",
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Collecting langchain-postgres\n",
            "  Downloading langchain_postgres-0.0.16-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-text-splitters) (1.2.8)\n",
            "Collecting asyncpg>=0.30.0 (from langchain-postgres)\n",
            "  Downloading asyncpg-0.31.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.21 in /usr/local/lib/python3.12/dist-packages (from langchain-postgres) (2.0.2)\n",
            "Collecting pgvector<0.4,>=0.2.5 (from langchain-postgres)\n",
            "  Downloading pgvector-0.3.6-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting psycopg-pool<4,>=3.2.1 (from langchain-postgres)\n",
            "  Downloading psycopg_pool-3.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting psycopg<4,>=3 (from psycopg[binary]<4,>=3->langchain-postgres)\n",
            "  Downloading psycopg-3.3.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: sqlalchemy<3,>=2 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]<3,>=2->langchain-postgres) (2.0.46)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.6.8)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (26.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.12.3)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.14.0)\n",
            "Collecting psycopg-binary==3.3.2 (from psycopg[binary]<4,>=3->langchain-postgres)\n",
            "  Downloading psycopg_binary-3.3.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=2->sqlalchemy[asyncio]<3,>=2->langchain-postgres) (3.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.32.5)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.5.0)\n",
            "Downloading langchain_postgres-0.0.16-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asyncpg-0.31.0-cp312-cp312-manylinux_2_28_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pgvector-0.3.6-py3-none-any.whl (24 kB)\n",
            "Downloading psycopg-3.3.2-py3-none-any.whl (212 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.8/212.8 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psycopg_pool-3.3.0-py3-none-any.whl (39 kB)\n",
            "Downloading psycopg_binary-3.3.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: psycopg-pool, psycopg-binary, psycopg, pgvector, asyncpg, langchain-postgres\n",
            "Successfully installed asyncpg-0.31.0 langchain-postgres-0.0.16 pgvector-0.3.6 psycopg-3.3.2 psycopg-binary-3.3.2 psycopg-pool-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY']=userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "_L4A9kSXTSYW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 1-1 기본 LLM 호출"
      ],
      "metadata": {
        "id": "z1u6_jg2cjV0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VDbEjFXBQCnW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "98b40ecb-d640-4186-cea5-a6ece9f9ead8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling\\n\\nThe sky is falling'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from langchain_openai.llms import OpenAI\n",
        "\n",
        "model = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
        "\n",
        "model.invoke(\"The sky is\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 1-2 채팅 모델 호출"
      ],
      "metadata": {
        "id": "FrPTvKY8co2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "model = ChatOpenAI()\n",
        "prompt = [HumanMessage(\"What is the capital of France?\")]\n",
        "\n",
        "model.invoke(prompt)\n"
      ],
      "metadata": {
        "id": "Io1SbBvPVajp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56b0b139-2c22-4ab8-862a-729aa8c47ce0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='The capital of France is Paris.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 14, 'total_tokens': 21, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-D6bmd9vtCUSPXVZ1Tu5Py4s32DLxG', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c3817-55a5-72d2-8f74-2ebf723f0a4e-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 14, 'output_tokens': 7, 'total_tokens': 21, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 1-3 시스템 메시지를 적용한 채팅 모델 호출"
      ],
      "metadata": {
        "id": "BRV5qu1_dWxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI()\n",
        "system_msg = SystemMessage(\n",
        "    '''You are a helpful assistant that responds to questions with three\n",
        "        exclamation marks.'''\n",
        ")\n",
        "human_msg = HumanMessage('What is the capital of France?')\n",
        "\n",
        "model.invoke([system_msg, human_msg])"
      ],
      "metadata": {
        "id": "ETXOBlEfVqfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5759603-2772-4fad-de3c-804f18191567"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Paris!!!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 35, 'total_tokens': 37, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-D6bmfAR5gIuBhq37tlbL7n7jlW8Mk', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c3817-59eb-7ba0-8047-fc574426f98f-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 35, 'output_tokens': 2, 'total_tokens': 37, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 1-4 프롬프트 템플릿 적용"
      ],
      "metadata": {
        "id": "7Ykh3iaxdXb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template = PromptTemplate.from_template(\"\"\"Answer the question based on the\n",
        "    context below. If the question cannot be answered using the information\n",
        "    provided, answer with \"I don't know\".\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer: \"\"\")\n",
        "\n",
        "template.invoke({\n",
        "    \"context\": \"\"\"The most recent advancements in NLP are being driven by Large\n",
        "        Language Models (LLMs). These models outperform their smaller\n",
        "        counterparts and have become invaluable for developers who are creating\n",
        "        applications with NLP capabilities. Developers can tap into these\n",
        "        models through Hugging Face's `transformers` library, or by utilizing\n",
        "        OpenAI and Cohere's offerings through the `openai` and `cohere`\n",
        "        libraries, respectively.\"\"\",\n",
        "    \"question\": \"Which model providers offer LLMs?\"\n",
        "})"
      ],
      "metadata": {
        "id": "bKYQhx1PV8LJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1923f044-db7a-48be-8bfa-0d048239aae1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringPromptValue(text='Answer the question based on the\\n    context below. If the question cannot be answered using the information\\n    provided, answer with \"I don\\'t know\".\\n\\nContext: The most recent advancements in NLP are being driven by Large\\n        Language Models (LLMs). These models outperform their smaller\\n        counterparts and have become invaluable for developers who are creating\\n        applications with NLP capabilities. Developers can tap into these\\n        models through Hugging Face\\'s `transformers` library, or by utilizing\\n        OpenAI and Cohere\\'s offerings through the `openai` and `cohere`\\n        libraries, respectively.\\n\\nQuestion: Which model providers offer LLMs?\\n\\nAnswer: ')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 1-5 동적 프롬프트"
      ],
      "metadata": {
        "id": "MlQxnEhbdaZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai.llms import OpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# both `template` and `model` can be reused many times\n",
        "\n",
        "template = PromptTemplate.from_template(\"\"\"Answer the question based on the\n",
        "    context below. If the question cannot be answered using the information\n",
        "    provided, answer with \"I don't know\".\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer: \"\"\")\n",
        "\n",
        "model = OpenAI()\n",
        "\n",
        "# `prompt` and `completion` are the results of using template and model once\n",
        "\n",
        "prompt = template.invoke({\n",
        "    \"context\": \"\"\"The most recent advancements in NLP are being driven by Large\n",
        "        Language Models (LLMs). These models outperform their smaller\n",
        "        counterparts and have become invaluable for developers who are creating\n",
        "        applications with NLP capabilities. Developers can tap into these\n",
        "        models through Hugging Face's `transformers` library, or by utilizing\n",
        "        OpenAI and Cohere's offerings through the `openai` and `cohere`\n",
        "        libraries, respectively.\"\"\",\n",
        "    \"question\": \"Which model providers offer LLMs?\"\n",
        "})\n",
        "\n",
        "completion = model.invoke(prompt)\n",
        "\n",
        "print(completion)"
      ],
      "metadata": {
        "id": "m-QSw_7qWBb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38204b29-1259-4a75-c99c-753be3c33e4f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hugging Face, OpenAI, and Cohere offer LLMs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 1-6 역할에 따른 동적 프롬프트"
      ],
      "metadata": {
        "id": "BrLuXZVvdbJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "template = ChatPromptTemplate.from_messages([\n",
        "    ('system', '''Answer the question based on the context below. If the\n",
        "        question cannot be answered using the information provided, answer with\n",
        "        \"I don\\'t know\".'''),\n",
        "    ('human', 'Context: {context}'),\n",
        "    ('human', 'Question: {question}'),\n",
        "])\n",
        "\n",
        "template.invoke({\n",
        "    \"context\": \"\"\"The most recent advancements in NLP are being driven by Large\n",
        "        Language Models (LLMs). These models outperform their smaller\n",
        "        counterparts and have become invaluable for developers who are creating\n",
        "        applications with NLP capabilities. Developers can tap into these\n",
        "        models through Hugging Face's `transformers` library, or by utilizing\n",
        "        OpenAI and Cohere's offerings through the `openai` and `cohere`\n",
        "        libraries, respectively.\"\"\",\n",
        "    \"question\": \"Which model providers offer LLMs?\"\n",
        "})"
      ],
      "metadata": {
        "id": "j61JdMlIYs5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85256943-c5b5-42cd-ca80-8b0a611ec954"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='Answer the question based on the context below. If the\\n        question cannot be answered using the information provided, answer with\\n        \"I don\\'t know\".', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Context: The most recent advancements in NLP are being driven by Large\\n        Language Models (LLMs). These models outperform their smaller\\n        counterparts and have become invaluable for developers who are creating\\n        applications with NLP capabilities. Developers can tap into these\\n        models through Hugging Face's `transformers` library, or by utilizing\\n        OpenAI and Cohere's offerings through the `openai` and `cohere`\\n        libraries, respectively.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Question: Which model providers offer LLMs?', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 1-7 두 개의 동적 프롬프트를 적용한 호출"
      ],
      "metadata": {
        "id": "DUA7YzesdfKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# both `template` and `model` can be reused many times\n",
        "\n",
        "template = ChatPromptTemplate.from_messages([\n",
        "    ('system', '''Answer the question based on the context below. If the\n",
        "        question cannot be answered using the information provided, answer\n",
        "        with \"I don\\'t know\".'''),\n",
        "    ('human', 'Context: {context}'),\n",
        "    ('human', 'Question: {question}'),\n",
        "])\n",
        "\n",
        "model = ChatOpenAI()\n",
        "\n",
        "# `prompt` and `completion` are the results of using template and model once\n",
        "\n",
        "prompt = template.invoke({\n",
        "    \"context\": \"\"\"The most recent advancements in NLP are being driven by\n",
        "        Large Language Models (LLMs). These models outperform their smaller\n",
        "        counterparts and have become invaluable for developers who are creating\n",
        "        applications with NLP capabilities. Developers can tap into these\n",
        "        models through Hugging Face's `transformers` library, or by utilizing\n",
        "        OpenAI and Cohere's offerings through the `openai` and `cohere`\n",
        "        libraries, respectively.\"\"\",\n",
        "    \"question\": \"Which model providers offer LLMs?\"\n",
        "})\n",
        "\n",
        "model.invoke(prompt)"
      ],
      "metadata": {
        "id": "R3Fw2NciYyBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "febae490-c361-44ed-c445-6dbd67e223fa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='OpenAI and Cohere offer Large Language Models (LLMs) through their libraries `openai` and `cohere`, respectively.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 152, 'total_tokens': 179, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-D6bmiyvFHjGN97in8gi2N8BLIIgUt', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c3817-6638-7770-afbc-2bc76a8e3ba2-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 152, 'output_tokens': 27, 'total_tokens': 179, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 1-8 JSON 형식 출력 요청"
      ],
      "metadata": {
        "id": "vIOy2ZlkdqZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class AnswerWithJustification(BaseModel):\n",
        "    '''An answer to the user's question along with justification for the\n",
        "        answer.'''\n",
        "    answer: str\n",
        "    '''The answer to the user's question'''\n",
        "    justification: str\n",
        "    '''Justification for the answer'''\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "structured_llm = llm.with_structured_output(AnswerWithJustification)\n",
        "\n",
        "result = structured_llm.invoke(\"\"\"What weighs more, a pound of bricks or a pound of feathers\"\"\")\n",
        "\n",
        "print(result.model_dump_json())\n"
      ],
      "metadata": {
        "id": "OauUyV58Y1J7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22eb73cc-a0f6-45a2-c807-dedad6fa4a7b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"answer\":\"A pound of bricks and a pound of feathers weigh the same.\",\"justification\":\"Both are measured as one pound, so regardless of the material, they have the same weight. The confusion often arises from the volume and density differences; bricks are much denser than feathers, so a pound of feathers will take up much more space than a pound of bricks.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 1-9 랭체인의 CSV 출력 파서"
      ],
      "metadata": {
        "id": "3vcDI_NWdtAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
        "parser = CommaSeparatedListOutputParser()\n",
        "items = parser.invoke(\"apple, banana, cherry\")\n",
        "print(items)"
      ],
      "metadata": {
        "id": "ILAFEr2baCNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f3bbf6c-e701-47d0-9840-e6a6bdc55f16"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['apple', 'banana', 'cherry']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 1-10 랭체인의 공통 인터페이스 예시"
      ],
      "metadata": {
        "id": "_bz9AGDYdwXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI()\n",
        "\n",
        "completion = model.invoke('Hi there!')\n",
        "print(completion)\n",
        "\n",
        "completions = model.batch(['Hi there!', 'Bye!'])\n",
        "print(completions)\n",
        "\n",
        "for token in model.stream('Bye!'):\n",
        "    print(token)"
      ],
      "metadata": {
        "id": "U5NphLpYoGv4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "159e7821-c275-452b-ee26-8b4b34751918"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='Hello! How can I assist you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 10, 'total_tokens': 19, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-D6bmk4tsqY8OJnFwhpD5KUxGtMqKf', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019c3817-6e5c-7140-8a1c-c0a4d1c100c3-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 10, 'output_tokens': 9, 'total_tokens': 19, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "[AIMessage(content='Hello! How can I help you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 10, 'total_tokens': 19, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-D6bml796X4bieRmL3bdomxDiRL1hH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c3817-71c1-7672-b242-3c25e9e5e287-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 10, 'output_tokens': 9, 'total_tokens': 19, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), AIMessage(content='Goodbye! Have a great day!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 10, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-D6bmlXbcQAjYijjyTtJwDqQshoEon', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c3817-71c6-71f3-b26f-87cec6a39dbb-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 10, 'output_tokens': 8, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7566-79d0-93f4-03aa6ad356ec' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='Good' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7566-79d0-93f4-03aa6ad356ec' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='bye' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7566-79d0-93f4-03aa6ad356ec' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='!' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7566-79d0-93f4-03aa6ad356ec' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Have' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7566-79d0-93f4-03aa6ad356ec' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' a' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7566-79d0-93f4-03aa6ad356ec' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' great' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7566-79d0-93f4-03aa6ad356ec' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' day' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7566-79d0-93f4-03aa6ad356ec' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='!' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7566-79d0-93f4-03aa6ad356ec' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125', 'service_tier': 'default', 'model_provider': 'openai'} id='lc_run--019c3817-7566-79d0-93f4-03aa6ad356ec' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='' additional_kwargs={} response_metadata={} id='lc_run--019c3817-7566-79d0-93f4-03aa6ad356ec' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 10, 'output_tokens': 8, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}} tool_call_chunks=[]\n",
            "content='' additional_kwargs={} response_metadata={} id='lc_run--019c3817-7566-79d0-93f4-03aa6ad356ec' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 1-11 명령형 구성 예시"
      ],
      "metadata": {
        "id": "Ds2Nv5fTd2rM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import chain\n",
        "\n",
        "# the building blocks\n",
        "\n",
        "template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant.\"),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# combine them in a function\n",
        "# dd @chain decorator adds the same Runnable interface for any function you write\n",
        "\n",
        "\n",
        "@chain\n",
        "def chatbot(values):\n",
        "    prompt = template.invoke(values)\n",
        "    return model.invoke(prompt)\n",
        "\n",
        "\n",
        "# use it\n",
        "\n",
        "response = chatbot.invoke({\"question\": \"Which model providers offer LLMs?\"})\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "avVIXRgfox2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8b69a01-df68-4abb-8bb2-1e9863f59ca5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Many law schools and universities around the world offer Master of Laws (LLM) programs. Some well-known and prestigious law school models that offer LLM programs include Harvard Law School, Yale Law School, Stanford Law School, Columbia Law School, NYU School of Law, University of Chicago Law School, and UC Berkeley School of Law. Additionally, there are many other law schools and institutions that offer LLM programs in various specializations and locations. It is advisable to research and consider factors such as program reputation, faculty expertise, specialization options, and location when choosing a program that best fits your academic and career goals.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 1-12 명령형 구성을 사용한 스트리밍 호출 예시"
      ],
      "metadata": {
        "id": "u-cN2kSShnzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@chain\n",
        "def chatbot(values):\n",
        "    prompt = template.invoke(values)\n",
        "    for token in model.stream(prompt):\n",
        "        yield token\n",
        "\n",
        "for part in chatbot.stream({\n",
        "    \"question\": \"Which model providers offer LLMs?\"\n",
        "}):\n",
        "    print(part)\n"
      ],
      "metadata": {
        "id": "ODYoQt4vpgT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f52c6d58-0af8-43f1-848c-d258bab57e95"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='Several' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' model' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' providers' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' offer' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' limited' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' liability' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' models' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' (' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='LL' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='Ms' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='),' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' including' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' but' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' not' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' limited' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' to' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=':\\n\\n' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='1' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Legal' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='Zoom' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='\\n' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='2' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Rocket' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Lawyer' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='\\n' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='3' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Inc' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='file' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='\\n' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='4' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Biz' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='Fil' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='ings' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='\\n' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='5' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Zen' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='Business' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='\\n\\n' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='You' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' can' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' explore' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' their' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' services' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' and' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' pricing' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' to' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' find' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' the' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' best' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' fit' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' for' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' your' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' needs' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125', 'service_tier': 'default', 'model_provider': 'openai'} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='' additional_kwargs={} response_metadata={} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 25, 'output_tokens': 59, 'total_tokens': 84, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}} tool_call_chunks=[]\n",
            "content='' additional_kwargs={} response_metadata={} id='lc_run--019c3817-7ae8-73b1-bd62-4b0212d55e79' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 1-13 명령형 구성을 사용한 비동기 실행"
      ],
      "metadata": {
        "id": "znAc8GK2iMmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@chain\n",
        "async def chatbot(values):\n",
        "    prompt = await template.ainvoke(values)\n",
        "    return await model.ainvoke(prompt)\n",
        "\n",
        "await chatbot.ainvoke({\"question\": \"Which model providers offer LLMs?\"})\n"
      ],
      "metadata": {
        "id": "z0txrqFspjO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b1a6014-6ae0-4b98-b886-e534d8b4ff5f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"There are many universities and law schools around the world that offer Master of Laws (LLM) programs. Some well-known institutions known for their LLM programs include:\\n\\n1. Harvard Law School\\n2. Yale Law School\\n3. Stanford Law School\\n4. Columbia Law School\\n5. University of Oxford\\n6. University of Cambridge\\n7. London School of Economics (LSE)\\n8. New York University (NYU) School of Law\\n9. University of California, Berkeley (UC Berkeley) School of Law\\n10. University of Chicago Law School\\n\\nThese are just a few examples, and there are many other universities and law schools that also offer LLM programs. It's a good idea to research and compare different programs to find the one that best fits your interests and career goals.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 162, 'prompt_tokens': 25, 'total_tokens': 187, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-D6bmo6qAHmS39SJxZZ4UgliyN4NNF', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c3817-7f8d-7f21-ac1b-083d783018bd-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 25, 'output_tokens': 162, 'total_tokens': 187, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 1-14 선언형 구성 예시"
      ],
      "metadata": {
        "id": "kLihci_uiQOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# the building blocks\n",
        "\n",
        "template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant.\"),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model = ChatOpenAI()\n",
        "\n",
        "# combine them with the | operator\n",
        "\n",
        "chatbot = template | model\n",
        "\n",
        "# use it\n",
        "\n",
        "response = chatbot.invoke({\"question\": \"Which model providers offer LLMs?\"})\n",
        "print(response.content)\n",
        "\n",
        "# streaming\n",
        "\n",
        "for part in chatbot.stream({\"question\": \"Which model providers offer LLMs?\"}):\n",
        "    print(part)"
      ],
      "metadata": {
        "id": "7j_O_j1xpth4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f1dc594-b49a-4db4-c20a-0fc980fbe31d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Several model providers offer the LLM (Lease Like Model) service, including Tesla, Rivian, and Volvo. These companies provide subscription-based services that offer a more flexible alternative to traditional car ownership or leasing. Customers pay a monthly fee for access to a vehicle for a set period, along with services like maintenance, insurance, and roadside assistance.\n",
            "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='There' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' are' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' various' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' model' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' providers' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' who' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' offer' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Legal' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Entity' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Ident' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='ifiers' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' (' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='LE' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='Is' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='),' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' not' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' L' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='LM' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='s' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' LE' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='Is' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' are' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' unique' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' identifiers' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' assigned' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' to' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' legal' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' entities' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' that' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' engage' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' in' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' financial' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' transactions' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Some' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' popular' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' LE' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='I' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' service' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' providers' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' include' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Bloomberg' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=',' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Ref' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='init' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='iv' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=',' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' and' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Rapid' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='LE' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='I' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' If' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' you' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' are' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' specifically' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' looking' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' for' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' L' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='LM' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='s' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' (' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='which' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' may' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' refer' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' to' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' something' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' else' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='),' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' please' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' provide' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' more' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' context' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' or' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' details' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' so' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' I' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' can' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' assist' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' you' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' better' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125', 'service_tier': 'default', 'model_provider': 'openai'} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='' additional_kwargs={} response_metadata={} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 25, 'output_tokens': 83, 'total_tokens': 108, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}} tool_call_chunks=[]\n",
            "content='' additional_kwargs={} response_metadata={} id='lc_run--019c3817-86fd-74f3-b42a-4d53de345032' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 1-15 선언형 구성을 사용한 스트리밍 호출 예시"
      ],
      "metadata": {
        "id": "_Rw1TlKCiheL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot = template | model\n",
        "\n",
        "for part in chatbot.stream({\n",
        "    \"question\": \"Which model providers offer LLMs?\"\n",
        "}):\n",
        "    print(part)\n",
        "    # > AIMessageChunk(content=\"Hugging\")\n",
        "    # > AIMessageChunk(content=\" Face's\")\n",
        "    # > AIMessageChunk(content=\" `transformers`\")\n",
        "    # ...\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FdfEjV_iie2",
        "outputId": "f2cd942e-627e-4f63-cfe2-c7bb8261960c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='Many' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' law' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' schools' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' and' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' universities' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' around' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' the' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' world' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' offer' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Master' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' of' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Laws' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' (' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='LL' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='M' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=')' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' programs' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Some' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' well' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='-known' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' law' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' schools' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' that' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' offer' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' L' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='LM' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' programs' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' include' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Harvard' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Law' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' School' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=',' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Yale' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Law' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' School' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=',' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Stanford' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Law' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' School' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=',' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Columbia' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Law' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' School' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=',' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' and' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' University' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' of' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' London' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' Additionally' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=',' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' there' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' are' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' numerous' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' other' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' law' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' schools' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' and' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' universities' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' that' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' offer' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' L' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='LM' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' programs' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' with' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' various' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' special' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='izations' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' and' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' concentrations' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' It' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' is' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' recommended' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' to' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' research' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' specific' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' law' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' schools' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' and' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' their' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' L' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='LM' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' offerings' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' to' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' find' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' the' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' best' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' program' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' that' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' align' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='s' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' with' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' your' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' interests' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' and' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' career' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content=' goals' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='.' additional_kwargs={} response_metadata={'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125', 'service_tier': 'default', 'model_provider': 'openai'} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[]\n",
            "content='' additional_kwargs={} response_metadata={} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 25, 'output_tokens': 100, 'total_tokens': 125, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}} tool_call_chunks=[]\n",
            "content='' additional_kwargs={} response_metadata={} id='lc_run--019c3817-89ef-7670-ad28-490d74d1cf98' tool_calls=[] invalid_tool_calls=[] tool_call_chunks=[] chunk_position='last'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "코드 1-16 선언형 구성을 사용한 비동기 실행"
      ],
      "metadata": {
        "id": "EX0YEGoEiyKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot = template | model\n",
        "\n",
        "await chatbot.ainvoke({\n",
        "    \"question\": \"Which model providers offer LLMs?\"\n",
        "})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYP3U5z9i5jW",
        "outputId": "319ba5b7-8566-4468-f717-f5617c51c17e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Many law schools offer Master of Laws (LLM) programs. Some popular law schools known for their LLM programs include:\\n\\n1. Harvard Law School\\n2. Yale Law School\\n3. Stanford Law School\\n4. Columbia Law School\\n5. New York University (NYU) School of Law\\n6. University of California, Berkeley School of Law (Berkeley Law)\\n7. University of Chicago Law School\\n8. University of Michigan Law School\\n9. University of Pennsylvania Carey Law School\\n10. Georgetown University Law Center\\n\\nThese are just a few examples, and there are many more law schools around the world that also offer LLM programs. It's best to research specific law schools that align with your interests and career goals to find the right fit for you.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 157, 'prompt_tokens': 25, 'total_tokens': 182, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-D6bmr9ZWgUM0zrTdkQNyTYHDI7xBf', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c3817-8dd0-7ed1-9522-410df15c4122-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 25, 'output_tokens': 157, 'total_tokens': 182, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}