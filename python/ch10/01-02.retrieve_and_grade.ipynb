{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 검색 및 관련성 평가 (Retrieve & Grade)\n",
    "\n",
    "이 노트북에서는 **RAG 시스템에서 검색 결과의 관련성을 평가**하는 방법을 배웁니다.\n",
    "\n",
    "## RAG 평가의 중요성\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────┐\n",
    "│                    RAG 평가가 필요한 이유                           │\n",
    "├────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                    │\n",
    "│   RAG 시스템:                                                      │\n",
    "│   질문 → 검색 → 문서들 → LLM → 답변                               │\n",
    "│                                                                    │\n",
    "│   문제:                                                            │\n",
    "│   검색된 문서가 질문과 관련 없으면?                                │\n",
    "│   → LLM이 잘못된 정보로 답변                                       │\n",
    "│   → 환각(Hallucination) 발생                                       │\n",
    "│                                                                    │\n",
    "│   해결:                                                            │\n",
    "│   검색 결과의 관련성을 LLM으로 평가!                               │\n",
    "│   → 관련 없는 문서 필터링                                          │\n",
    "│   → 필요시 재검색 또는 웹 검색                                     │\n",
    "│                                                                    │\n",
    "└────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "## 아키텍처\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────┐\n",
    "│                    검색 + 평가 흐름                                 │\n",
    "├────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                    │\n",
    "│   질문: \"2024년 LangGraph 에이전트 사례는?\"                        │\n",
    "│     │                                                              │\n",
    "│     ▼                                                              │\n",
    "│   ┌──────────────┐                                                 │\n",
    "│   │   Retriever  │  → 문서 4개 검색                                │\n",
    "│   └──────┬───────┘                                                 │\n",
    "│          │                                                         │\n",
    "│          ▼                                                         │\n",
    "│   ┌──────────────┐                                                 │\n",
    "│   │    Grader    │  → 각 문서 관련성 평가 (yes/no)                │\n",
    "│   │ (LLM 평가기) │                                                 │\n",
    "│   └──────┬───────┘                                                 │\n",
    "│          │                                                         │\n",
    "│   관련 문서만 선택                                                  │\n",
    "│          │                                                         │\n",
    "│          ▼                                                         │\n",
    "│   ┌──────────────┐                                                 │\n",
    "│   │   Generator  │  → 관련 문서로 답변 생성                        │\n",
    "│   └──────────────┘                                                 │\n",
    "│                                                                    │\n",
    "└────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-ollama langchain-community beautifulsoup4 tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "!apt-get install -y zstd\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "subprocess.Popen(['ollama', 'serve'])\n",
    "time.sleep(3)\n",
    "\n",
    "!ollama pull llama3.2\n",
    "!ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 문서 로드 및 인덱싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import InMemoryVectorStore\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# 블로그 게시물 URL\n",
    "urls = [\n",
    "    \"https://blog.langchain.dev/top-5-langgraph-agents-in-production-2024/\",\n",
    "    \"https://blog.langchain.dev/langchain-state-of-ai-2024/\",\n",
    "    \"https://blog.langchain.dev/introducing-ambient-agents/\",\n",
    "]\n",
    "\n",
    "# 문서 로드\n",
    "print(\"=== 문서 로드 중 ===\")\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "print(f\"로드된 문서: {len(docs_list)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, \n",
    "    chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "print(f\"분할된 청크: {len(doc_splits)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 스토어 생성\n",
    "embeddings = OllamaEmbeddings(model='nomic-embed-text')\n",
    "\n",
    "vectorstore = InMemoryVectorStore.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "print(\"✅ 벡터 스토어 및 Retriever 생성 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 검색 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 테스트\n",
    "question = \"2024년에 프로덕션 환경에서 사용된 LangGraph 에이전트 2개는 무엇인가요?\"\n",
    "\n",
    "results = retriever.invoke(question)\n",
    "\n",
    "print(f\"=== 검색 결과 ({len(results)}개) ===\")\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n[문서 {i+1}]\")\n",
    "    print(f\"내용: {doc.page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 관련성 평가 스키마 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"검색된 문서의 관련성 평가 결과\"\"\"\n",
    "    \n",
    "    binary_score: str = Field(\n",
    "        description=\"문서가 질문과 관련이 있으면 'yes', 없으면 'no'\"\n",
    "    )\n",
    "\n",
    "print(\"✅ GradeDocuments 스키마 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 관련성 평가기 (Grader) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# LLM 설정 (Structured Output)\n",
    "llm = ChatOllama(model='llama3.2', temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# 평가 프롬프트\n",
    "system = \"\"\"당신은 사용자 질문에 대한 검색된 문서의 관련성을 평가하는 채점자입니다.\n",
    "문서에 질문과 관련된 키워드나 의미가 포함되어 있다면 관련성이 있다고 평가하세요.\n",
    "문서가 질문과 관련이 있는지 여부를 나타내는 'yes' 또는 'no'로 평가해 주세요.\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"검색된 문서: \\n\\n {document} \\n\\n 사용자 질문: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 평가 체인\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "\n",
    "print(\"✅ 관련성 평가기 생성 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 검색 결과 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문서 평가\n",
    "print(\"=== 관련성 평가 ===\")\n",
    "print(f\"질문: {question}\\n\")\n",
    "\n",
    "relevant_docs = []\n",
    "\n",
    "for i, doc in enumerate(results):\n",
    "    result = retrieval_grader.invoke({\n",
    "        \"question\": question, \n",
    "        \"document\": doc.page_content\n",
    "    })\n",
    "    \n",
    "    status = \"✅ 관련\" if result.binary_score == 'yes' else \"❌ 무관\"\n",
    "    print(f\"[문서 {i+1}] {status}\")\n",
    "    print(f\"  내용: {doc.page_content[:100]}...\")\n",
    "    print()\n",
    "    \n",
    "    if result.binary_score == 'yes':\n",
    "        relevant_docs.append(doc)\n",
    "\n",
    "print(f\"\\n관련 문서: {len(relevant_docs)}개 / 전체: {len(results)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 관련 문서로 답변 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 답변 생성 프롬프트\n",
    "answer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 질문에 답변하는 어시스턴트입니다. 주어진 문서를 바탕으로 답변하세요.\"),\n",
    "    (\"human\", \"문서:\\n{context}\\n\\n질문: {question}\")\n",
    "])\n",
    "\n",
    "# 컨텍스트 생성\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "# 답변 생성\n",
    "answer_chain = answer_prompt | llm\n",
    "answer = answer_chain.invoke({\"context\": context, \"question\": question})\n",
    "\n",
    "print(\"=== 최종 답변 ===\")\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 정리: 검색 관련성 평가\n",
    "\n",
    "### 핵심 코드\n",
    "\n",
    "```python\n",
    "# 1. 평가 스키마\n",
    "class GradeDocuments(BaseModel):\n",
    "    binary_score: str = Field(description=\"'yes' 또는 'no'\")\n",
    "\n",
    "# 2. Structured Output LLM\n",
    "grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# 3. 평가 체인\n",
    "retrieval_grader = grade_prompt | grader\n",
    "\n",
    "# 4. 각 문서 평가\n",
    "for doc in docs:\n",
    "    result = retrieval_grader.invoke({\"question\": q, \"document\": doc})\n",
    "    if result.binary_score == 'yes':\n",
    "        relevant_docs.append(doc)\n",
    "```\n",
    "\n",
    "### 평가 활용\n",
    "\n",
    "| 평가 결과 | 다음 행동 |\n",
    "|----------|----------|\n",
    "| 관련 문서 있음 | 답변 생성 |\n",
    "| 관련 문서 없음 | 재검색 또는 웹 검색 |\n",
    "\n",
    "## 코드 변경점 (OpenAI → Ollama)\n",
    "\n",
    "```python\n",
    "# 원본\n",
    "embeddings = OpenAIEmbeddings()\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# 변경\n",
    "embeddings = OllamaEmbeddings(model='nomic-embed-text')\n",
    "llm = ChatOllama(model='llama3.2', temperature=0)\n",
    "```\n",
    "\n",
    "## 다음 단계\n",
    "\n",
    "**LangSmith**를 사용한 체계적인 평가 방법을 배웁니다. (03-06번 노트북)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
