{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown ë¬¸ì„œ ë¶„í• í•˜ê¸°\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **RecursiveCharacterTextSplitter.from_language()**ë¡œ Markdown ë¬¸ì„œë¥¼ êµ¬ì¡°ì— ë§ê²Œ ë¶„í• í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤.\n",
    "\n",
    "## Markdown ë¶„í•  íŠ¹ì§•\n",
    "\n",
    "Markdownì€ í—¤ë”(`#`, `##`) ê¸°ë°˜ êµ¬ì¡°ë¥¼ ê°€ì§€ë¯€ë¡œ, ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• í•˜ë©´ ì˜ë¯¸ ìˆëŠ” ì„¹ì…˜ ë‹¨ìœ„ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**Markdown êµ¬ë¶„ì ìˆœì„œ:**\n",
    "1. `\\n# ` (H1 í—¤ë”)\n",
    "2. `\\n## ` (H2 í—¤ë”)\n",
    "3. `\\n### ` (H3 í—¤ë”)\n",
    "4. `\\n#### ` (H4 í—¤ë”)\n",
    "5. `\\n- ` (ë¦¬ìŠ¤íŠ¸)\n",
    "6. ` ``` ` (ì½”ë“œ ë¸”ë¡)\n",
    "7. `\\n\\n`, `\\n`, ` `\n",
    "\n",
    "---\n",
    "\n",
    "# 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-text-splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Markdown ë¬¸ì„œ ë¶„í• \n",
    "\n",
    "**ì½”ë“œ ì„¤ëª…:**\n",
    "\n",
    "```python\n",
    "md_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.MARKDOWN,\n",
    "    chunk_size=60,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "# metadata ì¶”ê°€ ê°€ëŠ¥\n",
    "md_docs = md_splitter.create_documents(\n",
    "    [markdown_text],\n",
    "    [{'source': 'https://...'}]  # ê° ë¬¸ì„œì˜ ë©”íƒ€ë°ì´í„°\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import Language, RecursiveCharacterTextSplitter\n",
    "\n",
    "# ìƒ˜í”Œ Markdown í…ìŠ¤íŠ¸\n",
    "markdown_text = ''' \n",
    "# ğŸ¦œğŸ”— LangChain âš¡ Building applications with LLMs through composability âš¡ \n",
    "\n",
    "## Quick Install\n",
    "```bash\n",
    "pip install langchain\n",
    "```\n",
    "\n",
    "As an open source project in a rapidly developing field, we are extremely open\n",
    "    to contributions.\n",
    "'''\n",
    "\n",
    "print(\"=== ì›ë³¸ Markdown ===\")\n",
    "print(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markdown ì „ìš© Splitter ìƒì„±\n",
    "md_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.MARKDOWN,\n",
    "    chunk_size=60,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "# ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ë¬¸ì„œ ìƒì„±\n",
    "md_docs = md_splitter.create_documents(\n",
    "    [markdown_text],\n",
    "    [{'source': 'https://www.langchain.com'}]  # ì¶œì²˜ ë©”íƒ€ë°ì´í„°\n",
    ")\n",
    "\n",
    "print(f\"\\në¶„í• ëœ ì²­í¬ ìˆ˜: {len(md_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ë¶„í•  ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê° ì²­í¬ í™•ì¸\n",
    "for i, doc in enumerate(md_docs):\n",
    "    print(f\"\\n=== ì²­í¬ {i+1} ===\")\n",
    "    print(f\"metadata: {doc.metadata}\")\n",
    "    print(f\"content ({len(doc.page_content)}ì):\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. í—¤ë” ê¸°ë°˜ ë¶„í•  (MarkdownHeaderTextSplitter)\n",
    "\n",
    "í—¤ë”ë¥¼ ë©”íƒ€ë°ì´í„°ë¡œ ë³´ì¡´í•˜ë©´ì„œ ë¶„í• í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "# ë¶„í• í•  í—¤ë” ë ˆë²¨ ì •ì˜\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "md_header_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")\n",
    "\n",
    "# ë” êµ¬ì¡°í™”ëœ Markdown ì˜ˆì‹œ\n",
    "structured_md = '''# LangChain ì†Œê°œ\n",
    "\n",
    "LangChainì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "## ì„¤ì¹˜ ë°©ë²•\n",
    "\n",
    "pip install langchain ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ì£¼ìš” ê¸°ëŠ¥\n",
    "\n",
    "### ì²´ì¸ êµ¬ì„±\n",
    "\n",
    "LCELë¡œ ì²´ì¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "### RAG\n",
    "\n",
    "ê²€ìƒ‰ ì¦ê°• ìƒì„±ì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "'''\n",
    "\n",
    "header_splits = md_header_splitter.split_text(structured_md)\n",
    "\n",
    "print(\"=== í—¤ë” ê¸°ë°˜ ë¶„í•  ê²°ê³¼ ===\")\n",
    "for i, doc in enumerate(header_splits):\n",
    "    print(f\"\\n--- ì²­í¬ {i+1} ---\")\n",
    "    print(f\"metadata: {doc.metadata}\")\n",
    "    print(f\"content: {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ë‘ Splitter ë¹„êµ\n",
    "\n",
    "| Splitter | íŠ¹ì§• |\n",
    "|----------|------|\n",
    "| `RecursiveCharacterTextSplitter.from_language(MARKDOWN)` | chunk_size ê¸°ë°˜ ë¶„í•  |\n",
    "| `MarkdownHeaderTextSplitter` | í—¤ë” ê¸°ë°˜ ë¶„í• , í—¤ë”ë¥¼ ë©”íƒ€ë°ì´í„°ë¡œ ë³´ì¡´ |\n",
    "\n",
    "## ì¡°í•© ì‚¬ìš© (ê¶Œì¥)\n",
    "\n",
    "```python\n",
    "# 1. í—¤ë”ë¡œ ë¨¼ì € ë¶„í• \n",
    "header_splits = md_header_splitter.split_text(markdown)\n",
    "\n",
    "# 2. í° ì„¹ì…˜ì€ ì¶”ê°€ë¡œ ë¶„í• \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500)\n",
    "final_splits = text_splitter.split_documents(header_splits)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
