{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load â†’ Split â†’ Embed ì „ì²´ íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **ë¬¸ì„œ ë¡œë“œ â†’ ë¶„í•  â†’ ì„ë² ë”©**ê¹Œì§€ì˜ ì „ì²´ íë¦„ì„ ì—°ê²°í•˜ì—¬ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "## RAG ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  ğŸ“„ Load    â”‚ â”€â”€â–¶ â”‚  âœ‚ï¸ Split   â”‚ â”€â”€â–¶ â”‚  ğŸ”¢ Embed   â”‚ â”€â”€â–¶ â”‚  ğŸ’¾ Store   â”‚\n",
    "â”‚ TextLoader  â”‚     â”‚ TextSplitterâ”‚     â”‚  Embeddings â”‚     â”‚ VectorStore â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "    â†‘                    â†‘                    â†‘\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "              ì´ ë…¸íŠ¸ë¶ì—ì„œ ë‹¤ë£¨ëŠ” ë²”ìœ„\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 1. Ollama ì„¤ì¹˜ ë° ì„œë²„ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "!apt-get install -y zstd\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "subprocess.Popen(['ollama', 'serve'])\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull nomic-embed-text\n",
    "!pip install -q langchain langchain-community langchain-ollama langchain-text-splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = '''LangChainì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì£¼ìš” ê¸°ëŠ¥:\n",
    "1. í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ë° ìµœì í™”\n",
    "2. ì²´ì¸ êµ¬ì„±ì„ í†µí•œ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ìƒì„±\n",
    "3. ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ì˜ ì—°ë™\n",
    "4. ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ í†µí•œ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€\n",
    "\n",
    "LangChainì„ ì‚¬ìš©í•˜ë©´ RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì„ ì‰½ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. RAGëŠ” ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•˜ì—¬ LLMì˜ ì‘ë‹µì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
    "\n",
    "Vector StoreëŠ” ì„ë² ë”©ëœ ë¬¸ì„œë¥¼ ì €ì¥í•˜ê³  ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤. ëŒ€í‘œì ìœ¼ë¡œ Chroma, Pinecone, PGVector ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì„ë² ë”©ì€ í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì˜ë¯¸ê°€ ë¹„ìŠ·í•œ í…ìŠ¤íŠ¸ëŠ” ë²¡í„° ê³µê°„ì—ì„œ ê°€ê¹Œìš´ ìœ„ì¹˜ì— ìˆìŠµë‹ˆë‹¤.\n",
    "'''\n",
    "\n",
    "with open('./test.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(sample_text)\n",
    "\n",
    "print(f\"test.txt ìƒì„± ì™„ë£Œ ({len(sample_text)}ì)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "\n",
    "## Step 1: ë¬¸ì„œ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# ë¬¸ì„œ ë¡œë“œ\n",
    "loader = TextLoader('./test.txt', encoding='utf-8')\n",
    "doc = loader.load()\n",
    "\n",
    "print(f\"âœ… Step 1: ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ\")\n",
    "print(f\"   - ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(doc)}\")\n",
    "print(f\"   - ì›ë³¸ ê¸¸ì´: {len(doc[0].page_content)}ì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: ë¬¸ì„œ ë¶„í• "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# ë¬¸ì„œ ë¶„í• \n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "chunks = splitter.split_documents(doc)\n",
    "\n",
    "print(f\"\\nâœ… Step 2: ë¬¸ì„œ ë¶„í•  ì™„ë£Œ\")\n",
    "print(f\"   - ë¶„í• ëœ ì²­í¬ ìˆ˜: {len(chunks)}\")\n",
    "print(f\"   - ì²­í¬ í¬ê¸°: {[len(c.page_content) for c in chunks]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: ì„ë² ë”© ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ ìƒì„±\n",
    "embeddings_model = OllamaEmbeddings(model='nomic-embed-text')\n",
    "\n",
    "# ê° ì²­í¬ì˜ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©\n",
    "embeddings = embeddings_model.embed_documents(\n",
    "    [chunk.page_content for chunk in chunks]\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Step 3: ì„ë² ë”© ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"   - ì„ë² ë”© ìˆ˜: {len(embeddings)}\")\n",
    "print(f\"   - ë²¡í„° ì°¨ì›: {len(embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²­í¬ì™€ ì„ë² ë”© ë§¤í•‘ í™•ì¸\n",
    "print(\"=== ì²­í¬-ì„ë² ë”© ë§¤í•‘ ===\")\n",
    "for i, (chunk, emb) in enumerate(zip(chunks, embeddings)):\n",
    "    print(f\"\\n[ì²­í¬ {i+1}]\")\n",
    "    print(f\"  í…ìŠ¤íŠ¸: {chunk.page_content[:50]}...\")\n",
    "    print(f\"  ë²¡í„°: [{emb[0]:.4f}, {emb[1]:.4f}, ..., {emb[-1]:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì½”ë“œ ë³€ê²½ì  (OpenAI â†’ Ollama)\n",
    "\n",
    "```python\n",
    "# ì›ë³¸ (OpenAI)\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings_model = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "\n",
    "# ë³€ê²½ (Ollama)\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "embeddings_model = OllamaEmbeddings(model='nomic-embed-text')\n",
    "```\n",
    "\n",
    "## ì „ì²´ íŒŒì´í”„ë¼ì¸ ìš”ì•½\n",
    "\n",
    "```python\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# 1. Load\n",
    "docs = TextLoader('./file.txt').load()\n",
    "\n",
    "# 2. Split\n",
    "chunks = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ").split_documents(docs)\n",
    "\n",
    "# 3. Embed\n",
    "embeddings = OllamaEmbeddings(model='nomic-embed-text').embed_documents(\n",
    "    [c.page_content for c in chunks]\n",
    ")\n",
    "```\n",
    "\n",
    "## ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "ìƒì„±ëœ ì„ë² ë”©ì„ **Vector Store**ì— ì €ì¥í•˜ì—¬ ìœ ì‚¬ë„ ê²€ìƒ‰ ê°€ëŠ¥í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤. (09ë²ˆ ë…¸íŠ¸ë¶)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
