{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c86afdf31d14eabbd18d82e960875ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa7f744022db4cf08b0d21fac5fee7f5",
              "IPY_MODEL_780ab5593f124efe8b7519ccc80c9764",
              "IPY_MODEL_f1c41cd5249e4582b6d02ba80057913b"
            ],
            "layout": "IPY_MODEL_f0ad5b08787f41029ea2eec8b59e6ce4"
          }
        },
        "aa7f744022db4cf08b0d21fac5fee7f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb50060fe9014c2a8a7777345ff3d7d9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_81d45f5dab8042a39236b39e78b195f7",
            "value": "Loadingâ€‡weights:â€‡100%"
          }
        },
        "780ab5593f124efe8b7519ccc80c9764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8601a170577f4223b0a6463e894931a9",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6efa39216f364e3da7b3da047e371af3",
            "value": 200
          }
        },
        "f1c41cd5249e4582b6d02ba80057913b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_115c1b38426f476f8ca8927c66dbcf9d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_aaa851529fee496d900cae06f021abc9",
            "value": "â€‡200/200â€‡[00:00&lt;00:00,â€‡458.09it/s,â€‡Materializingâ€‡param=linear.weight]"
          }
        },
        "f0ad5b08787f41029ea2eec8b59e6ce4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb50060fe9014c2a8a7777345ff3d7d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81d45f5dab8042a39236b39e78b195f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8601a170577f4223b0a6463e894931a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6efa39216f364e3da7b3da047e371af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "115c1b38426f476f8ca8927c66dbcf9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaa851529fee496d900cae06f021abc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80327176e4bd4631971883a8660e291a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff5af81b7ba54e39baba1cefce8ca0ef",
              "IPY_MODEL_7e79a2f2632240d0ad888985516b35c6",
              "IPY_MODEL_b42b70ebea1e497b9334d2b5f5b1ea51"
            ],
            "layout": "IPY_MODEL_370515ffecdf4d95adf331485d7f1704"
          }
        },
        "ff5af81b7ba54e39baba1cefce8ca0ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8f3c06cb34c45f0a78c343daa67f858",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8b3da599406341d3a00aedce583329eb",
            "value": "Loadingâ€‡weights:â€‡100%"
          }
        },
        "7e79a2f2632240d0ad888985516b35c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0f598a84a9549eb89addc430bf9e656",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8048d34ffe15410f99b2bf9e5dd2d6a5",
            "value": 200
          }
        },
        "b42b70ebea1e497b9334d2b5f5b1ea51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ba9621dfdd04ffcb3a740ed855b1140",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_25b5a9e2a8e84e1fa0fe0e8cd05faac7",
            "value": "â€‡200/200â€‡[00:00&lt;00:00,â€‡443.38it/s,â€‡Materializingâ€‡param=linear.weight]"
          }
        },
        "370515ffecdf4d95adf331485d7f1704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8f3c06cb34c45f0a78c343daa67f858": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b3da599406341d3a00aedce583329eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0f598a84a9549eb89addc430bf9e656": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8048d34ffe15410f99b2bf9e5dd2d6a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ba9621dfdd04ffcb3a740ed855b1140": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25b5a9e2a8e84e1fa0fe0e8cd05faac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l926Sx_-X-yh"
      },
      "source": [
        "# 2ì¥. ë°ì´í„° ì¤€ë¹„ì™€ RAG\n",
        "\n",
        "2ì¥ì€ **RAG(ê²€ìƒ‰ ì¦ê°• ìƒì„±)** ì‹œìŠ¤í…œì„ ë§Œë“¤ê¸° ìœ„í•œ ë°ì´í„° ì¤€ë¹„ ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ë‹¤ë£¹ë‹ˆë‹¤.\n",
        "\n",
        "```\n",
        "ğŸ“„ Load(ë¡œë“œ) â†’ âœ‚ï¸ Split(ë¶„í• ) â†’ ğŸ”¢ Embed(ì„ë² ë”©) â†’ ğŸ’¾ Store(ì €ì¥) â†’ ğŸ” Search(ê²€ìƒ‰)\n",
        "```\n",
        "\n",
        "\n",
        "### 1ë‹¨ê³„: ë¬¸ì„œ ë¡œë“œ (ì½”ë“œ 2-1 ~ 2-3)\n",
        "\n",
        "**\"ë‹¤ì–‘í•œ í˜•ì‹ì˜ íŒŒì¼ì„ ì½ì–´ì˜¤ê¸°\"**\n",
        "\n",
        "| ì½”ë“œ | í•˜ëŠ” ì¼ | ë¹„ìœ  |\n",
        "|------|---------|------|\n",
        "| **2-1** TextLoader | `.txt` íŒŒì¼ ì½ê¸° | ë©”ëª¨ì¥ íŒŒì¼ ì—´ê¸° |\n",
        "| **2-2** WebBaseLoader | ì›¹í˜ì´ì§€ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° | ë¸Œë¼ìš°ì €ë¡œ í˜ì´ì§€ ë³µì‚¬í•˜ê¸° |\n",
        "| **2-3** PyPDFLoader | PDF íŒŒì¼ ì½ê¸° | PDF ë·°ì–´ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ |\n",
        "\n",
        "ì½ì–´ì˜¨ ê²°ê³¼ëŠ” ëª¨ë‘ **Document ê°ì²´** (ë‚´ìš© `page_content` + ë¶€ê°€ì •ë³´ `metadata`)ë¡œ í†µì¼ë©ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "### 2ë‹¨ê³„: ë¬¸ì„œ ë¶„í•  (ì½”ë“œ 2-4 ~ 2-6)\n",
        "\n",
        "**\"ê¸´ ë¬¸ì„œë¥¼ ì ë‹¹í•œ í¬ê¸°ë¡œ ìë¥´ê¸°\"**\n",
        "\n",
        "AIì—ê²Œ í•œë²ˆì— ì±… í•œ ê¶Œì„ ì£¼ë©´ ì²˜ë¦¬ê°€ ì–´ë µìŠµë‹ˆë‹¤. ì ë‹¹íˆ ì˜ë¼ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "| ì½”ë“œ | í•˜ëŠ” ì¼ | ë¹„ìœ  |\n",
        "|------|---------|------|\n",
        "| **2-4** RecursiveCharacterTextSplitter | ì¼ë°˜ í…ìŠ¤íŠ¸ë¥¼ ê¸€ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ë¶„í•  | ê¸´ í¸ì§€ë¥¼ ë‹¨ë½ë³„ë¡œ ìë¥´ê¸° |\n",
        "| **2-5** Languageë³„ ì½”ë“œ ë¶„í•  | Python, JS ë“± ì½”ë“œë¥¼ í•¨ìˆ˜/í´ë˜ìŠ¤ ë‹¨ìœ„ë¡œ ë¶„í•  | ì½”ë“œë¥¼ í•¨ìˆ˜ë³„ë¡œ ë¶„ë¦¬ |\n",
        "| **2-6** Markdown ë¶„í•  | Markdownì„ í—¤ë”(#, ##) ê¸°ì¤€ìœ¼ë¡œ ë¶„í•  | ì±…ì„ ì±•í„°ë³„ë¡œ ë‚˜ëˆ„ê¸° |\n",
        "\n",
        "í•µì‹¬ ì„¤ì •: `chunk_size`(í•œ ì¡°ê°ì˜ ìµœëŒ€ ê¸€ì ìˆ˜), `chunk_overlap`(ì¡°ê° ê°„ ê²¹ì¹˜ëŠ” ë¶€ë¶„, ë¬¸ë§¥ ìœ ì§€ìš©)\n",
        "\n",
        "\n",
        "### 3ë‹¨ê³„: ì„ë² ë”© (ì½”ë“œ 2-7 ~ 2-8)\n",
        "\n",
        "**\"í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜í•˜ê¸°\"**\n",
        "\n",
        "ì»´í“¨í„°ëŠ” ê¸€ìë¥¼ ì´í•´í•˜ì§€ ëª»í•©ë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¥¼ **ìˆ«ì ë°°ì—´(ë²¡í„°)**ë¡œ ë°”ê¿”ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "```\n",
        "\"Hello World!\" â†’ [0.12, -0.34, 0.56, ...]  # 768ê°œì˜ ìˆ«ì\n",
        "```\n",
        "\n",
        "**ì˜ë¯¸ê°€ ë¹„ìŠ·í•œ ë¬¸ì¥ â†’ ë²¡í„°ë„ ê°€ê¹Œì›€** (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ ì¸¡ì •). ì½”ë“œ 2-8ì€ Load â†’ Split â†’ Embedë¥¼ í•œë²ˆì— ì—°ê²°í•˜ëŠ” íŒŒì´í”„ë¼ì¸ ì˜ˆì œì…ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "### 4ë‹¨ê³„: ë²¡í„° ì €ì¥ì†Œ (ì½”ë“œ 2-9 ~ 2-12)\n",
        "\n",
        "**\"ì„ë² ë”©ëœ ë²¡í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ê¸°\"**\n",
        "\n",
        "**PGVector**(PostgreSQL + ë²¡í„° ê²€ìƒ‰ í™•ì¥)ì— ë¬¸ì„œë¥¼ ì €ì¥í•˜ê³ , ì§ˆë¬¸í•˜ë©´ ê°€ì¥ ê´€ë ¨ ìˆëŠ” ë¬¸ì„œë¥¼ ì°¾ì•„ì¤ë‹ˆë‹¤.\n",
        "ë¹„ìœ : ë„ì„œê´€ì— ì±…ì„ ë¶„ë¥˜í•´ì„œ ë„£ê³ , ì§ˆë¬¸í•˜ë©´ ê´€ë ¨ ì±…ì„ ì°¾ì•„ì£¼ëŠ” ì‚¬ì„œ ì—­í• \n",
        "\n",
        "\n",
        "### 5ë‹¨ê³„: ë¬¸ì„œ ì¸ë±ì‹± ê´€ë¦¬ (ì½”ë“œ 2-13)\n",
        "\n",
        "**\"ì¤‘ë³µ ì €ì¥ ë°©ì§€ + ìë™ ì—…ë°ì´íŠ¸\"**\n",
        "\n",
        "`SQLRecordManager`ëŠ” ë¬¸ì„œì˜ í•´ì‹œê°’ì„ ê¸°ë¡í•´ì„œ ê°™ì€ ë¬¸ì„œëŠ” ë¬´ì‹œí•˜ê³ , ìˆ˜ì •ëœ ë¬¸ì„œëŠ” ìë™ìœ¼ë¡œ ì´ì „ ë²„ì „ì„ ì‚­ì œí•˜ê³  ìƒˆ ë²„ì „ì„ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "### 6ë‹¨ê³„: ìš”ì•½ ê¸°ë°˜ ê²€ìƒ‰ (ì½”ë“œ 2-14)\n",
        "\n",
        "**\"ìš”ì•½ìœ¼ë¡œ ê²€ìƒ‰í•˜ê³ , ì›ë³¸ ë¬¸ì„œë¥¼ ë°˜í™˜í•˜ê¸°\"**\n",
        "\n",
        "`MultiVectorRetriever`: ê° ë¬¸ì„œì˜ ìš”ì•½ì„ AIë¡œ ìƒì„± â†’ ê²€ìƒ‰ì€ ìš”ì•½ì—ì„œ â†’ ê²°ê³¼ëŠ” ì›ë³¸ ì „ì²´ ë¬¸ì„œë¥¼ ë°˜í™˜.\n",
        "ë¹„ìœ : ì±…ì˜ ëª©ì°¨(ìš”ì•½)ë¡œ ì°¾ê³ , í•´ë‹¹ ì±•í„° ì „ë¬¸(ì›ë³¸)ì„ ì½ëŠ” ê²ƒ\n",
        "\n",
        "\n",
        "### 7ë‹¨ê³„: ColBERT ê³ ê¸‰ ê²€ìƒ‰ (ì½”ë“œ 2-15)\n",
        "\n",
        "**\"í† í° ë‹¨ìœ„ì˜ ì •ë°€í•œ ê²€ìƒ‰\"**\n",
        "\n",
        "`RAGatouille` + `ColBERT`: ì¼ë°˜ ì„ë² ë”©ì€ ë¬¸ì¥ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ë³€í™˜í•˜ì§€ë§Œ, ColBERTëŠ” ê° ë‹¨ì–´(í† í°)ë§ˆë‹¤ ë³„ë„ ë²¡í„°ë¥¼ ìƒì„±í•˜ì—¬ ë” ì •ë°€í•œ ë§¤ì¹­ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "id": "w7zQI3ol4-xu",
        "outputId": "7bc7d7b6-b2fb-4302-84b4-dccb4449fa6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: Tried to clean up context but failed!\n"
          ]
        }
      ],
      "source": [
        "# [ìˆ˜ì •] Colab í•„ìˆ˜ íŒ¨í‚¤ì§€ ì¼ê´„ ì„¤ì¹˜ (ë²„ì „ ê³ ì •)\n",
        "!pip install -q \\\n",
        "    langchain==0.3.25 \\\n",
        "    langchain-community==0.3.25 \\\n",
        "    langchain-core==0.3.83 \\\n",
        "    langchain-text-splitters==0.3.11 \\\n",
        "    langchain-postgres==0.0.16 \\\n",
        "    langchain-ollama \\\n",
        "    pypdf \\\n",
        "    beautifulsoup4 \\\n",
        "    numpy \\\n",
        "    requests\n",
        "\n",
        "# [ì¶”ê°€] WARNING ì–µì œ\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "os.environ['USER_AGENT'] = 'LangChain-Learning-Notebook'\n",
        "\n",
        "import logging\n",
        "logging.getLogger('langchain').setLevel(logging.ERROR)\n",
        "logging.getLogger('langchain_community').setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIS5qPb94-xv"
      },
      "source": [
        "## ì½”ë“œ 2-1 TextLoaderë¡œ í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œí•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIM5YgFv4-xv"
      },
      "source": [
        "# TextLoaderë¡œ í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œí•˜ê¸°\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **TextLoader**ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œì»¬ í…ìŠ¤íŠ¸ íŒŒì¼ì„ LangChain Documentë¡œ ë¡œë“œí•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤.\n",
        "\n",
        "## RAG íŒŒì´í”„ë¼ì¸ì—ì„œì˜ ìœ„ì¹˜\n",
        "\n",
        "```\n",
        "\n",
        "  ğŸ“„ Load     â”€â”€â–¶   âœ‚ï¸ Split    â”€â”€â–¶   ğŸ”¢ Embed    â”€â”€â–¶   ğŸ’¾ Store   \n",
        "  (ë¡œë“œ)            (ë¶„í• )            (ì„ë² ë”©)           (ì €ì¥)     \n",
        "\n",
        "      â†‘\n",
        "   í˜„ì¬ ë‹¨ê³„\n",
        "```\n",
        "\n",
        "## Document Loaderë€?\n",
        "\n",
        "Document LoaderëŠ” ë‹¤ì–‘í•œ ì†ŒìŠ¤(íŒŒì¼, ì›¹, DB ë“±)ì—ì„œ ë°ì´í„°ë¥¼ ì½ì–´ **LangChain Document ê°ì²´**ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "```python\n",
        "Document(\n",
        "    page_content='í…ìŠ¤íŠ¸ ë‚´ìš©...',  # ì‹¤ì œ í…ìŠ¤íŠ¸\n",
        "    metadata={'source': 'test.txt'}  # ë©”íƒ€ë°ì´í„°\n",
        ")\n",
        "```\n",
        "\n",
        "## ì£¼ìš” Document Loader ì¢…ë¥˜\n",
        "\n",
        "| Loader | ìš©ë„ |\n",
        "|--------|------|\n",
        "| `TextLoader` | í…ìŠ¤íŠ¸ íŒŒì¼ (.txt) |\n",
        "| `PyPDFLoader` | PDF íŒŒì¼ |\n",
        "| `WebBaseLoader` | ì›¹ í˜ì´ì§€ |\n",
        "| `CSVLoader` | CSV íŒŒì¼ |\n",
        "| `JSONLoader` | JSON íŒŒì¼ |\n",
        "\n",
        "\n",
        "# 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiUhqlCv4-xv"
      },
      "source": [
        "# 2. í…ŒìŠ¤íŠ¸ìš© í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±\n",
        "\n",
        "ì˜ˆì œë¥¼ ìœ„í•œ ìƒ˜í”Œ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iIc3nDw4-xv",
        "outputId": "0c6b4437-44c4-4fc6-ccda-1b01dd61e6a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test.txt íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "# í…ŒìŠ¤íŠ¸ìš© í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±\n",
        "sample_text = '''LangChainì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì£¼ìš” ê¸°ëŠ¥:\n",
        "1. í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ë° ìµœì í™”\n",
        "2. ì²´ì¸ êµ¬ì„±ì„ í†µí•œ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ìƒì„±\n",
        "3. ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ì˜ ì—°ë™\n",
        "4. ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ í†µí•œ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€\n",
        "\n",
        "LangChainì„ ì‚¬ìš©í•˜ë©´ RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì„ ì‰½ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "'''\n",
        "\n",
        "with open('./test.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(sample_text)\n",
        "\n",
        "print(\"test.txt íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TICsMQwH4-xv"
      },
      "source": [
        "# 3. TextLoaderë¡œ íŒŒì¼ ë¡œë“œ\n",
        "\n",
        "**ì½”ë“œ ì„¤ëª…:**\n",
        "\n",
        "```python\n",
        "loader = TextLoader('./test.txt', encoding='utf-8')\n",
        "docs = loader.load()\n",
        "```\n",
        "\n",
        "- `TextLoader(íŒŒì¼ê²½ë¡œ, encoding)` - ë¡œë” ìƒì„±\n",
        "- `loader.load()` - íŒŒì¼ì„ ì½ì–´ Document ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\n",
        "- `encoding='utf-8'` - í•œê¸€ íŒŒì¼ì˜ ê²½ìš° ì¸ì½”ë”© ì§€ì • í•„ìˆ˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pFA44QT4-xv",
        "outputId": "4f25d08f-f36e-4e2a-c28e-40707254e490"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: 1\n",
            "íƒ€ì…: Document\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "# TextLoaderë¡œ íŒŒì¼ ë¡œë“œ\n",
        "loader = TextLoader('./test.txt', encoding='utf-8')\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(docs)}\")\n",
        "print(f\"íƒ€ì…: {type(docs[0]).__name__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3Yi6CEQ4-xv"
      },
      "source": [
        "# 4. Document ê°ì²´ í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS1r6Pdf4-xw",
        "outputId": "bdf3dfc9-e0c2-4ae8-d6cd-b0d431054f4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== page_content ===\n",
            "LangChainì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
            "\n",
            "ì£¼ìš” ê¸°ëŠ¥:\n",
            "1. í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ë° ìµœì í™”\n",
            "2. ì²´ì¸ êµ¬ì„±ì„ í†µí•œ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ìƒì„±\n",
            "3. ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ì˜ ì—°ë™\n",
            "4. ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ í†µí•œ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€\n",
            "\n",
            "LangChainì„ ì‚¬ìš©í•˜ë©´ RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì„ ì‰½ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "\n",
            "=== metadata ===\n",
            "{'source': './test.txt'}\n"
          ]
        }
      ],
      "source": [
        "# Document ë‚´ìš© í™•ì¸\n",
        "doc = docs[0]\n",
        "\n",
        "print(\"=== page_content ===\")\n",
        "print(doc.page_content)\n",
        "\n",
        "print(\"\\n=== metadata ===\")\n",
        "print(doc.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-1KoMfq4-xw"
      },
      "source": [
        "## Document ê°ì²´ êµ¬ì¡°\n",
        "\n",
        "| ì†ì„± | ì„¤ëª… |\n",
        "|------|------|\n",
        "| `page_content` | ì‹¤ì œ í…ìŠ¤íŠ¸ ë‚´ìš© |\n",
        "| `metadata` | ì¶œì²˜, í˜ì´ì§€ ë²ˆí˜¸ ë“± ë¶€ê°€ ì •ë³´ |\n",
        "\n",
        "## ì—¬ëŸ¬ íŒŒì¼ ë¡œë“œí•˜ê¸°\n",
        "\n",
        "```python\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "\n",
        "# ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  txt íŒŒì¼ ë¡œë“œ\n",
        "loader = DirectoryLoader('./data/', glob='**/*.txt', loader_cls=TextLoader)\n",
        "docs = loader.load()\n",
        "```\n",
        "\n",
        "## ë‹¤ìŒ ë‹¨ê³„\n",
        "\n",
        "ë¡œë“œí•œ ë¬¸ì„œëŠ” ë³´í†µ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤:\n",
        "\n",
        "1. **Text Splitter**ë¡œ ì²­í¬ ë¶„í•  (04ë²ˆ ë…¸íŠ¸ë¶)\n",
        "2. **Embeddings**ë¡œ ë²¡í„° ë³€í™˜ (07ë²ˆ ë…¸íŠ¸ë¶)\n",
        "3. **Vector Store**ì— ì €ì¥ (09ë²ˆ ë…¸íŠ¸ë¶)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri6muJvs4-xw"
      },
      "source": [
        "## ì½”ë“œ 2-2 WebBaseLoaderë¡œ ì›¹ í˜ì´ì§€ ë¡œë“œí•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xio784Q4-xw"
      },
      "source": [
        "# WebBaseLoaderë¡œ ì›¹ í˜ì´ì§€ ë¡œë“œí•˜ê¸°\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **WebBaseLoader**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ í˜ì´ì§€ì˜ ë‚´ìš©ì„ LangChain Documentë¡œ ë¡œë“œí•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤.\n",
        "\n",
        "## WebBaseLoaderë€?\n",
        "\n",
        "ì›¹ URLì—ì„œ HTMLì„ ê°€ì ¸ì™€ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” Document Loaderì…ë‹ˆë‹¤.\n",
        "\n",
        "```python\n",
        "loader = WebBaseLoader('https://example.com')\n",
        "docs = loader.load()  # ì›¹ í˜ì´ì§€ â†’ Document\n",
        "```\n",
        "\n",
        "## íŠ¹ì§•\n",
        "\n",
        "- **BeautifulSoup** ê¸°ë°˜ HTML íŒŒì‹±\n",
        "- JavaScript ë Œë”ë§ì´ í•„ìš” ì—†ëŠ” ì •ì  í˜ì´ì§€ì— ì í•©\n",
        "- ì—¬ëŸ¬ URLì„ í•œ ë²ˆì— ë¡œë“œ ê°€ëŠ¥\n",
        "\n",
        "## ë‹¤ë¥¸ ì›¹ ë¡œë”ë“¤\n",
        "\n",
        "| Loader | íŠ¹ì§• |\n",
        "|--------|------|\n",
        "| `WebBaseLoader` | ê¸°ë³¸ HTML íŒŒì‹± |\n",
        "| `SeleniumURLLoader` | JavaScript ë Œë”ë§ ì§€ì› |\n",
        "| `PlaywrightURLLoader` | ë¸Œë¼ìš°ì € ìë™í™” |\n",
        "| `UnstructuredURLLoader` | êµ¬ì¡°í™”ëœ ì¶”ì¶œ |\n",
        "\n",
        "\n",
        "# 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itwxUrfP4-xw"
      },
      "source": [
        "# 2. WebBaseLoaderë¡œ ì›¹ í˜ì´ì§€ ë¡œë“œ\n",
        "\n",
        "**ì½”ë“œ ì„¤ëª…:**\n",
        "\n",
        "```python\n",
        "loader = WebBaseLoader('https://www.langchain.com/')\n",
        "docs = loader.load()\n",
        "```\n",
        "\n",
        "- URLì„ ì§€ì •í•˜ì—¬ ë¡œë” ìƒì„±\n",
        "- `load()` í˜¸ì¶œ ì‹œ ì›¹ í˜ì´ì§€ë¥¼ ê°€ì ¸ì™€ í…ìŠ¤íŠ¸ ì¶”ì¶œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC09u1G74-xw",
        "outputId": "78a5a9b6-3d06-4fcf-a497-f7186786fc5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: 1\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "# ì›¹ í˜ì´ì§€ ë¡œë“œ\n",
        "loader = WebBaseLoader('https://www.langchain.com/')\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(docs)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgCu1abH4-xw"
      },
      "source": [
        "# 3. Document ë‚´ìš© í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb2Q8Yaz4-xw",
        "outputId": "f99e9ef2-a82a-41ea-e0de-d7c873e1c002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== metadata ===\n",
            "{'source': 'https://www.langchain.com/', 'title': 'LangChain: Observe, Evaluate, and Deploy Reliable AI Agents', 'description': 'LangChain provides the engineering platform and open source frameworks developers use to build, test, and deploy reliable AI agents.', 'language': 'en'}\n",
            "\n",
            "=== page_content (ì²˜ìŒ 500ì) ===\n",
            "LangChain: Observe, Evaluate, and Deploy Reliable AI Agents\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Products\n",
            "\n",
            "LangSmithObservabilityDebug and monitor in-depth tracesEvaluationIterate on prompts and modelsDeploymentShip and scale agents in productionAgent BuilderNewBuild no-code agentsOpen Source FrameworksLangChainQuick start agents with any model providerLangGraphBuild custom agents with low-level controlDeep AgentsNewUse planning, memory, and sub-agents for complex, long-running tasksLearn\n",
            "\n",
            "ResourcesBlog2026 S\n"
          ]
        }
      ],
      "source": [
        "doc = docs[0]\n",
        "\n",
        "print(\"=== metadata ===\")\n",
        "print(doc.metadata)\n",
        "\n",
        "print(\"\\n=== page_content (ì²˜ìŒ 500ì) ===\")\n",
        "print(doc.page_content[:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V-LoFCN4-xw"
      },
      "source": [
        "# 4. ì—¬ëŸ¬ URL ë™ì‹œ ë¡œë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vHdvtcm4-xw",
        "outputId": "3e844d6a-b986-4bc1-d33a-559175408b34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: 2\n",
            "\n",
            "[1] https://python.langchain.com/docs/introduction/\n",
            "    ê¸¸ì´: 4171ì\n",
            "\n",
            "[2] https://python.langchain.com/docs/tutorials/\n",
            "    ê¸¸ì´: 4171ì\n"
          ]
        }
      ],
      "source": [
        "# ì—¬ëŸ¬ URL ë¡œë“œ\n",
        "urls = [\n",
        "    'https://python.langchain.com/docs/introduction/',\n",
        "    'https://python.langchain.com/docs/tutorials/',\n",
        "]\n",
        "\n",
        "loader = WebBaseLoader(urls)\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(docs)}\")\n",
        "for i, doc in enumerate(docs):\n",
        "    print(f\"\\n[{i+1}] {doc.metadata.get('source', 'N/A')}\")\n",
        "    print(f\"    ê¸¸ì´: {len(doc.page_content)}ì\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__GJexpH4-xw"
      },
      "source": [
        "## ê³ ê¸‰ ì˜µì…˜\n",
        "\n",
        "### íŠ¹ì • ìš”ì†Œë§Œ ì¶”ì¶œ (BeautifulSoup ì„¤ì •)\n",
        "\n",
        "```python\n",
        "import bs4\n",
        "\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=['https://example.com'],\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=['article-content', 'main-text']  # íŠ¹ì • í´ë˜ìŠ¤ë§Œ ì¶”ì¶œ\n",
        "        )\n",
        "    )\n",
        ")\n",
        "```\n",
        "\n",
        "### í—¤ë” ì„¤ì •\n",
        "\n",
        "```python\n",
        "loader = WebBaseLoader(\n",
        "    'https://example.com',\n",
        "    header_template={'User-Agent': 'MyBot/1.0'}\n",
        ")\n",
        "```\n",
        "\n",
        "## ì£¼ì˜ì‚¬í•­\n",
        "\n",
        "1. **JavaScript ë Œë”ë§**: WebBaseLoaderëŠ” ì •ì  HTMLë§Œ ì²˜ë¦¬. ë™ì  ì½˜í…ì¸ ëŠ” Selenium/Playwright ì‚¬ìš©\n",
        "2. **robots.txt ì¤€ìˆ˜**: ì›¹ í¬ë¡¤ë§ ì‹œ ì‚¬ì´íŠ¸ ì •ì±… í™•ì¸\n",
        "3. **ìš”ì²­ ì œí•œ**: ëŒ€ëŸ‰ í¬ë¡¤ë§ ì‹œ ë”œë ˆì´ ì¶”ê°€ ê¶Œì¥"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykjh-Mdr4-xw"
      },
      "source": [
        "## ì½”ë“œ 2-3 PyPDFLoaderë¡œ PDF íŒŒì¼ ë¡œë“œí•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip3oGFEZ4-xw"
      },
      "source": [
        "# PyPDFLoaderë¡œ PDF íŒŒì¼ ë¡œë“œí•˜ê¸°\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **PyPDFLoader**ë¥¼ ì‚¬ìš©í•˜ì—¬ PDF íŒŒì¼ì„ LangChain Documentë¡œ ë¡œë“œí•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤.\n",
        "\n",
        "## PyPDFLoaderë€?\n",
        "\n",
        "PDF íŒŒì¼ì„ **í˜ì´ì§€ ë‹¨ìœ„**ë¡œ ì½ì–´ Document ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ë¡œë”ì…ë‹ˆë‹¤.\n",
        "\n",
        "```python\n",
        "loader = PyPDFLoader('./document.pdf')\n",
        "pages = loader.load()  # í˜ì´ì§€ë³„ Document ë¦¬ìŠ¤íŠ¸\n",
        "```\n",
        "\n",
        "## PDF Loader ì¢…ë¥˜\n",
        "\n",
        "| Loader | íŠ¹ì§• |\n",
        "|--------|------|\n",
        "| `PyPDFLoader` | ê¸°ë³¸ PDF ë¡œë”, í˜ì´ì§€ë³„ ë¶„ë¦¬ |\n",
        "| `PyMuPDFLoader` | ë¹ ë¥¸ ì²˜ë¦¬, ì´ë¯¸ì§€ ì¶”ì¶œ ì§€ì› |\n",
        "| `PDFPlumberLoader` | í…Œì´ë¸” ì¶”ì¶œì— ê°•í•¨ |\n",
        "| `UnstructuredPDFLoader` | êµ¬ì¡°í™”ëœ ì¶”ì¶œ |\n",
        "\n",
        "\n",
        "# 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsCUNjd_4-xw"
      },
      "source": [
        "# 2. í…ŒìŠ¤íŠ¸ìš© PDF íŒŒì¼ ìƒì„±\n",
        "\n",
        "ì˜ˆì œë¥¼ ìœ„í•´ ê°„ë‹¨í•œ PDF íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQh6l0uI4-xw",
        "outputId": "24e0e519-aaa7-41da-d46b-8ec0e183e382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test.pdf íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. (2í˜ì´ì§€)\n"
          ]
        }
      ],
      "source": [
        "# reportlabìœ¼ë¡œ í…ŒìŠ¤íŠ¸ PDF ìƒì„±\n",
        "!pip install -q reportlab\n",
        "\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.pdfgen import canvas\n",
        "\n",
        "# PDF ìƒì„±\n",
        "c = canvas.Canvas('./test.pdf', pagesize=letter)\n",
        "\n",
        "# í˜ì´ì§€ 1\n",
        "c.drawString(100, 750, 'LangChain Tutorial - Page 1')\n",
        "c.drawString(100, 700, 'LangChain is a framework for developing applications')\n",
        "c.drawString(100, 680, 'powered by large language models (LLMs).')\n",
        "c.showPage()\n",
        "\n",
        "# í˜ì´ì§€ 2\n",
        "c.drawString(100, 750, 'RAG System - Page 2')\n",
        "c.drawString(100, 700, 'RAG stands for Retrieval-Augmented Generation.')\n",
        "c.drawString(100, 680, 'It combines retrieval and generation for better answers.')\n",
        "c.showPage()\n",
        "\n",
        "c.save()\n",
        "print('test.pdf íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. (2í˜ì´ì§€)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIiUj5Vg4-xw"
      },
      "source": [
        "# 3. PyPDFLoaderë¡œ PDF ë¡œë“œ\n",
        "\n",
        "**ì½”ë“œ ì„¤ëª…:**\n",
        "\n",
        "```python\n",
        "loader = PyPDFLoader('./test.pdf')\n",
        "pages = loader.load()\n",
        "```\n",
        "\n",
        "- ê° í˜ì´ì§€ê°€ ë³„ë„ì˜ Documentë¡œ ë°˜í™˜ë¨\n",
        "- `metadata`ì— í˜ì´ì§€ ë²ˆí˜¸(`page`) í¬í•¨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6l80t8l4-xw",
        "outputId": "49503a79-7ce1-4dcf-fd79-35c21306aaab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë¡œë“œëœ í˜ì´ì§€ ìˆ˜: 2\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# PDF ë¡œë“œ\n",
        "loader = PyPDFLoader('./test.pdf')\n",
        "pages = loader.load()\n",
        "\n",
        "print(f\"ë¡œë“œëœ í˜ì´ì§€ ìˆ˜: {len(pages)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNBFndcQ4-xw"
      },
      "source": [
        "# 4. í˜ì´ì§€ë³„ ë‚´ìš© í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WejQvmBO4-xw",
        "outputId": "003fbdfa-231f-40c7-c33b-53ac7ec61334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== í˜ì´ì§€ 1 ===\n",
            "metadata: {'producer': 'ReportLab PDF Library - (opensource)', 'creator': 'anonymous', 'creationdate': '2026-02-13T15:22:22+00:00', 'author': 'anonymous', 'keywords': '', 'moddate': '2026-02-13T15:22:22+00:00', 'subject': 'unspecified', 'title': 'untitled', 'trapped': '/False', 'source': './test.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}\n",
            "content: LangChain Tutorial - Page 1\n",
            "LangChain is a framework for developing applications\n",
            "powered by large language models (LLMs).\n",
            "\n",
            "=== í˜ì´ì§€ 2 ===\n",
            "metadata: {'producer': 'ReportLab PDF Library - (opensource)', 'creator': 'anonymous', 'creationdate': '2026-02-13T15:22:22+00:00', 'author': 'anonymous', 'keywords': '', 'moddate': '2026-02-13T15:22:22+00:00', 'subject': 'unspecified', 'title': 'untitled', 'trapped': '/False', 'source': './test.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}\n",
            "content: RAG System - Page 2\n",
            "RAG stands for Retrieval-Augmented Generation.\n",
            "It combines retrieval and generation for better answers.\n"
          ]
        }
      ],
      "source": [
        "# ê° í˜ì´ì§€ ë‚´ìš© í™•ì¸\n",
        "for i, page in enumerate(pages):\n",
        "    print(f\"\\n=== í˜ì´ì§€ {i+1} ===\")\n",
        "    print(f\"metadata: {page.metadata}\")\n",
        "    print(f\"content: {page.page_content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7cyj5MR4-xw"
      },
      "source": [
        "## ê³ ê¸‰ ì‚¬ìš©ë²•\n",
        "\n",
        "### íŠ¹ì • í˜ì´ì§€ë§Œ ë¡œë“œ\n",
        "\n",
        "```python\n",
        "# load_and_splitìœ¼ë¡œ íŠ¹ì • í˜ì´ì§€ ì„ íƒ ê°€ëŠ¥\n",
        "pages = loader.load()\n",
        "selected_pages = [pages[0], pages[2]]  # 1, 3í˜ì´ì§€ë§Œ\n",
        "```\n",
        "\n",
        "### í…ìŠ¤íŠ¸ ì¶”ì¶œ ëª¨ë“œ\n",
        "\n",
        "```python\n",
        "loader = PyPDFLoader('./test.pdf', extract_images=True)  # ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
        "```\n",
        "\n",
        "## ë‹¤ë¥¸ PDF ë¡œë” ì˜ˆì‹œ\n",
        "\n",
        "### PyMuPDFLoader (ë” ë¹ ë¦„)\n",
        "```python\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "loader = PyMuPDFLoader('./test.pdf')\n",
        "pages = loader.load()\n",
        "```\n",
        "\n",
        "### PDFPlumberLoader (í…Œì´ë¸” ì¶”ì¶œ)\n",
        "```python\n",
        "from langchain_community.document_loaders import PDFPlumberLoader\n",
        "\n",
        "loader = PDFPlumberLoader('./test.pdf')\n",
        "pages = loader.load()\n",
        "```\n",
        "\n",
        "## ì£¼ì˜ì‚¬í•­\n",
        "\n",
        "1. **ìŠ¤ìº” PDF**: OCRì´ í•„ìš”í•œ ê²½ìš° `UnstructuredPDFLoader` + Tesseract ì‚¬ìš©\n",
        "2. **ì•”í˜¸í™” PDF**: ë¹„ë°€ë²ˆí˜¸ ì˜µì…˜ í•„ìš”\n",
        "3. **ëŒ€ìš©ëŸ‰ PDF**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì£¼ì˜, lazy_load() ê³ ë ¤"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvyQrj0H4-xw"
      },
      "source": [
        "## ì½”ë“œ 2-4 RecursiveCharacterTextSplitterë¡œ ë¬¸ì„œ ë¶„í• í•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF3P_JJz4-xw"
      },
      "source": [
        "# RecursiveCharacterTextSplitterë¡œ ë¬¸ì„œ ë¶„í• í•˜ê¸°\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **RecursiveCharacterTextSplitter**ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ì ì ˆí•œ í¬ê¸°ì˜ ì²­í¬ë¡œ ë¶„í• í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤.\n",
        "\n",
        "## RAG íŒŒì´í”„ë¼ì¸ì—ì„œì˜ ìœ„ì¹˜\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  ğŸ“„ Load    â”‚ â”€â”€â–¶ â”‚  âœ‚ï¸ Split   â”‚ â”€â”€â–¶ â”‚  ğŸ”¢ Embed   â”‚ â”€â”€â–¶ â”‚  ğŸ’¾ Store   â”‚\n",
        "â”‚  (ë¡œë“œ)     â”‚     â”‚  (ë¶„í• )     â”‚     â”‚  (ì„ë² ë”©)    â”‚     â”‚  (ì €ì¥)     â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                          â†‘\n",
        "                       í˜„ì¬ ë‹¨ê³„\n",
        "```\n",
        "\n",
        "## ì™œ ë¬¸ì„œë¥¼ ë¶„í• í•´ì•¼ í• ê¹Œ?\n",
        "\n",
        "1. **LLM ì»¨í…ìŠ¤íŠ¸ ì œí•œ**: ëª¨ë¸ì˜ ìµœëŒ€ í† í° ìˆ˜ ì œí•œ\n",
        "2. **ê²€ìƒ‰ ì •í™•ë„**: ì‘ì€ ì²­í¬ê°€ ë” ì •í™•í•œ ê²€ìƒ‰ ê²°ê³¼\n",
        "3. **ë¹„ìš© íš¨ìœ¨**: í•„ìš”í•œ ë¶€ë¶„ë§Œ LLMì— ì „ë‹¬\n",
        "\n",
        "## RecursiveCharacterTextSplitterë€?\n",
        "\n",
        "**ì¬ê·€ì **ìœ¼ë¡œ ì—¬ëŸ¬ êµ¬ë¶„ìë¥¼ ì‹œë„í•˜ì—¬ ì˜ë¯¸ ìˆëŠ” ë‹¨ìœ„ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•©ë‹ˆë‹¤.\n",
        "\n",
        "ê¸°ë³¸ êµ¬ë¶„ì ìˆœì„œ:\n",
        "1. `\\n\\n` (ë‹¨ë½)\n",
        "2. `\\n` (ì¤„ë°”ê¿ˆ)\n",
        "3. ` ` (ê³µë°±)\n",
        "4. `` (ë¬¸ì)\n",
        "\n",
        "\n",
        "# 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J17EMTks4-xx"
      },
      "source": [
        "# 2. í…ŒìŠ¤íŠ¸ íŒŒì¼ ì¤€ë¹„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUwgfR164-xx",
        "outputId": "7d9a8b37-baad-4c9d-9a6c-747b4902dca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test.txt ìƒì„± ì™„ë£Œ (ì´ 357ì)\n"
          ]
        }
      ],
      "source": [
        "# í…ŒìŠ¤íŠ¸ìš© í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±\n",
        "sample_text = '''LangChainì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì£¼ìš” ê¸°ëŠ¥:\n",
        "1. í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ë° ìµœì í™”\n",
        "2. ì²´ì¸ êµ¬ì„±ì„ í†µí•œ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ìƒì„±\n",
        "3. ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ì˜ ì—°ë™\n",
        "4. ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ í†µí•œ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€\n",
        "\n",
        "LangChainì„ ì‚¬ìš©í•˜ë©´ RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì„ ì‰½ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. RAGëŠ” ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•˜ì—¬ LLMì˜ ì‘ë‹µì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
        "\n",
        "Vector StoreëŠ” ì„ë² ë”©ëœ ë¬¸ì„œë¥¼ ì €ì¥í•˜ê³  ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤. ëŒ€í‘œì ìœ¼ë¡œ Chroma, Pinecone, Weaviate ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n",
        "'''\n",
        "\n",
        "with open('./test.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(sample_text)\n",
        "\n",
        "print(f\"test.txt ìƒì„± ì™„ë£Œ (ì´ {len(sample_text)}ì)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0SsECtC4-xx"
      },
      "source": [
        "# 3. ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• \n",
        "\n",
        "**í•µì‹¬ íŒŒë¼ë¯¸í„°:**\n",
        "\n",
        "```python\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,    # ì²­í¬ ìµœëŒ€ í¬ê¸° (ë¬¸ì ìˆ˜)\n",
        "    chunk_overlap=200   # ì²­í¬ ê°„ ì¤‘ë³µ (ë¬¸ë§¥ ìœ ì§€)\n",
        ")\n",
        "```\n",
        "\n",
        "| íŒŒë¼ë¯¸í„° | ì„¤ëª… |\n",
        "|----------|------|\n",
        "| `chunk_size` | ê° ì²­í¬ì˜ ìµœëŒ€ ë¬¸ì ìˆ˜ |\n",
        "| `chunk_overlap` | ì¸ì ‘ ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¬¸ì ìˆ˜ (ë¬¸ë§¥ ìœ ì§€ìš©) |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R67b8Yb64-xx",
        "outputId": "3d304ed9-4b91-4205-a1d3-1239310c46d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì›ë³¸ ë¬¸ì„œ ìˆ˜: 1\n",
            "ì›ë³¸ ë¬¸ì„œ ê¸¸ì´: 357ì\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# 1. ë¬¸ì„œ ë¡œë“œ\n",
        "loader = TextLoader('./test.txt', encoding='utf-8')\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"ì›ë³¸ ë¬¸ì„œ ìˆ˜: {len(docs)}\")\n",
        "print(f\"ì›ë³¸ ë¬¸ì„œ ê¸¸ì´: {len(docs[0].page_content)}ì\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpoYgGfr4-xx",
        "outputId": "09144f73-910b-4e61-f923-0e3ef209287d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë¶„í• ëœ ë¬¸ì„œ ìˆ˜: 3\n"
          ]
        }
      ],
      "source": [
        "# 2. Text Splitter ìƒì„±\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200,     # ì˜ˆì‹œë¥¼ ìœ„í•´ ì‘ì€ ê°’ ì‚¬ìš©\n",
        "    chunk_overlap=50\n",
        ")\n",
        "\n",
        "# 3. ë¬¸ì„œ ë¶„í• \n",
        "splitted_docs = splitter.split_documents(docs)\n",
        "\n",
        "print(f\"ë¶„í• ëœ ë¬¸ì„œ ìˆ˜: {len(splitted_docs)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHxrKV3i4-xx"
      },
      "source": [
        "# 4. ë¶„í•  ê²°ê³¼ í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-_iZBGQ4-xx",
        "outputId": "5125053f-6cfd-4a9e-9cf6-b3b8becd51d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ì²­í¬ 1 (149ì) ===\n",
            "LangChainì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
            "\n",
            "ì£¼ìš” ê¸°ëŠ¥:\n",
            "1. í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ë° ìµœì í™”\n",
            "2. ì²´ì¸ êµ¬ì„±ì„ í†µí•œ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ìƒì„±\n",
            "3. ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ì˜ ì—°ë™\n",
            "4. ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ í†µí•œ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€\n",
            "metadata: {'source': './test.txt'}\n",
            "\n",
            "=== ì²­í¬ 2 (110ì) ===\n",
            "LangChainì„ ì‚¬ìš©í•˜ë©´ RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì„ ì‰½ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. RAGëŠ” ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•˜ì—¬ LLMì˜ ì‘ë‹µì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
            "metadata: {'source': './test.txt'}\n",
            "\n",
            "=== ì²­í¬ 3 (93ì) ===\n",
            "Vector StoreëŠ” ì„ë² ë”©ëœ ë¬¸ì„œë¥¼ ì €ì¥í•˜ê³  ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤. ëŒ€í‘œì ìœ¼ë¡œ Chroma, Pinecone, Weaviate ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n",
            "metadata: {'source': './test.txt'}\n"
          ]
        }
      ],
      "source": [
        "# ê° ì²­í¬ í™•ì¸\n",
        "for i, doc in enumerate(splitted_docs):\n",
        "    print(f\"\\n=== ì²­í¬ {i+1} ({len(doc.page_content)}ì) ===\")\n",
        "    print(doc.page_content)\n",
        "    print(f\"metadata: {doc.metadata}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z07c8u_U4-xz"
      },
      "source": [
        "## chunk_overlapì˜ ì—­í• \n",
        "\n",
        "```\n",
        "ì²­í¬ 1: [    í…ìŠ¤íŠ¸ A    ][ì¤‘ë³µ]\n",
        "ì²­í¬ 2:              [ì¤‘ë³µ][    í…ìŠ¤íŠ¸ B    ]\n",
        "```\n",
        "\n",
        "- ë¬¸ë§¥ì´ ì²­í¬ ê²½ê³„ì—ì„œ ëŠê¸°ëŠ” ê²ƒì„ ë°©ì§€\n",
        "- ê²€ìƒ‰ ì‹œ ê´€ë ¨ ì •ë³´ê°€ ëˆ„ë½ë˜ì§€ ì•Šë„ë¡ ë³´ì¥\n",
        "\n",
        "## ì ì ˆí•œ chunk_size ì„ íƒ\n",
        "\n",
        "| chunk_size | ì¥ì  | ë‹¨ì  |\n",
        "|------------|------|------|\n",
        "| ì‘ìŒ (200-500) | ì •í™•í•œ ê²€ìƒ‰ | ë¬¸ë§¥ ì†ì‹¤ ê°€ëŠ¥ |\n",
        "| ì¤‘ê°„ (500-1000) | ê· í˜• ì¡í˜ | - |\n",
        "| í¼ (1000-2000) | í’ë¶€í•œ ë¬¸ë§¥ | ê²€ìƒ‰ ì •í™•ë„ ì €í•˜ |\n",
        "\n",
        "## ë‹¤ë¥¸ Text Splitter\n",
        "\n",
        "```python\n",
        "# í† í° ê¸°ë°˜ ë¶„í• \n",
        "from langchain_text_splitters import TokenTextSplitter\n",
        "splitter = TokenTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "\n",
        "# ë¬¸ì¥ ê¸°ë°˜ ë¶„í• \n",
        "from langchain_text_splitters import SentenceTransformersTokenTextSplitter\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyov7f_K4-xz"
      },
      "source": [
        "## ì½”ë“œ 2-5 í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë³„ ì½”ë“œ ë¶„í• í•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO6O6v9Y4-xz"
      },
      "source": [
        "# í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë³„ ì½”ë“œ ë¶„í• í•˜ê¸°\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **RecursiveCharacterTextSplitter.from_language()**ë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡œê·¸ë˜ë° ì½”ë“œë¥¼ ì–¸ì–´ë³„ êµ¬ë¬¸ì— ë§ê²Œ ë¶„í• í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤.\n",
        "\n",
        "## ì½”ë“œ ë¶„í• ì´ íŠ¹ë³„í•œ ì´ìœ \n",
        "\n",
        "ì¼ë°˜ í…ìŠ¤íŠ¸ì™€ ë‹¬ë¦¬ ì½”ë“œëŠ” **ë¬¸ë²•ì  êµ¬ì¡°**ê°€ ìˆìŠµë‹ˆë‹¤:\n",
        "\n",
        "- í•¨ìˆ˜/í´ë˜ìŠ¤ ë‹¨ìœ„\n",
        "- ë“¤ì—¬ì“°ê¸° ë¸”ë¡\n",
        "- ì£¼ì„\n",
        "\n",
        "`from_language()`ëŠ” ì–¸ì–´ë³„ êµ¬ë¶„ìë¥¼ ìë™ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "\n",
        "## ì§€ì› ì–¸ì–´\n",
        "\n",
        "```python\n",
        "from langchain_text_splitters import Language\n",
        "\n",
        "# ì£¼ìš” ì§€ì› ì–¸ì–´\n",
        "Language.PYTHON\n",
        "Language.JAVASCRIPT\n",
        "Language.TYPESCRIPT\n",
        "Language.JAVA\n",
        "Language.GO\n",
        "Language.RUST\n",
        "Language.MARKDOWN\n",
        "Language.HTML\n",
        "# ... ë“± 20+ ì–¸ì–´ ì§€ì›\n",
        "```\n",
        "\n",
        "\n",
        "# 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAOi-2gs4-x0"
      },
      "source": [
        "# 2. Python ì½”ë“œ ë¶„í• \n",
        "\n",
        "**ì½”ë“œ ì„¤ëª…:**\n",
        "\n",
        "```python\n",
        "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "    language=Language.PYTHON,  # Python êµ¬ë¬¸ ê·œì¹™ ì‚¬ìš©\n",
        "    chunk_size=50,\n",
        "    chunk_overlap=0\n",
        ")\n",
        "```\n",
        "\n",
        "Pythonì˜ ê¸°ë³¸ êµ¬ë¶„ì:\n",
        "1. í´ë˜ìŠ¤ ì •ì˜ (`class`)\n",
        "2. í•¨ìˆ˜ ì •ì˜ (`def`)\n",
        "3. ì œì–´ë¬¸ (`if`, `for`, `while` ë“±)\n",
        "4. ì¤„ë°”ê¿ˆ, ê³µë°±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFaBvOsF4-x0",
        "outputId": "17d881bb-f026-4564-eb4c-3c63eff403d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ì›ë³¸ ì½”ë“œ ===\n",
            "\n",
            "def hello_world():\n",
            "    print(\"Hello, World!\")\n",
            "\n",
            "# Call the function\n",
            "hello_world()\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import Language, RecursiveCharacterTextSplitter\n",
        "\n",
        "# ìƒ˜í”Œ Python ì½”ë“œ\n",
        "PYTHON_CODE = '''\n",
        "def hello_world():\n",
        "    print(\"Hello, World!\")\n",
        "\n",
        "# Call the function\n",
        "hello_world()\n",
        "'''\n",
        "\n",
        "print(\"=== ì›ë³¸ ì½”ë“œ ===\")\n",
        "print(PYTHON_CODE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rl2C3644-x0",
        "outputId": "41789a4f-6df4-4b7c-ce14-d2170a695235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ë¶„í• ëœ ì²­í¬ ìˆ˜: 2\n",
            "\n",
            "--- ì²­í¬ 1 ---\n",
            "def hello_world():\n",
            "    print(\"Hello, World!\")\n",
            "\n",
            "--- ì²­í¬ 2 ---\n",
            "# Call the function\n",
            "hello_world()\n"
          ]
        }
      ],
      "source": [
        "# Python ì „ìš© Splitter ìƒì„±\n",
        "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "    language=Language.PYTHON,\n",
        "    chunk_size=50,\n",
        "    chunk_overlap=0\n",
        ")\n",
        "\n",
        "# ë¬¸ì„œ ìƒì„± ë° ë¶„í• \n",
        "python_docs = python_splitter.create_documents([PYTHON_CODE])\n",
        "\n",
        "print(f\"\\në¶„í• ëœ ì²­í¬ ìˆ˜: {len(python_docs)}\")\n",
        "for i, doc in enumerate(python_docs):\n",
        "    print(f\"\\n--- ì²­í¬ {i+1} ---\")\n",
        "    print(doc.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5OqLie44-x0"
      },
      "source": [
        "# 3. JavaScript ì½”ë“œ ë¶„í• "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTHioQVy4-x0",
        "outputId": "01961eab-96ae-437a-9c03-7ef4aa8b0d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë¶„í• ëœ ì²­í¬ ìˆ˜: 3\n",
            "\n",
            "--- ì²­í¬ 1 ---\n",
            "function greet(name) {\n",
            "    console.log(`Hello, ${name}!`);\n",
            "\n",
            "--- ì²­í¬ 2 ---\n",
            "}\n",
            "\n",
            "--- ì²­í¬ 3 ---\n",
            "const add = (a, b) => a + b;\n",
            "\n",
            "greet(\"World\");\n"
          ]
        }
      ],
      "source": [
        "JS_CODE = '''\n",
        "function greet(name) {\n",
        "    console.log(`Hello, ${name}!`);\n",
        "}\n",
        "\n",
        "const add = (a, b) => a + b;\n",
        "\n",
        "greet(\"World\");\n",
        "'''\n",
        "\n",
        "js_splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "    language=Language.JS,\n",
        "    chunk_size=60,\n",
        "    chunk_overlap=0\n",
        ")\n",
        "\n",
        "js_docs = js_splitter.create_documents([JS_CODE])\n",
        "\n",
        "print(f\"ë¶„í• ëœ ì²­í¬ ìˆ˜: {len(js_docs)}\")\n",
        "for i, doc in enumerate(js_docs):\n",
        "    print(f\"\\n--- ì²­í¬ {i+1} ---\")\n",
        "    print(doc.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpEZplVi4-x0"
      },
      "source": [
        "# 4. ì–¸ì–´ë³„ êµ¬ë¶„ì í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ez-RVab4-x0",
        "outputId": "7df7dc16-5a0d-4b86-d52e-dc3447ab2f0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Python êµ¬ë¶„ì ===\n",
            "['\\nclass ', '\\ndef ', '\\n\\tdef ', '\\n\\n', '\\n', ' ', '']\n",
            "\n",
            "=== JavaScript êµ¬ë¶„ì ===\n",
            "['\\nfunction ', '\\nconst ', '\\nlet ', '\\nvar ', '\\nclass ', '\\nif ', '\\nfor ', '\\nwhile ', '\\nswitch ', '\\ncase ', '\\ndefault ', '\\n\\n', '\\n', ' ', '']\n",
            "\n",
            "=== Markdown êµ¬ë¶„ì ===\n",
            "['\\n#{1,6} ', '```\\n', '\\n\\\\*\\\\*\\\\*+\\n', '\\n---+\\n', '\\n___+\\n', '\\n\\n', '\\n', ' ', '']\n"
          ]
        }
      ],
      "source": [
        "# ê° ì–¸ì–´ì˜ êµ¬ë¶„ì í™•ì¸\n",
        "print(\"=== Python êµ¬ë¶„ì ===\")\n",
        "print(RecursiveCharacterTextSplitter.get_separators_for_language(Language.PYTHON))\n",
        "\n",
        "print(\"\\n=== JavaScript êµ¬ë¶„ì ===\")\n",
        "print(RecursiveCharacterTextSplitter.get_separators_for_language(Language.JS))\n",
        "\n",
        "print(\"\\n=== Markdown êµ¬ë¶„ì ===\")\n",
        "print(RecursiveCharacterTextSplitter.get_separators_for_language(Language.MARKDOWN))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6_nSho74-x0"
      },
      "source": [
        "## ì§€ì› ì–¸ì–´ ëª©ë¡\n",
        "\n",
        "```python\n",
        "# ì „ì²´ ì§€ì› ì–¸ì–´ í™•ì¸\n",
        "print([e.value for e in Language])\n",
        "```\n",
        "\n",
        "ì£¼ìš” ì–¸ì–´:\n",
        "- `Language.PYTHON`\n",
        "- `Language.JS` / `Language.TYPESCRIPT`\n",
        "- `Language.JAVA` / `Language.KOTLIN`\n",
        "- `Language.GO` / `Language.RUST`\n",
        "- `Language.C` / `Language.CPP`\n",
        "- `Language.MARKDOWN` / `Language.HTML`\n",
        "\n",
        "## í™œìš© ì‚¬ë¡€\n",
        "\n",
        "1. **ì½”ë“œ ê²€ìƒ‰ ì‹œìŠ¤í…œ**: í•¨ìˆ˜/í´ë˜ìŠ¤ ë‹¨ìœ„ë¡œ ê²€ìƒ‰\n",
        "2. **ì½”ë“œ ë¦¬ë·° ë„ìš°ë¯¸**: ê´€ë ¨ ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ\n",
        "3. **ë¬¸ì„œí™” ìë™í™”**: ì½”ë“œì™€ ì£¼ì„ ì—°ê²°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JelC8uy04-x0"
      },
      "source": [
        "## ì½”ë“œ 2-6 Markdown ë¬¸ì„œ ë¶„í• í•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bp_IUfM4-x0"
      },
      "source": [
        "# Markdown ë¬¸ì„œ ë¶„í• í•˜ê¸°\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **RecursiveCharacterTextSplitter.from_language()**ë¡œ Markdown ë¬¸ì„œë¥¼ êµ¬ì¡°ì— ë§ê²Œ ë¶„í• í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤.\n",
        "\n",
        "## Markdown ë¶„í•  íŠ¹ì§•\n",
        "\n",
        "Markdownì€ í—¤ë”(`#`, `##`) ê¸°ë°˜ êµ¬ì¡°ë¥¼ ê°€ì§€ë¯€ë¡œ, ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• í•˜ë©´ ì˜ë¯¸ ìˆëŠ” ì„¹ì…˜ ë‹¨ìœ„ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "**Markdown êµ¬ë¶„ì ìˆœì„œ:**\n",
        "1. `\\n# ` (H1 í—¤ë”)\n",
        "2. `\\n## ` (H2 í—¤ë”)\n",
        "3. `\\n### ` (H3 í—¤ë”)\n",
        "4. `\\n#### ` (H4 í—¤ë”)\n",
        "5. `\\n- ` (ë¦¬ìŠ¤íŠ¸)\n",
        "6. ` ``` ` (ì½”ë“œ ë¸”ë¡)\n",
        "7. `\\n\\n`, `\\n`, ` `\n",
        "\n",
        "\n",
        "# 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8swfTun4-x0"
      },
      "source": [
        "# 2. Markdown ë¬¸ì„œ ë¶„í• \n",
        "\n",
        "**ì½”ë“œ ì„¤ëª…:**\n",
        "\n",
        "```python\n",
        "md_splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "    language=Language.MARKDOWN,\n",
        "    chunk_size=60,\n",
        "    chunk_overlap=0\n",
        ")\n",
        "\n",
        "# metadata ì¶”ê°€ ê°€ëŠ¥\n",
        "md_docs = md_splitter.create_documents(\n",
        "    [markdown_text],\n",
        "    [{'source': 'https://...'}]  # ê° ë¬¸ì„œì˜ ë©”íƒ€ë°ì´í„°\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMl3o9bz4-x0",
        "outputId": "03ca9157-7755-4230-f0aa-88fdcb91d180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ì›ë³¸ Markdown ===\n",
            "\n",
            "# ğŸ¦œğŸ”— LangChain âš¡ Building applications with LLMs through composability âš¡\n",
            "\n",
            "## Quick Install\n",
            "```bash\n",
            "pip install langchain\n",
            "```\n",
            "\n",
            "As an open source project in a rapidly developing field, we are extremely open\n",
            "    to contributions.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import Language, RecursiveCharacterTextSplitter\n",
        "\n",
        "# ìƒ˜í”Œ Markdown í…ìŠ¤íŠ¸\n",
        "markdown_text = '''\n",
        "# ğŸ¦œğŸ”— LangChain âš¡ Building applications with LLMs through composability âš¡\n",
        "\n",
        "## Quick Install\n",
        "```bash\n",
        "pip install langchain\n",
        "```\n",
        "\n",
        "As an open source project in a rapidly developing field, we are extremely open\n",
        "    to contributions.\n",
        "'''\n",
        "\n",
        "print(\"=== ì›ë³¸ Markdown ===\")\n",
        "print(markdown_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNx92mEf4-x0",
        "outputId": "c15f75c5-fdb6-4394-be54-5209c25a6ede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ë¶„í• ëœ ì²­í¬ ìˆ˜: 7\n"
          ]
        }
      ],
      "source": [
        "# Markdown ì „ìš© Splitter ìƒì„±\n",
        "md_splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "    language=Language.MARKDOWN,\n",
        "    chunk_size=60,\n",
        "    chunk_overlap=0\n",
        ")\n",
        "\n",
        "# ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ë¬¸ì„œ ìƒì„±\n",
        "md_docs = md_splitter.create_documents(\n",
        "    [markdown_text],\n",
        "    [{'source': 'https://www.langchain.com'}]  # ì¶œì²˜ ë©”íƒ€ë°ì´í„°\n",
        ")\n",
        "\n",
        "print(f\"\\në¶„í• ëœ ì²­í¬ ìˆ˜: {len(md_docs)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U9OHSnp4-x0"
      },
      "source": [
        "# 3. ë¶„í•  ê²°ê³¼ í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPK8PPuE4-x0",
        "outputId": "ce7a293d-bc9e-439e-d889-eb79287dec2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ì²­í¬ 1 ===\n",
            "metadata: {'source': 'https://www.langchain.com'}\n",
            "content (56ì):\n",
            "# ğŸ¦œğŸ”— LangChain âš¡ Building applications with LLMs through\n",
            "\n",
            "=== ì²­í¬ 2 ===\n",
            "metadata: {'source': 'https://www.langchain.com'}\n",
            "content (15ì):\n",
            "composability âš¡\n",
            "\n",
            "=== ì²­í¬ 3 ===\n",
            "metadata: {'source': 'https://www.langchain.com'}\n",
            "content (46ì):\n",
            "## Quick Install\n",
            "```bash\n",
            "pip install langchain\n",
            "\n",
            "=== ì²­í¬ 4 ===\n",
            "metadata: {'source': 'https://www.langchain.com'}\n",
            "content (3ì):\n",
            "```\n",
            "\n",
            "=== ì²­í¬ 5 ===\n",
            "metadata: {'source': 'https://www.langchain.com'}\n",
            "content (59ì):\n",
            "As an open source project in a rapidly developing field, we\n",
            "\n",
            "=== ì²­í¬ 6 ===\n",
            "metadata: {'source': 'https://www.langchain.com'}\n",
            "content (18ì):\n",
            "are extremely open\n",
            "\n",
            "=== ì²­í¬ 7 ===\n",
            "metadata: {'source': 'https://www.langchain.com'}\n",
            "content (17ì):\n",
            "to contributions.\n"
          ]
        }
      ],
      "source": [
        "# ê° ì²­í¬ í™•ì¸\n",
        "for i, doc in enumerate(md_docs):\n",
        "    print(f\"\\n=== ì²­í¬ {i+1} ===\")\n",
        "    print(f\"metadata: {doc.metadata}\")\n",
        "    print(f\"content ({len(doc.page_content)}ì):\")\n",
        "    print(doc.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvFBccfM4-x0"
      },
      "source": [
        "# 4. í—¤ë” ê¸°ë°˜ ë¶„í•  (MarkdownHeaderTextSplitter)\n",
        "\n",
        "í—¤ë”ë¥¼ ë©”íƒ€ë°ì´í„°ë¡œ ë³´ì¡´í•˜ë©´ì„œ ë¶„í• í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22VCX_Pv4-x0",
        "outputId": "5d4665d3-ab54-41f4-c6ce-8e9fca739b9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== í—¤ë” ê¸°ë°˜ ë¶„í•  ê²°ê³¼ ===\n",
            "\n",
            "--- ì²­í¬ 1 ---\n",
            "metadata: {'Header 1': 'LangChain ì†Œê°œ'}\n",
            "content: LangChainì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
            "\n",
            "--- ì²­í¬ 2 ---\n",
            "metadata: {'Header 1': 'LangChain ì†Œê°œ', 'Header 2': 'ì„¤ì¹˜ ë°©ë²•'}\n",
            "content: pip install langchain ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
            "\n",
            "--- ì²­í¬ 3 ---\n",
            "metadata: {'Header 1': 'LangChain ì†Œê°œ', 'Header 2': 'ì£¼ìš” ê¸°ëŠ¥', 'Header 3': 'ì²´ì¸ êµ¬ì„±'}\n",
            "content: LCELë¡œ ì²´ì¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
            "\n",
            "--- ì²­í¬ 4 ---\n",
            "metadata: {'Header 1': 'LangChain ì†Œê°œ', 'Header 2': 'ì£¼ìš” ê¸°ëŠ¥', 'Header 3': 'RAG'}\n",
            "content: ê²€ìƒ‰ ì¦ê°• ìƒì„±ì„ ì§€ì›í•©ë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
        "\n",
        "# ë¶„í• í•  í—¤ë” ë ˆë²¨ ì •ì˜\n",
        "headers_to_split_on = [\n",
        "    (\"#\", \"Header 1\"),\n",
        "    (\"##\", \"Header 2\"),\n",
        "    (\"###\", \"Header 3\"),\n",
        "]\n",
        "\n",
        "md_header_splitter = MarkdownHeaderTextSplitter(\n",
        "    headers_to_split_on=headers_to_split_on\n",
        ")\n",
        "\n",
        "# ë” êµ¬ì¡°í™”ëœ Markdown ì˜ˆì‹œ\n",
        "structured_md = '''# LangChain ì†Œê°œ\n",
        "\n",
        "LangChainì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
        "\n",
        "## ì„¤ì¹˜ ë°©ë²•\n",
        "\n",
        "pip install langchain ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "## ì£¼ìš” ê¸°ëŠ¥\n",
        "\n",
        "### ì²´ì¸ êµ¬ì„±\n",
        "\n",
        "LCELë¡œ ì²´ì¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "### RAG\n",
        "\n",
        "ê²€ìƒ‰ ì¦ê°• ìƒì„±ì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
        "'''\n",
        "\n",
        "header_splits = md_header_splitter.split_text(structured_md)\n",
        "\n",
        "print(\"=== í—¤ë” ê¸°ë°˜ ë¶„í•  ê²°ê³¼ ===\")\n",
        "for i, doc in enumerate(header_splits):\n",
        "    print(f\"\\n--- ì²­í¬ {i+1} ---\")\n",
        "    print(f\"metadata: {doc.metadata}\")\n",
        "    print(f\"content: {doc.page_content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ny3Vtd8b4-x0"
      },
      "source": [
        "## ë‘ Splitter ë¹„êµ\n",
        "\n",
        "| Splitter | íŠ¹ì§• |\n",
        "|----------|------|\n",
        "| `RecursiveCharacterTextSplitter.from_language(MARKDOWN)` | chunk_size ê¸°ë°˜ ë¶„í•  |\n",
        "| `MarkdownHeaderTextSplitter` | í—¤ë” ê¸°ë°˜ ë¶„í• , í—¤ë”ë¥¼ ë©”íƒ€ë°ì´í„°ë¡œ ë³´ì¡´ |\n",
        "\n",
        "## ì¡°í•© ì‚¬ìš© (ê¶Œì¥)\n",
        "\n",
        "```python\n",
        "# 1. í—¤ë”ë¡œ ë¨¼ì € ë¶„í• \n",
        "header_splits = md_header_splitter.split_text(markdown)\n",
        "\n",
        "# 2. í° ì„¹ì…˜ì€ ì¶”ê°€ë¡œ ë¶„í• \n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500)\n",
        "final_splits = text_splitter.split_documents(header_splits)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q58xqfuh4-x0"
      },
      "source": [
        "## ì½”ë“œ 2-7 Embeddingsë¡œ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJbrFBss4-x0"
      },
      "source": [
        "# Embeddingsë¡œ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ê¸°\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **Embeddings**ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°(ìˆ«ì ë°°ì—´)ë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤.\n",
        "\n",
        "## RAG íŒŒì´í”„ë¼ì¸ì—ì„œì˜ ìœ„ì¹˜\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  ğŸ“„ Load    â”‚ â”€â”€â–¶ â”‚  âœ‚ï¸ Split   â”‚ â”€â”€â–¶ â”‚  ğŸ”¢ Embed   â”‚ â”€â”€â–¶ â”‚  ğŸ’¾ Store   â”‚\n",
        "â”‚  (ë¡œë“œ)     â”‚     â”‚  (ë¶„í• )     â”‚     â”‚  (ì„ë² ë”©)    â”‚     â”‚  (ì €ì¥)     â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                              â†‘\n",
        "                                           í˜„ì¬ ë‹¨ê³„\n",
        "```\n",
        "\n",
        "## Embeddingì´ë€?\n",
        "\n",
        "í…ìŠ¤íŠ¸ì˜ **ì˜ë¯¸**ë¥¼ ìˆ«ì ë²¡í„°ë¡œ í‘œí˜„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
        "\n",
        "```\n",
        "\"ì•ˆë…•í•˜ì„¸ìš”\" â†’ [0.12, -0.34, 0.56, ..., 0.78]  (1536ì°¨ì›)\n",
        "```\n",
        "\n",
        "**íŠ¹ì§•:**\n",
        "- ì˜ë¯¸ê°€ ë¹„ìŠ·í•œ í…ìŠ¤íŠ¸ â†’ ë²¡í„°ê°€ ê°€ê¹Œì›€\n",
        "- ë²¡í„° ê°„ ê±°ë¦¬/ìœ ì‚¬ë„ë¡œ ê²€ìƒ‰ ê°€ëŠ¥\n",
        "\n",
        "## ì£¼ìš” Embedding ëª¨ë¸\n",
        "\n",
        "| ëª¨ë¸ | íŠ¹ì§• |\n",
        "|------|------|\n",
        "| OpenAI `text-embedding-3-small` | ë¹ ë¥´ê³  ì €ë ´ |\n",
        "| OpenAI `text-embedding-3-large` | ë†’ì€ ì •í™•ë„ |\n",
        "| Ollama (nomic-embed-text) | ë¡œì»¬, ë¬´ë£Œ |\n",
        "| HuggingFace | ë‹¤ì–‘í•œ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ |\n",
        "\n",
        "\n",
        "# 1. Ollama ì„¤ì¹˜ ë° ì„œë²„ ì‹¤í–‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FhYC8jy4-x0",
        "outputId": "f19f98a9-d83c-4eec-e69b-866d7d92616b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "zstd is already the newest version (1.4.8+dfsg-3build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 58 not upgraded.\n",
            ">>> Cleaning up old version at /usr/local/lib/ollama\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading ollama-linux-amd64.tar.zst\n",
            "######################################################################## 100.0%\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import time\n",
        "\n",
        "!apt-get install -y zstd\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "subprocess.Popen(['ollama', 'serve'])\n",
        "time.sleep(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKV_1x7G4-x0"
      },
      "source": [
        "# 2. ì„ë² ë”© ëª¨ë¸ ë‹¤ìš´ë¡œë“œ & íŒ¨í‚¤ì§€ ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAUI0iK_4-x0",
        "outputId": "9752f0b6-7f3a-47c8-ecdf-3ce31421be5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ],
      "source": [
        "# Ollama ì„ë² ë”©/ì±— ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì´í›„ ì„¹ì…˜ì—ì„œë„ ì‚¬ìš©)\n",
        "!ollama pull nomic-embed-text\n",
        "!ollama pull llama3.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKLYfY9e4-x0"
      },
      "source": [
        "# 3. Embeddings ìƒì„±\n",
        "\n",
        "**ì½”ë“œ ì„¤ëª…:**\n",
        "\n",
        "```python\n",
        "model = OllamaEmbeddings(model='nomic-embed-text')\n",
        "embeddings = model.embed_documents(['í…ìŠ¤íŠ¸1', 'í…ìŠ¤íŠ¸2', ...])\n",
        "```\n",
        "\n",
        "- `embed_documents()` - ì—¬ëŸ¬ ë¬¸ì„œë¥¼ ë²¡í„°ë¡œ ë³€í™˜\n",
        "- `embed_query()` - ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wcn84MY4-x0",
        "outputId": "7f6ee661-4d15-4f71-83bc-1957a829aa82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì„ë² ë”©ëœ ë¬¸ì„œ ìˆ˜: 5\n",
            "ê° ë²¡í„°ì˜ ì°¨ì›: 768\n"
          ]
        }
      ],
      "source": [
        "from langchain_ollama import OllamaEmbeddings\n",
        "\n",
        "# ì„ë² ë”© ëª¨ë¸ ìƒì„±\n",
        "model = OllamaEmbeddings(model='nomic-embed-text')\n",
        "\n",
        "# ì—¬ëŸ¬ ë¬¸ì„œ ì„ë² ë”©\n",
        "texts = [\n",
        "    'Hi there!',\n",
        "    'Oh, hello!',\n",
        "    \"What's your name?\",\n",
        "    'My friends call me World',\n",
        "    'Hello World!'\n",
        "]\n",
        "\n",
        "embeddings = model.embed_documents(texts)\n",
        "\n",
        "print(f\"ì„ë² ë”©ëœ ë¬¸ì„œ ìˆ˜: {len(embeddings)}\")\n",
        "print(f\"ê° ë²¡í„°ì˜ ì°¨ì›: {len(embeddings[0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_q4DCq_4-x0"
      },
      "source": [
        "# 4. ì„ë² ë”© ë²¡í„° í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "id": "19wEeN6w4-x1",
        "outputId": "596a5937-4c33-416d-a755-5ce6b362eb47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "í…ìŠ¤íŠ¸: 'Hi there!'\n",
            "ë²¡í„° (ì²˜ìŒ 10ê°œ): [0.020429805, -0.010229979, -0.177349, -0.0413164, 0.0508709, -0.0045323865, -0.030966198, 0.034292486, -0.016935103, -0.07356401]\n",
            "...\n",
            "ë²¡í„° (ë§ˆì§€ë§‰ 5ê°œ): [0.0132998945, -0.034147747, -0.029394977, -0.0061468175, -0.014125981]\n"
          ]
        }
      ],
      "source": [
        "# ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ì˜ ë²¡í„° (ì¼ë¶€ë§Œ ì¶œë ¥)\n",
        "print(f\"í…ìŠ¤íŠ¸: '{texts[0]}'\")\n",
        "print(f\"ë²¡í„° (ì²˜ìŒ 10ê°œ): {embeddings[0][:10]}\")\n",
        "print(f\"...\")\n",
        "print(f\"ë²¡í„° (ë§ˆì§€ë§‰ 5ê°œ): {embeddings[0][-5:]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMT528Se4-x1"
      },
      "source": [
        "# 5. ìœ ì‚¬ë„ ê³„ì‚°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "id": "fSw8jN9q4-x1",
        "outputId": "b002d7c6-24f2-4a55-e44c-90a07e3057ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== í…ìŠ¤íŠ¸ ê°„ ìœ ì‚¬ë„ ===\n",
            "'Hi there!' vs 'Oh, hello!': 0.7517\n",
            "'Hi there!' vs 'What's your name?': 0.5900\n",
            "'Hi there!' vs 'My friends call me World': 0.5899\n",
            "'Hi there!' vs 'Hello World!': 0.8568\n",
            "'Oh, hello!' vs 'What's your name?': 0.6113\n",
            "'Oh, hello!' vs 'My friends call me World': 0.5965\n",
            "'Oh, hello!' vs 'Hello World!': 0.7607\n",
            "'What's your name?' vs 'My friends call me World': 0.6831\n",
            "'What's your name?' vs 'Hello World!': 0.5879\n",
            "'My friends call me World' vs 'Hello World!': 0.6176\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "# ê° í…ìŠ¤íŠ¸ ìŒì˜ ìœ ì‚¬ë„ ê³„ì‚°\n",
        "print(\"=== í…ìŠ¤íŠ¸ ê°„ ìœ ì‚¬ë„ ===\")\n",
        "for i in range(len(texts)):\n",
        "    for j in range(i+1, len(texts)):\n",
        "        sim = cosine_similarity(embeddings[i], embeddings[j])\n",
        "        print(f\"'{texts[i]}' vs '{texts[j]}': {sim:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ4QnVll4-x1"
      },
      "source": [
        "# 6. ì¿¼ë¦¬ ì„ë² ë”© (ê²€ìƒ‰ìš©)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {
        "id": "zyPDOF7X4-x1",
        "outputId": "bf362e7e-9108-4293-918c-c13d1bd03927",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì¿¼ë¦¬: 'greeting'\n",
            "ì¿¼ë¦¬ ë²¡í„° ì°¨ì›: 768\n",
            "\n",
            "=== ì¿¼ë¦¬ì™€ ë¬¸ì„œ ìœ ì‚¬ë„ ===\n",
            "'Hi there!': 0.4996\n",
            "'Oh, hello!': 0.7707\n",
            "'What's your name?': 0.4498\n",
            "'My friends call me World': 0.4937\n",
            "'Hello World!': 0.4925\n"
          ]
        }
      ],
      "source": [
        "# ê²€ìƒ‰ ì¿¼ë¦¬ ì„ë² ë”©\n",
        "query = \"greeting\"\n",
        "query_embedding = model.embed_query(query)\n",
        "\n",
        "print(f\"ì¿¼ë¦¬: '{query}'\")\n",
        "print(f\"ì¿¼ë¦¬ ë²¡í„° ì°¨ì›: {len(query_embedding)}\")\n",
        "\n",
        "# ì¿¼ë¦¬ì™€ ê° ë¬¸ì„œì˜ ìœ ì‚¬ë„\n",
        "print(\"\\n=== ì¿¼ë¦¬ì™€ ë¬¸ì„œ ìœ ì‚¬ë„ ===\")\n",
        "for i, text in enumerate(texts):\n",
        "    sim = cosine_similarity(query_embedding, embeddings[i])\n",
        "    print(f\"'{text}': {sim:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeVU2fp14-x1"
      },
      "source": [
        "## ì½”ë“œ ë³€ê²½ì  (OpenAI â†’ Ollama)\n",
        "\n",
        "```python\n",
        "# ì›ë³¸ (OpenAI)\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "model = OpenAIEmbeddings(model='text-embedding-3-small')\n",
        "\n",
        "# ë³€ê²½ (Ollama)\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "model = OllamaEmbeddings(model='nomic-embed-text')\n",
        "```\n",
        "\n",
        "## Embedding ë©”ì„œë“œ\n",
        "\n",
        "| ë©”ì„œë“œ | ìš©ë„ |\n",
        "|--------|------|\n",
        "| `embed_documents([texts])` | ë¬¸ì„œë“¤ì„ ë²¡í„°ë¡œ ë³€í™˜ (ì €ì¥ìš©) |\n",
        "| `embed_query(text)` | ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ |\n",
        "\n",
        "## ë‹¤ìŒ ë‹¨ê³„\n",
        "\n",
        "ì„ë² ë”©ëœ ë²¡í„°ëŠ” **Vector Store**ì— ì €ì¥í•˜ì—¬ ìœ ì‚¬ë„ ê²€ìƒ‰ì— ì‚¬ìš©í•©ë‹ˆë‹¤. (09ë²ˆ ë…¸íŠ¸ë¶)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKLyt-zC4-x1"
      },
      "source": [
        "## ì½”ë“œ 2-8 Load â†’ Split â†’ Embed ì „ì²´ íŒŒì´í”„ë¼ì¸"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClyIFLLY4-x1"
      },
      "source": [
        "# Load â†’ Split â†’ Embed ì „ì²´ íŒŒì´í”„ë¼ì¸\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **ë¬¸ì„œ ë¡œë“œ â†’ ë¶„í•  â†’ ì„ë² ë”©**ê¹Œì§€ì˜ ì „ì²´ íë¦„ì„ ì—°ê²°í•˜ì—¬ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
        "\n",
        "## RAG ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  ğŸ“„ Load    â”‚ â”€â”€â–¶ â”‚  âœ‚ï¸ Split   â”‚ â”€â”€â–¶ â”‚  ğŸ”¢ Embed   â”‚ â”€â”€â–¶ â”‚  ğŸ’¾ Store   â”‚\n",
        "â”‚ TextLoader  â”‚     â”‚ TextSplitterâ”‚     â”‚  Embeddings â”‚     â”‚ VectorStore â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "    â†‘                    â†‘                    â†‘\n",
        "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "              ì´ ë…¸íŠ¸ë¶ì—ì„œ ë‹¤ë£¨ëŠ” ë²”ìœ„\n",
        "```\n",
        "\n",
        "\n",
        "# 1. Ollama ì„¤ì¹˜ ë° ì„œë²„ ì‹¤í–‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {
        "id": "RnkXRKJJ4-x1"
      },
      "outputs": [],
      "source": [
        "# OllamaëŠ” ìœ„ ì½”ë“œ 2-7ì—ì„œ ì´ë¯¸ ì„¤ì¹˜ ë° ì‹¤í–‰ ì™„ë£Œ\n",
        "# (Colab ëŸ°íƒ€ì„ì´ ì¬ì‹œì‘ëœ ê²½ìš° ì½”ë“œ 2-7ì˜ Ollama ì„¤ì¹˜ ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0Dps-jF4-x1"
      },
      "source": [
        "# 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {
        "id": "o5VTejnY4-x1"
      },
      "outputs": [],
      "source": [
        "# nomic-embed-textëŠ” ìœ„ ì½”ë“œ 2-7ì—ì„œ ì´ë¯¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\n",
        "# pip installì€ Cell 1ì—ì„œ ì„¤ì¹˜ ì™„ë£Œ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSzuS6bA4-x1"
      },
      "source": [
        "# 3. í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "id": "vJJAIN2F4-x1",
        "outputId": "eef27a4c-d894-4b40-b29a-e6504e7b8bbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test.txt ìƒì„± ì™„ë£Œ (423ì)\n"
          ]
        }
      ],
      "source": [
        "sample_text = '''LangChainì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì£¼ìš” ê¸°ëŠ¥:\n",
        "1. í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ë° ìµœì í™”\n",
        "2. ì²´ì¸ êµ¬ì„±ì„ í†µí•œ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ìƒì„±\n",
        "3. ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ì˜ ì—°ë™\n",
        "4. ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ í†µí•œ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€\n",
        "\n",
        "LangChainì„ ì‚¬ìš©í•˜ë©´ RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì„ ì‰½ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. RAGëŠ” ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•˜ì—¬ LLMì˜ ì‘ë‹µì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
        "\n",
        "Vector StoreëŠ” ì„ë² ë”©ëœ ë¬¸ì„œë¥¼ ì €ì¥í•˜ê³  ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤. ëŒ€í‘œì ìœ¼ë¡œ Chroma, Pinecone, PGVector ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì„ë² ë”©ì€ í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì˜ë¯¸ê°€ ë¹„ìŠ·í•œ í…ìŠ¤íŠ¸ëŠ” ë²¡í„° ê³µê°„ì—ì„œ ê°€ê¹Œìš´ ìœ„ì¹˜ì— ìˆìŠµë‹ˆë‹¤.\n",
        "'''\n",
        "\n",
        "with open('./test.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(sample_text)\n",
        "\n",
        "print(f\"test.txt ìƒì„± ì™„ë£Œ ({len(sample_text)}ì)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpBDPvub4-x1"
      },
      "source": [
        "# 4. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
        "\n",
        "## Step 1: ë¬¸ì„œ ë¡œë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {
        "id": "3k31iKhL4-x1",
        "outputId": "a3ab74ec-7b3b-45d2-afc0-55e04068c964",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Step 1: ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ\n",
            "   - ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: 1\n",
            "   - ì›ë³¸ ê¸¸ì´: 423ì\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "# ë¬¸ì„œ ë¡œë“œ\n",
        "loader = TextLoader('./test.txt', encoding='utf-8')\n",
        "doc = loader.load()\n",
        "\n",
        "print(f\"âœ… Step 1: ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ\")\n",
        "print(f\"   - ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(doc)}\")\n",
        "print(f\"   - ì›ë³¸ ê¸¸ì´: {len(doc[0].page_content)}ì\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6j3mAJb4-x1"
      },
      "source": [
        "## Step 2: ë¬¸ì„œ ë¶„í• "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {
        "id": "QP22AxZs4-x1",
        "outputId": "8064607f-0a14-486c-c398-15166351eb94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Step 2: ë¬¸ì„œ ë¶„í•  ì™„ë£Œ\n",
            "   - ë¶„í• ëœ ì²­í¬ ìˆ˜: 3\n",
            "   - ì²­í¬ í¬ê¸°: [149, 110, 159]\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# ë¬¸ì„œ ë¶„í• \n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=50\n",
        ")\n",
        "chunks = splitter.split_documents(doc)\n",
        "\n",
        "print(f\"\\nâœ… Step 2: ë¬¸ì„œ ë¶„í•  ì™„ë£Œ\")\n",
        "print(f\"   - ë¶„í• ëœ ì²­í¬ ìˆ˜: {len(chunks)}\")\n",
        "print(f\"   - ì²­í¬ í¬ê¸°: {[len(c.page_content) for c in chunks]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkMY67dt4-x1"
      },
      "source": [
        "## Step 3: ì„ë² ë”© ìƒì„±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "metadata": {
        "id": "hU80j3QE4-x1",
        "outputId": "051d0720-4b58-4e46-e679-8aebd4e707a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Step 3: ì„ë² ë”© ìƒì„± ì™„ë£Œ\n",
            "   - ì„ë² ë”© ìˆ˜: 3\n",
            "   - ë²¡í„° ì°¨ì›: 768\n"
          ]
        }
      ],
      "source": [
        "from langchain_ollama import OllamaEmbeddings\n",
        "\n",
        "# ì„ë² ë”© ëª¨ë¸ ìƒì„±\n",
        "embeddings_model = OllamaEmbeddings(model='nomic-embed-text')\n",
        "\n",
        "# ê° ì²­í¬ì˜ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©\n",
        "embeddings = embeddings_model.embed_documents(\n",
        "    [chunk.page_content for chunk in chunks]\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ… Step 3: ì„ë² ë”© ìƒì„± ì™„ë£Œ\")\n",
        "print(f\"   - ì„ë² ë”© ìˆ˜: {len(embeddings)}\")\n",
        "print(f\"   - ë²¡í„° ì°¨ì›: {len(embeddings[0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vE0v9to4-x1"
      },
      "source": [
        "# 5. ê²°ê³¼ í™•ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {
        "id": "XlZ9XY1f4-x1",
        "outputId": "07482823-3ffc-4e38-db37-3a39fbbdbeea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ì²­í¬-ì„ë² ë”© ë§¤í•‘ ===\n",
            "\n",
            "[ì²­í¬ 1]\n",
            "  í…ìŠ¤íŠ¸: LangChainì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬...\n",
            "  ë²¡í„°: [-0.0124, 0.0023, ..., -0.0694]\n",
            "\n",
            "[ì²­í¬ 2]\n",
            "  í…ìŠ¤íŠ¸: LangChainì„ ì‚¬ìš©í•˜ë©´ RAG(Retrieval-Augmented Generation...\n",
            "  ë²¡í„°: [-0.0096, 0.0637, ..., -0.0509]\n",
            "\n",
            "[ì²­í¬ 3]\n",
            "  í…ìŠ¤íŠ¸: Vector StoreëŠ” ì„ë² ë”©ëœ ë¬¸ì„œë¥¼ ì €ì¥í•˜ê³  ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤...\n",
            "  ë²¡í„°: [0.0232, 0.0238, ..., -0.0396]\n"
          ]
        }
      ],
      "source": [
        "# ì²­í¬ì™€ ì„ë² ë”© ë§¤í•‘ í™•ì¸\n",
        "print(\"=== ì²­í¬-ì„ë² ë”© ë§¤í•‘ ===\")\n",
        "for i, (chunk, emb) in enumerate(zip(chunks, embeddings)):\n",
        "    print(f\"\\n[ì²­í¬ {i+1}]\")\n",
        "    print(f\"  í…ìŠ¤íŠ¸: {chunk.page_content[:50]}...\")\n",
        "    print(f\"  ë²¡í„°: [{emb[0]:.4f}, {emb[1]:.4f}, ..., {emb[-1]:.4f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzZh_odn4-x1"
      },
      "source": [
        "## ì½”ë“œ ë³€ê²½ì  (OpenAI â†’ Ollama)\n",
        "\n",
        "```python\n",
        "# ì›ë³¸ (OpenAI)\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "embeddings_model = OpenAIEmbeddings(model='text-embedding-3-small')\n",
        "\n",
        "# ë³€ê²½ (Ollama)\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "embeddings_model = OllamaEmbeddings(model='nomic-embed-text')\n",
        "```\n",
        "\n",
        "## ì „ì²´ íŒŒì´í”„ë¼ì¸ ìš”ì•½\n",
        "\n",
        "```python\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "\n",
        "# 1. Load\n",
        "docs = TextLoader('./file.txt').load()\n",
        "\n",
        "# 2. Split\n",
        "chunks = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000, chunk_overlap=200\n",
        ").split_documents(docs)\n",
        "\n",
        "# 3. Embed\n",
        "embeddings = OllamaEmbeddings(model='nomic-embed-text').embed_documents(\n",
        "    [c.page_content for c in chunks]\n",
        ")\n",
        "```\n",
        "\n",
        "## ë‹¤ìŒ ë‹¨ê³„\n",
        "\n",
        "ìƒì„±ëœ ì„ë² ë”©ì„ **Vector Store**ì— ì €ì¥í•˜ì—¬ ìœ ì‚¬ë„ ê²€ìƒ‰ ê°€ëŠ¥í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤. (09ë²ˆ ë…¸íŠ¸ë¶)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WshbflXa4-x1"
      },
      "source": [
        "## ì½”ë“œ 2-9~2-12 PGVectorë¡œ ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶•í•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvK7vDO24-x1"
      },
      "source": [
        "# PGVectorë¡œ ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶•í•˜ê¸°\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **PGVector**(PostgreSQL + pgvector í™•ì¥)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë²¡í„° ì €ì¥ì†Œë¥¼ êµ¬ì¶•í•˜ê³  ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤.\n",
        "\n",
        "## RAG íŒŒì´í”„ë¼ì¸ì—ì„œì˜ ìœ„ì¹˜\n",
        "\n",
        "\n",
        "  ğŸ“„ Load     â”€â”€â–¶   âœ‚ï¸ Split    â”€â”€â–¶   ğŸ”¢ Embed    â”€â”€â–¶   ğŸ’¾ Store   \n",
        "  (ë¡œë“œ)             (ë¶„í• )               (ì„ë² ë”©)           (ì €ì¥)     \n",
        "                                                                  â†‘\n",
        "                                                               í˜„ì¬ ë‹¨ê³„\n",
        "```\n",
        "\n",
        "## Vector Storeë€?\n",
        "\n",
        "ì„ë² ë”© ë²¡í„°ë¥¼ ì €ì¥í•˜ê³  **ìœ ì‚¬ë„ ê²€ìƒ‰**ì„ ìˆ˜í–‰í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.\n",
        "\n",
        "## ì£¼ìš” Vector Store\n",
        "\n",
        "| Store | íŠ¹ì§• |\n",
        "|-------|------|\n",
        "| **PGVector** | PostgreSQL ê¸°ë°˜, SQL ì§€ì› |\n",
        "| Chroma | ê²½ëŸ‰, ë¡œì»¬ ê°œë°œì— ì í•© |\n",
        "| Pinecone | í´ë¼ìš°ë“œ ë§¤ë‹ˆì§€ë“œ |\n",
        "| Weaviate | ê·¸ë˜í”„ ê²€ìƒ‰ ì§€ì› |\n",
        "| FAISS | ê³ ì„±ëŠ¥, ë©”ëª¨ë¦¬ ê¸°ë°˜ |\n",
        "\n",
        "\n",
        "# 1. Dockerë¡œ PGVector ì‹¤í–‰\n",
        "\n",
        "ë¨¼ì € í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ PGVector ì»¨í…Œì´ë„ˆë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:\n",
        "\n",
        "```bash\n",
        "docker run \\\n",
        "    --name pgvector-container \\\n",
        "    -e POSTGRES_USER=langchain \\\n",
        "    -e POSTGRES_PASSWORD=langchain \\\n",
        "    -e POSTGRES_DB=langchain \\\n",
        "    -p 6024:5432 \\\n",
        "    -d pgvector/pgvector:pg16\n",
        "```\n",
        "\n",
        "> **âš ï¸ Google Colab ì‚¬ìš©ì:** Dockerë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, ì•„ë˜ ì½”ë“œ ì…€ì„ ì‹¤í–‰í•˜ì—¬ PostgreSQL + pgvectorë¥¼ ì§ì ‘ ì„¤ì¹˜í•˜ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {
        "id": "Vp2UrHtY4-x1",
        "outputId": "c1c5da49-17c6-4b31-ea2b-34ddde953a0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "fatal: destination path 'pgvector' already exists and is not an empty directory.\n",
            "make: Nothing to be done for 'all'.\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib'\n",
            "/bin/mkdir -p '/usr/share/postgresql/14/extension'\n",
            "/bin/mkdir -p '/usr/share/postgresql/14/extension'\n",
            "/usr/bin/install -c -m 755  vector.so '/usr/lib/postgresql/14/lib/vector.so'\n",
            "/usr/bin/install -c -m 644 .//vector.control '/usr/share/postgresql/14/extension/'\n",
            "/usr/bin/install -c -m 644 .//sql/vector--0.1.0--0.1.1.sql .//sql/vector--0.1.1--0.1.3.sql .//sql/vector--0.1.3--0.1.4.sql .//sql/vector--0.1.4--0.1.5.sql .//sql/vector--0.1.5--0.1.6.sql .//sql/vector--0.1.6--0.1.7.sql .//sql/vector--0.1.7--0.1.8.sql .//sql/vector--0.1.8--0.2.0.sql .//sql/vector--0.2.0--0.2.1.sql .//sql/vector--0.2.1--0.2.2.sql .//sql/vector--0.2.2--0.2.3.sql .//sql/vector--0.2.3--0.2.4.sql .//sql/vector--0.2.4--0.2.5.sql .//sql/vector--0.2.5--0.2.6.sql .//sql/vector--0.2.6--0.2.7.sql .//sql/vector--0.2.7--0.3.0.sql .//sql/vector--0.3.0--0.3.1.sql .//sql/vector--0.3.1--0.3.2.sql .//sql/vector--0.3.2--0.4.0.sql .//sql/vector--0.4.0--0.4.1.sql .//sql/vector--0.4.1--0.4.2.sql .//sql/vector--0.4.2--0.4.3.sql .//sql/vector--0.4.3--0.4.4.sql .//sql/vector--0.4.4--0.5.0.sql .//sql/vector--0.5.0--0.5.1.sql .//sql/vector--0.5.1--0.6.0.sql .//sql/vector--0.6.0--0.6.1.sql .//sql/vector--0.6.1--0.6.2.sql .//sql/vector--0.6.2--0.7.0.sql .//sql/vector--0.7.0--0.7.1.sql .//sql/vector--0.7.1--0.7.2.sql .//sql/vector--0.7.2--0.7.3.sql .//sql/vector--0.7.3--0.7.4.sql .//sql/vector--0.7.4--0.8.0.sql sql/vector--0.8.0.sql '/usr/share/postgresql/14/extension/'\n",
            "/bin/mkdir -p '/usr/include/postgresql/14/server/extension/vector/'\n",
            "/usr/bin/install -c -m 644   .//src/halfvec.h .//src/sparsevec.h .//src/vector.h '/usr/include/postgresql/14/server/extension/vector/'\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib/bitcode/vector'\n",
            "/bin/mkdir -p '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/bitutils.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/bitvec.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/halfutils.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/halfvec.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnsw.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswbuild.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswinsert.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswscan.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswutils.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/hnswvacuum.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfbuild.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfflat.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfinsert.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfkmeans.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfscan.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfutils.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/ivfvacuum.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/sparsevec.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "/usr/bin/install -c -m 644 src/vector.bc '/usr/lib/postgresql/14/lib/bitcode'/vector/src/\n",
            "cd '/usr/lib/postgresql/14/lib/bitcode' && /usr/lib/llvm-14/bin/llvm-lto -thinlto -thinlto-action=thinlink -o vector.index.bc vector/src/bitutils.bc vector/src/bitvec.bc vector/src/halfutils.bc vector/src/halfvec.bc vector/src/hnsw.bc vector/src/hnswbuild.bc vector/src/hnswinsert.bc vector/src/hnswscan.bc vector/src/hnswutils.bc vector/src/hnswvacuum.bc vector/src/ivfbuild.bc vector/src/ivfflat.bc vector/src/ivfinsert.bc vector/src/ivfkmeans.bc vector/src/ivfscan.bc vector/src/ivfutils.bc vector/src/ivfvacuum.bc vector/src/sparsevec.bc vector/src/vector.bc\n",
            " * Starting PostgreSQL 14 database server\n",
            "   ...done.\n",
            "ERROR:  role \"langchain\" already exists\n",
            "ERROR:  database \"langchain\" already exists\n",
            "NOTICE:  extension \"vector\" already exists, skipping\n",
            "CREATE EXTENSION\n",
            "ALTER ROLE\n",
            " * Restarting PostgreSQL 14 database server\n",
            "   ...done.\n",
            "             status             \n",
            "--------------------------------\n",
            " PostgreSQL ready on port 6024!\n",
            "(1 row)\n",
            "\n",
            "âœ… PostgreSQL + pgvector ì„¤ì¹˜ ë° ì‹¤í–‰ ì™„ë£Œ (í¬íŠ¸: 6024)\n"
          ]
        }
      ],
      "source": [
        "# [ì¶”ê°€] Colabì—ì„œ PostgreSQL + pgvector ì„¤ì¹˜ ë° ì‹¤í–‰ (Docker ëŒ€ì‹ )\n",
        "# ë¡œì»¬ì—ì„œ Dockerë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì´ ì…€ì„ ê±´ë„ˆë›°ì„¸ìš”.\n",
        "\n",
        "import subprocess\n",
        "\n",
        "# PostgreSQL ì„¤ì¹˜\n",
        "!sudo apt-get -qq update\n",
        "!sudo apt-get -qq install -y postgresql postgresql-server-dev-all\n",
        "\n",
        "# pgvector í™•ì¥ ì„¤ì¹˜ (ì†ŒìŠ¤ì—ì„œ ë¹Œë“œ)\n",
        "!cd /tmp && git clone --branch v0.8.0 https://github.com/pgvector/pgvector.git\n",
        "!cd /tmp/pgvector && make && sudo make install\n",
        "\n",
        "# PostgreSQL ì‹œì‘\n",
        "!sudo service postgresql start\n",
        "\n",
        "# langchain ì‚¬ìš©ì ë° DB ìƒì„±\n",
        "!sudo -u postgres psql -c \"CREATE USER langchain WITH PASSWORD 'langchain';\"\n",
        "!sudo -u postgres psql -c \"CREATE DATABASE langchain OWNER langchain;\"\n",
        "!sudo -u postgres psql -d langchain -c \"CREATE EXTENSION IF NOT EXISTS vector;\"\n",
        "!sudo -u postgres psql -c \"ALTER USER langchain WITH SUPERUSER;\"\n",
        "\n",
        "# í¬íŠ¸ë¥¼ 6024ë¡œ ë³€ê²½í•˜ê³  PostgreSQL ì¬ì‹œì‘\n",
        "!sudo sed -i \"s/^port = .*/port = 6024/\" /etc/postgresql/*/main/postgresql.conf\n",
        "\n",
        "# pg_hba.confì—ì„œ ë¡œì»¬ ì ‘ì† í—ˆìš©\n",
        "!sudo bash -c 'echo \"host all all 127.0.0.1/32 md5\" >> /etc/postgresql/*/main/pg_hba.conf'\n",
        "!sudo bash -c 'echo \"host all all ::1/128 md5\" >> /etc/postgresql/*/main/pg_hba.conf'\n",
        "\n",
        "# PostgreSQL ì¬ì‹œì‘\n",
        "!sudo service postgresql restart\n",
        "\n",
        "import time\n",
        "time.sleep(2)\n",
        "\n",
        "# ì—°ê²° í…ŒìŠ¤íŠ¸\n",
        "!PGPASSWORD=langchain psql -h localhost -p 6024 -U langchain -d langchain -c \"SELECT 'PostgreSQL ready on port 6024!' AS status;\"\n",
        "print('âœ… PostgreSQL + pgvector ì„¤ì¹˜ ë° ì‹¤í–‰ ì™„ë£Œ (í¬íŠ¸: 6024)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9xUO2dw4-x1"
      },
      "source": [
        "# 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAkwrNhy4-x1"
      },
      "source": [
        "# 3. Ollama ì„¤ì¹˜ ë° ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {
        "id": "E3Z_wyTp4-x1"
      },
      "outputs": [],
      "source": [
        "# OllamaëŠ” ìœ„ ì½”ë“œ 2-7ì—ì„œ ì´ë¯¸ ì„¤ì¹˜ ë° ì‹¤í–‰ ì™„ë£Œ\n",
        "# nomic-embed-text ëª¨ë¸ë„ ì´ë¯¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\n",
        "# (Colab ëŸ°íƒ€ì„ì´ ì¬ì‹œì‘ëœ ê²½ìš° ì½”ë“œ 2-7ì˜ Ollama ì„¤ì¹˜ ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk968-0p4-x1"
      },
      "source": [
        "# 4. í…ŒìŠ¤íŠ¸ íŒŒì¼ ì¤€ë¹„ ë° ë¬¸ì„œ ë¡œë“œ/ë¶„í• "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {
        "id": "tbN_6sls4-x2",
        "outputId": "2a8a3498-cccf-4e3b-e8d2-5441f88c12da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test.txt ìƒì„± ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "# í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±\n",
        "sample_text = '''LangChainì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
        "RAGëŠ” ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•˜ì—¬ LLMì˜ ì‘ë‹µì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
        "Vector StoreëŠ” ì„ë² ë”©ëœ ë¬¸ì„œë¥¼ ì €ì¥í•˜ê³  ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "'''\n",
        "\n",
        "with open('./test.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(sample_text)\n",
        "\n",
        "print(\"test.txt ìƒì„± ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {
        "id": "EAk37FJr4-x2",
        "outputId": "e2a46972-c4ab-4f51-889a-be0a7acdc91c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë¶„í• ëœ ë¬¸ì„œ ìˆ˜: 2\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• \n",
        "raw_documents = TextLoader('./test.txt', encoding='utf-8').load()\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
        "documents = text_splitter.split_documents(raw_documents)\n",
        "\n",
        "print(f\"ë¶„í• ëœ ë¬¸ì„œ ìˆ˜: {len(documents)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayBdYmmP4-x2"
      },
      "source": [
        "# 5. PGVectorì— ë¬¸ì„œ ì €ì¥\n",
        "\n",
        "**ì½”ë“œ ì„¤ëª…:**\n",
        "\n",
        "```python\n",
        "db = PGVector.from_documents(\n",
        "    documents,         # ì €ì¥í•  ë¬¸ì„œë“¤\n",
        "    embeddings_model,  # ì„ë² ë”© ëª¨ë¸\n",
        "    connection=connection  # DB ì—°ê²° ë¬¸ìì—´\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {
        "id": "upVBO1Ow4-x2",
        "outputId": "ca85b0e8-bacb-46f3-aaec-84d1580f9557",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ë¬¸ì„œê°€ PGVectorì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "from langchain_ollama import OllamaEmbeddings\n",
        "from langchain_postgres.vectorstores import PGVector\n",
        "\n",
        "# DB ì—°ê²° ì„¤ì •\n",
        "connection = 'postgresql+psycopg://langchain:langchain@localhost:6024/langchain'\n",
        "\n",
        "# ì„ë² ë”© ëª¨ë¸\n",
        "embeddings_model = OllamaEmbeddings(model='nomic-embed-text')\n",
        "\n",
        "# PGVectorì— ë¬¸ì„œ ì €ì¥\n",
        "db = PGVector.from_documents(\n",
        "    documents,\n",
        "    embeddings_model,\n",
        "    connection=connection\n",
        ")\n",
        "\n",
        "print(\"âœ… ë¬¸ì„œê°€ PGVectorì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KbJ2Bkc4-x2"
      },
      "source": [
        "# 6. ìœ ì‚¬ë„ ê²€ìƒ‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 306,
      "metadata": {
        "id": "LWprs1h54-x2",
        "outputId": "69476ed5-6e1f-4fd1-f03d-081382ede3d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì¿¼ë¦¬: 'RAGê°€ ë­”ê°€ìš”?'\n",
            "\n",
            "=== ê²€ìƒ‰ ê²°ê³¼ ===\n",
            "\n",
            "[1] Vector StoreëŠ” ì„ë² ë”©ëœ ë¬¸ì„œë¥¼ ì €ì¥í•˜ê³  ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
            "    metadata: {'source': './test.txt'}\n",
            "\n",
            "[2] Vector StoreëŠ” ì„ë² ë”©ëœ ë¬¸ì„œë¥¼ ì €ì¥í•˜ê³  ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
            "    metadata: {'source': './test.txt'}\n"
          ]
        }
      ],
      "source": [
        "# ìœ ì‚¬ë„ ê²€ìƒ‰\n",
        "query = 'RAGê°€ ë­”ê°€ìš”?'\n",
        "results = db.similarity_search(query, k=2)\n",
        "\n",
        "print(f\"ì¿¼ë¦¬: '{query}'\\n\")\n",
        "print(\"=== ê²€ìƒ‰ ê²°ê³¼ ===\")\n",
        "for i, doc in enumerate(results):\n",
        "    print(f\"\\n[{i+1}] {doc.page_content}\")\n",
        "    print(f\"    metadata: {doc.metadata}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxTOLgmS4-x2"
      },
      "source": [
        "# 7. ë¬¸ì„œ ì¶”ê°€ ë° ì‚­ì œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {
        "id": "4qobTJBj4-x2",
        "outputId": "ef685bb0-84e5-4c50-9e4b-5017d0d8589d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ë¬¸ì„œ 2ê°œ ì¶”ê°€ ì™„ë£Œ\n",
            "   IDs: ['3168e891-2361-411f-8cce-9d437ed6ab98', '87c12371-c57d-452b-bf98-293cb84cd714']\n"
          ]
        }
      ],
      "source": [
        "from langchain.docstore.document import Document\n",
        "import uuid\n",
        "\n",
        "# ìƒˆ ë¬¸ì„œ ì¶”ê°€\n",
        "ids = [str(uuid.uuid4()), str(uuid.uuid4())]\n",
        "\n",
        "new_docs = [\n",
        "    Document(\n",
        "        page_content='there are cats in the pond',\n",
        "        metadata={'location': 'pond', 'topic': 'animals'}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content='ducks are also found in the pond',\n",
        "        metadata={'location': 'pond', 'topic': 'animals'}\n",
        "    ),\n",
        "]\n",
        "\n",
        "db.add_documents(new_docs, ids=ids)\n",
        "print(f\"âœ… ë¬¸ì„œ 2ê°œ ì¶”ê°€ ì™„ë£Œ\")\n",
        "print(f\"   IDs: {ids}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 308,
      "metadata": {
        "id": "iSjbaK624-x2",
        "outputId": "80934870-9038-4608-cc32-a896a7feb4c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì¡°íšŒëœ ë¬¸ì„œ ìˆ˜: 2\n",
            "\n",
            "âœ… ë¬¸ì„œ ì‚­ì œ ì™„ë£Œ\n",
            "ì‚­ì œ í›„ ì¡°íšŒëœ ë¬¸ì„œ ìˆ˜: 2\n"
          ]
        }
      ],
      "source": [
        "# IDë¡œ ë¬¸ì„œ ì¡°íšŒ\n",
        "retrieved = db.get_by_ids(ids)\n",
        "print(f\"ì¡°íšŒëœ ë¬¸ì„œ ìˆ˜: {len(retrieved)}\")\n",
        "\n",
        "# ë¬¸ì„œ ì‚­ì œ\n",
        "db.delete({'ids': ids})\n",
        "print(f\"\\nâœ… ë¬¸ì„œ ì‚­ì œ ì™„ë£Œ\")\n",
        "\n",
        "# ì‚­ì œ í™•ì¸\n",
        "retrieved_after = db.get_by_ids(ids)\n",
        "print(f\"ì‚­ì œ í›„ ì¡°íšŒëœ ë¬¸ì„œ ìˆ˜: {len(retrieved_after)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTQEzvl84-x2"
      },
      "source": [
        "## ì½”ë“œ ë³€ê²½ì  (OpenAI â†’ Ollama)\n",
        "\n",
        "```python\n",
        "# ì›ë³¸ (OpenAI)\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "embeddings_model = OpenAIEmbeddings()\n",
        "\n",
        "# ë³€ê²½ (Ollama)\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "embeddings_model = OllamaEmbeddings(model='nomic-embed-text')\n",
        "```\n",
        "\n",
        "## PGVector ì£¼ìš” ë©”ì„œë“œ\n",
        "\n",
        "| ë©”ì„œë“œ | ì„¤ëª… |\n",
        "|--------|------|\n",
        "| `from_documents()` | ë¬¸ì„œë¡œ ë²¡í„° ì €ì¥ì†Œ ìƒì„± |\n",
        "| `similarity_search()` | ìœ ì‚¬ë„ ê²€ìƒ‰ |\n",
        "| `add_documents()` | ë¬¸ì„œ ì¶”ê°€ |\n",
        "| `delete()` | ë¬¸ì„œ ì‚­ì œ |\n",
        "| `get_by_ids()` | IDë¡œ ë¬¸ì„œ ì¡°íšŒ |\n",
        "\n",
        "## Retrieverë¡œ ë³€í™˜\n",
        "\n",
        "```python\n",
        "# RAG ì²´ì¸ì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ Retrieverë¡œ ë³€í™˜\n",
        "retriever = db.as_retriever(search_kwargs={'k': 4})\n",
        "docs = retriever.invoke('query')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpsEScSm4-x2"
      },
      "source": [
        "## ì½”ë“œ 2-13 SQLRecordManagerë¡œ ë¬¸ì„œ ì¸ë±ì‹± ê´€ë¦¬í•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCQtjExQ4-x2"
      },
      "source": [
        "# SQLRecordManagerë¡œ ë¬¸ì„œ ì¸ë±ì‹± ê´€ë¦¬í•˜ê¸°\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **SQLRecordManager**ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ì¸ë±ì‹±ì„ ê´€ë¦¬í•˜ê³  **ì¤‘ë³µ ë°©ì§€** ë° **ìë™ ì—…ë°ì´íŠ¸**ë¥¼ êµ¬í˜„í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤.\n",
        "\n",
        "## ì™œ Record Managerê°€ í•„ìš”í•œê°€?\n",
        "\n",
        "Vector Storeì— ë¬¸ì„œë¥¼ ë°˜ë³µ ì €ì¥í•˜ë©´:\n",
        "- ë™ì¼ ë¬¸ì„œê°€ **ì¤‘ë³µ ì €ì¥**ë¨\n",
        "- ìˆ˜ì •ëœ ë¬¸ì„œì˜ **ì´ì „ ë²„ì „ì´ ë‚¨ìŒ**\n",
        "- ì‚­ì œëœ ë¬¸ì„œê°€ **ì—¬ì „íˆ ê²€ìƒ‰**ë¨\n",
        "\n",
        "**Record Manager**ëŠ” ì´ëŸ° ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤:\n",
        "- ë¬¸ì„œ í•´ì‹œë¡œ ì¤‘ë³µ ê°ì§€\n",
        "- ë³€ê²½ëœ ë¬¸ì„œë§Œ ì—…ë°ì´íŠ¸\n",
        "- ì‚­ì œëœ ë¬¸ì„œ ìë™ ì •ë¦¬\n",
        "\n",
        "## cleanup ëª¨ë“œ\n",
        "\n",
        "| ëª¨ë“œ | ë™ì‘ |\n",
        "|------|------|\n",
        "| `None` | ì¤‘ë³µ í—ˆìš©, ì •ë¦¬ ì•ˆí•¨ |\n",
        "| `incremental` | ë™ì¼ sourceì˜ ì´ì „ ë²„ì „ ì‚­ì œ |\n",
        "| `full` | í˜„ì¬ ë°°ì¹˜ì— ì—†ëŠ” ëª¨ë“  ë¬¸ì„œ ì‚­ì œ |\n",
        "\n",
        "\n",
        "# 1. Dockerë¡œ PGVector ì‹¤í–‰\n",
        "\n",
        "```bash\n",
        "docker run \\\n",
        "    --name pgvector-container \\\n",
        "    -e POSTGRES_USER=langchain \\\n",
        "    -e POSTGRES_PASSWORD=langchain \\\n",
        "    -e POSTGRES_DB=langchain \\\n",
        "    -p 6024:5432 \\\n",
        "    -d pgvector/pgvector:pg16\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqlpkeSd4-x2"
      },
      "source": [
        "# 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° Ollama ì¤€ë¹„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 309,
      "metadata": {
        "id": "PmqWPi1t4-x2"
      },
      "outputs": [],
      "source": [
        "# OllamaëŠ” ìœ„ ì½”ë“œ 2-7ì—ì„œ ì´ë¯¸ ì„¤ì¹˜ ë° ì‹¤í–‰ ì™„ë£Œ\n",
        "# nomic-embed-text ëª¨ë¸ë„ ì´ë¯¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\n",
        "# (Colab ëŸ°íƒ€ì„ì´ ì¬ì‹œì‘ëœ ê²½ìš° ì½”ë“œ 2-7ì˜ Ollama ì„¤ì¹˜ ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9ysyi2I4-x2"
      },
      "source": [
        "# 3. Vector Store ë° Record Manager ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 310,
      "metadata": {
        "id": "GzPfXuk54-x2",
        "outputId": "7db07275-15ae-4649-ccf2-e5cde7b8e30a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Vector Storeì™€ Record Manager ì„¤ì • ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "# pip installì€ Cell 1ì—ì„œ ì„¤ì¹˜ ì™„ë£Œ\n",
        "\n",
        "from langchain.indexes import SQLRecordManager\n",
        "from langchain_core.indexing import index\n",
        "from langchain_postgres.vectorstores import PGVector\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "# ì„¤ì •\n",
        "connection = 'postgresql+psycopg://langchain:langchain@localhost:6024/langchain'\n",
        "collection_name = 'my_docs'\n",
        "namespace = 'my_docs_namespace'\n",
        "\n",
        "# ì„ë² ë”© ëª¨ë¸\n",
        "embeddings_model = OllamaEmbeddings(model='nomic-embed-text')\n",
        "\n",
        "# Vector Store\n",
        "vectorstore = PGVector(\n",
        "    embeddings=embeddings_model,\n",
        "    collection_name=collection_name,\n",
        "    connection=connection,\n",
        "    use_jsonb=True,\n",
        ")\n",
        "\n",
        "# Record Manager\n",
        "record_manager = SQLRecordManager(\n",
        "    namespace,\n",
        "    db_url=connection,\n",
        ")\n",
        "\n",
        "# ìŠ¤í‚¤ë§ˆ ìƒì„±\n",
        "record_manager.create_schema()\n",
        "\n",
        "print(\"âœ… Vector Storeì™€ Record Manager ì„¤ì • ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmJVGdQ64-x2"
      },
      "source": [
        "# 4. ë¬¸ì„œ ì¸ë±ì‹± (1íšŒì°¨)\n",
        "\n",
        "**ì½”ë“œ ì„¤ëª…:**\n",
        "\n",
        "```python\n",
        "index(\n",
        "    docs,              # ì¸ë±ì‹±í•  ë¬¸ì„œë“¤\n",
        "    record_manager,    # ë ˆì½”ë“œ ê´€ë¦¬ì\n",
        "    vectorstore,       # ë²¡í„° ì €ì¥ì†Œ\n",
        "    cleanup='incremental',  # ì •ë¦¬ ëª¨ë“œ\n",
        "    source_id_key='source', # ì¶œì²˜ ì‹ë³„ í‚¤\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {
        "id": "du-0MWrP4-x2",
        "outputId": "6ca3ec1a-a5a0-4faf-872c-45d57fb7f36f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ì¸ë±ì‹± 1íšŒì°¨ ===\n",
            "{'num_added': 1, 'num_updated': 0, 'num_skipped': 1, 'num_deleted': 1}\n"
          ]
        }
      ],
      "source": [
        "# ë¬¸ì„œ ìƒì„±\n",
        "docs = [\n",
        "    Document(\n",
        "        page_content='there are cats in the pond',\n",
        "        metadata={'id': 1, 'source': 'cats.txt'}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content='ducks are also found in the pond',\n",
        "        metadata={'id': 2, 'source': 'ducks.txt'}\n",
        "    ),\n",
        "]\n",
        "\n",
        "# 1íšŒì°¨ ì¸ë±ì‹±\n",
        "result_1 = index(\n",
        "    docs,\n",
        "    record_manager,\n",
        "    vectorstore,\n",
        "    cleanup='incremental',\n",
        "    source_id_key='source',\n",
        ")\n",
        "\n",
        "print(\"=== ì¸ë±ì‹± 1íšŒì°¨ ===\")\n",
        "print(result_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFk0il604-x2"
      },
      "source": [
        "# 5. ë™ì¼ ë¬¸ì„œ ì¬ì¸ë±ì‹± (2íšŒì°¨ - ì¤‘ë³µ ë°©ì§€)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {
        "id": "IfmnU7Qu4-x2",
        "outputId": "d480274b-ae13-4fda-b9af-1b544fc572c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ì¸ë±ì‹± 2íšŒì°¨ (ë™ì¼ ë¬¸ì„œ) ===\n",
            "{'num_added': 0, 'num_updated': 0, 'num_skipped': 2, 'num_deleted': 0}\n",
            "\n",
            "â†’ num_added=0: ì¤‘ë³µì´ ë°©ì§€ë¨!\n"
          ]
        }
      ],
      "source": [
        "# 2íšŒì°¨ ì¸ë±ì‹± - ë™ì¼ ë¬¸ì„œ\n",
        "result_2 = index(\n",
        "    docs,\n",
        "    record_manager,\n",
        "    vectorstore,\n",
        "    cleanup='incremental',\n",
        "    source_id_key='source',\n",
        ")\n",
        "\n",
        "print(\"=== ì¸ë±ì‹± 2íšŒì°¨ (ë™ì¼ ë¬¸ì„œ) ===\")\n",
        "print(result_2)\n",
        "print(\"\\nâ†’ num_added=0: ì¤‘ë³µì´ ë°©ì§€ë¨!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC25jLM04-x2"
      },
      "source": [
        "# 6. ë¬¸ì„œ ìˆ˜ì • í›„ ì¬ì¸ë±ì‹± (3íšŒì°¨ - ìë™ ì—…ë°ì´íŠ¸)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {
        "id": "rAcvSujZ4-x2",
        "outputId": "8ad18174-9a60-4ed8-de7a-74f50cc48b14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ì¸ë±ì‹± 3íšŒì°¨ (ìˆ˜ì •ëœ ë¬¸ì„œ) ===\n",
            "{'num_added': 1, 'num_updated': 0, 'num_skipped': 1, 'num_deleted': 1}\n",
            "\n",
            "â†’ num_added=1, num_deleted=1: ìˆ˜ì •ëœ ë¬¸ì„œê°€ ì—…ë°ì´íŠ¸ë¨!\n"
          ]
        }
      ],
      "source": [
        "# ë¬¸ì„œ ë‚´ìš© ìˆ˜ì •\n",
        "docs[0].page_content = 'I just modified this document!'\n",
        "\n",
        "# 3íšŒì°¨ ì¸ë±ì‹± - ìˆ˜ì •ëœ ë¬¸ì„œ\n",
        "result_3 = index(\n",
        "    docs,\n",
        "    record_manager,\n",
        "    vectorstore,\n",
        "    cleanup='incremental',\n",
        "    source_id_key='source',\n",
        ")\n",
        "\n",
        "print(\"=== ì¸ë±ì‹± 3íšŒì°¨ (ìˆ˜ì •ëœ ë¬¸ì„œ) ===\")\n",
        "print(result_3)\n",
        "print(\"\\nâ†’ num_added=1, num_deleted=1: ìˆ˜ì •ëœ ë¬¸ì„œê°€ ì—…ë°ì´íŠ¸ë¨!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rFQnDqg4-x2"
      },
      "source": [
        "## ì½”ë“œ ë³€ê²½ì  (OpenAI â†’ Ollama)\n",
        "\n",
        "```python\n",
        "# ì›ë³¸ (OpenAI)\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "embeddings_model = OpenAIEmbeddings(model='text-embedding-3-small')\n",
        "\n",
        "# ë³€ê²½ (Ollama)\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "embeddings_model = OllamaEmbeddings(model='nomic-embed-text')\n",
        "```\n",
        "\n",
        "## index() ë°˜í™˜ê°’\n",
        "\n",
        "```python\n",
        "{\n",
        "    'num_added': 2,      # ìƒˆë¡œ ì¶”ê°€ëœ ë¬¸ì„œ ìˆ˜\n",
        "    'num_updated': 0,    # ì—…ë°ì´íŠ¸ëœ ë¬¸ì„œ ìˆ˜\n",
        "    'num_skipped': 0,    # ìŠ¤í‚µëœ ë¬¸ì„œ ìˆ˜ (ì´ë¯¸ ì¡´ì¬)\n",
        "    'num_deleted': 0,    # ì‚­ì œëœ ë¬¸ì„œ ìˆ˜\n",
        "}\n",
        "```\n",
        "\n",
        "## cleanup ëª¨ë“œ ì„ íƒ ê°€ì´ë“œ\n",
        "\n",
        "| ìƒí™© | ì¶”ì²œ ëª¨ë“œ |\n",
        "|------|----------|\n",
        "| ë¬¸ì„œê°€ ìì£¼ ì—…ë°ì´íŠ¸ë¨ | `incremental` |\n",
        "| ì „ì²´ ë¬¸ì„œ ì„¸íŠ¸ë¥¼ êµì²´ | `full` |\n",
        "| ë‹¨ìˆœ ì¶”ê°€ë§Œ í•„ìš” | `None` |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHkgZMBj4-x2"
      },
      "source": [
        "## ì½”ë“œ 2-14 MultiVectorRetrieverë¡œ ìš”ì•½ ê¸°ë°˜ ê²€ìƒ‰ êµ¬í˜„í•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gof74KB4-x2"
      },
      "source": [
        "# MultiVectorRetrieverë¡œ ìš”ì•½ ê¸°ë°˜ ê²€ìƒ‰ êµ¬í˜„í•˜ê¸°\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **MultiVectorRetriever**ë¥¼ ì‚¬ìš©í•˜ì—¬ **ìš”ì•½ìœ¼ë¡œ ê²€ìƒ‰**í•˜ê³  **ì›ë³¸ ë¬¸ì„œë¥¼ ë°˜í™˜**í•˜ëŠ” ê³ ê¸‰ RAG íŒ¨í„´ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
        "\n",
        "## ì¼ë°˜ ê²€ìƒ‰ vs MultiVector ê²€ìƒ‰\n",
        "\n",
        "| ë°©ì‹ | ê²€ìƒ‰ ëŒ€ìƒ | ë°˜í™˜ ê²°ê³¼ |\n",
        "|------|----------|----------|\n",
        "| **ì¼ë°˜** | ì›ë³¸ ì²­í¬ | ì›ë³¸ ì²­í¬ |\n",
        "| **MultiVector** | ìš”ì•½/ì„ë² ë”© | ì›ë³¸ ë¬¸ì„œ |\n",
        "\n",
        "## MultiVectorRetrieverì˜ ì¥ì \n",
        "\n",
        "1. **ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ**: ìš”ì•½ì´ í•µì‹¬ ë‚´ìš©ì„ ë‹´ì•„ ê²€ìƒ‰ í’ˆì§ˆ ê°œì„ \n",
        "2. **í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸**: ê²€ìƒ‰ì€ ìš”ì•½ìœ¼ë¡œ, ì‘ë‹µì€ ì „ì²´ ë¬¸ì„œë¡œ\n",
        "3. **ìœ ì—°í•œ ì €ì¥**: ë²¡í„° ì €ì¥ì†Œ + ë¬¸ì„œ ì €ì¥ì†Œ ë¶„ë¦¬\n",
        "\n",
        "## ì•„í‚¤í…ì²˜\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                    MultiVectorRetriever                    â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚     Vector Store        â”‚         Document Store           â”‚\n",
        "â”‚   (ìš”ì•½ ì„ë² ë”© ì €ì¥)      â”‚       (ì›ë³¸ ë¬¸ì„œ ì €ì¥)            â”‚\n",
        "â”‚                         â”‚                                   â”‚\n",
        "â”‚   ìš”ì•½1 â†’ [ë²¡í„°]         â”‚   doc_id_1 â†’ ì›ë³¸ ë¬¸ì„œ 1          â”‚\n",
        "â”‚   ìš”ì•½2 â†’ [ë²¡í„°]         â”‚   doc_id_2 â†’ ì›ë³¸ ë¬¸ì„œ 2          â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "            â”‚                           â”‚\n",
        "            â”‚  1. ì¿¼ë¦¬ë¡œ ìš”ì•½ ê²€ìƒ‰        â”‚  2. doc_idë¡œ ì›ë³¸ ì¡°íšŒ\n",
        "            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "\n",
        "# 1. Dockerë¡œ PGVector ì‹¤í–‰\n",
        "\n",
        "```bash\n",
        "docker run --name pgvector-container \\\n",
        "    -e POSTGRES_USER=langchain -e POSTGRES_PASSWORD=langchain \\\n",
        "    -e POSTGRES_DB=langchain -p 6024:5432 -d pgvector/pgvector:pg16\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HRhtROy4-x2"
      },
      "source": [
        "# 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° Ollama ì¤€ë¹„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {
        "id": "UUHit8oV4-x2"
      },
      "outputs": [],
      "source": [
        "# OllamaëŠ” ìœ„ ì½”ë“œ 2-7ì—ì„œ ì´ë¯¸ ì„¤ì¹˜ ë° ì‹¤í–‰ ì™„ë£Œ\n",
        "# llama3.2, nomic-embed-text ëª¨ë¸ë„ ì´ë¯¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\n",
        "# (Colab ëŸ°íƒ€ì„ì´ ì¬ì‹œì‘ëœ ê²½ìš° ì½”ë“œ 2-7ì˜ Ollama ì„¤ì¹˜ ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgdRgigw4-x2"
      },
      "source": [
        "# 3. í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ì¤€ë¹„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {
        "id": "ekdoeFHw4-x2",
        "outputId": "0bf20006-9546-4eac-aa7c-2515a71a089a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test.txt ìƒì„± ì™„ë£Œ (336ì)\n"
          ]
        }
      ],
      "source": [
        "sample_text = '''LangChainì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
        "í”„ë¡¬í”„íŠ¸ ê´€ë¦¬, ì²´ì¸ êµ¬ì„±, ë°ì´í„° ì—°ë™ ë“± ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "RAG(Retrieval-Augmented Generation)ëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„± ê¸°ìˆ ë¡œ, ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•˜ì—¬ LLMì˜ ì‘ë‹µì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n",
        "Vector Storeì— ë¬¸ì„œë¥¼ ì €ì¥í•˜ê³  ìœ ì‚¬ë„ ê²€ìƒ‰ì„ í†µí•´ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
        "\n",
        "Embeddingì€ í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì˜ë¯¸ê°€ ë¹„ìŠ·í•œ í…ìŠ¤íŠ¸ëŠ” ë²¡í„° ê³µê°„ì—ì„œ ê°€ê¹Œìš´ ìœ„ì¹˜ì— ìˆìŠµë‹ˆë‹¤.\n",
        "OpenAI, Ollama ë“± ë‹¤ì–‘í•œ ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "'''\n",
        "\n",
        "with open('./test.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(sample_text)\n",
        "\n",
        "print(f\"test.txt ìƒì„± ì™„ë£Œ ({len(sample_text)}ì)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqk_m2yW4-x3"
      },
      "source": [
        "# 4. ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {
        "id": "ixsqBmLe4-x3",
        "outputId": "34a1df67-0cd5-4abf-c557-6f5a8124b3cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì›ë³¸ ë¬¸ì„œ ê¸¸ì´: 336ì\n",
            "ë¶„í• ëœ ì²­í¬ ìˆ˜: 3\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# ë¬¸ì„œ ë¡œë“œ\n",
        "loader = TextLoader('./test.txt', encoding='utf-8')\n",
        "docs = loader.load()\n",
        "\n",
        "# ë¬¸ì„œ ë¶„í• \n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50)\n",
        "chunks = splitter.split_documents(docs)\n",
        "\n",
        "print(f\"ì›ë³¸ ë¬¸ì„œ ê¸¸ì´: {len(docs[0].page_content)}ì\")\n",
        "print(f\"ë¶„í• ëœ ì²­í¬ ìˆ˜: {len(chunks)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRlN0Rr-4-x3"
      },
      "source": [
        "# 5. ê° ì²­í¬ì˜ ìš”ì•½ ìƒì„±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {
        "id": "_gq2I7iV4-x3",
        "outputId": "bf2c7899-d318-4ff7-acf9-cea88f59407c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ìƒì„±ëœ ìš”ì•½ ===\n",
            "\n",
            "[ì²­í¬ 1] LangChainì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ë¡œ, í”„ë¡¬í”„íŠ¸ ê´€ë¦¬, ì²´ì¸ êµ¬ì„±, ë°ì´í„° ì—°ë™ ë“±ì˜ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
            "\n",
            "[ì²­í¬ 2] RAG(Retrieval-Augmented Generation)ëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„± ê¸°ìˆ ë¡œ, ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•˜ì—¬ Large Language Model (LLM)ì˜ ì‘ë‹µì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
            "\n",
            "[ì²­í¬ 3] Embeddingì€ í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ìœ¼ë¡œ, ì˜ë¯¸ê°€ ë¹„ìŠ·í•œ í…ìŠ¤íŠ¸ê°€ ë²¡í„° ê³µê°„ì—ì„œ ê°€ê¹Œìš´ ìœ„ì¹˜ì— ìœ„ì¹˜í•˜ê²Œ ë©ë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# ìš”ì•½ ì²´ì¸ ìƒì„±\n",
        "prompt = ChatPromptTemplate.from_template('ë‹¤ìŒ ë¬¸ì„œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”:\\n\\n{doc}')\n",
        "llm = ChatOllama(model='llama3.2', temperature=0)\n",
        "\n",
        "summarize_chain = {'doc': lambda x: x.page_content} | prompt | llm | StrOutputParser()\n",
        "\n",
        "# ê° ì²­í¬ ìš”ì•½ ìƒì„±\n",
        "summaries = summarize_chain.batch(chunks, {'max_concurrency': 2})\n",
        "\n",
        "print(\"=== ìƒì„±ëœ ìš”ì•½ ===\")\n",
        "for i, summary in enumerate(summaries):\n",
        "    print(f\"\\n[ì²­í¬ {i+1}] {summary}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FN1Uugk4-x3"
      },
      "source": [
        "# 6. MultiVectorRetriever ì„¤ì •"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {
        "id": "2bymVJRz4-x3",
        "outputId": "ef47e2e0-86ca-4da7-a07f-67ef24aab0fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… MultiVectorRetriever ì„¤ì • ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "from langchain_ollama import OllamaEmbeddings\n",
        "from langchain_postgres.vectorstores import PGVector\n",
        "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain.docstore.document import Document\n",
        "import uuid\n",
        "\n",
        "# ì„¤ì •\n",
        "connection = 'postgresql+psycopg://langchain:langchain@localhost:6024/langchain'\n",
        "collection_name = 'summaries'\n",
        "id_key = 'doc_id'\n",
        "\n",
        "# ì„ë² ë”© ëª¨ë¸\n",
        "embeddings_model = OllamaEmbeddings(model='nomic-embed-text')\n",
        "\n",
        "# Vector Store (ìš”ì•½ ì €ì¥)\n",
        "vectorstore = PGVector(\n",
        "    embeddings=embeddings_model,\n",
        "    collection_name=collection_name,\n",
        "    connection=connection,\n",
        "    use_jsonb=True,\n",
        ")\n",
        "\n",
        "# Document Store (ì›ë³¸ ì €ì¥)\n",
        "store = InMemoryStore()\n",
        "\n",
        "# MultiVectorRetriever ìƒì„±\n",
        "retriever = MultiVectorRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    docstore=store,\n",
        "    id_key=id_key,\n",
        ")\n",
        "\n",
        "print(\"âœ… MultiVectorRetriever ì„¤ì • ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ06Ou1W4-x3"
      },
      "source": [
        "# 7. ìš”ì•½ê³¼ ì›ë³¸ ë¬¸ì„œ ì €ì¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {
        "id": "pPMAM11Y4-x3",
        "outputId": "f843180c-c769-409e-9da6-c988b47ef9d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ìš”ì•½ 3ê°œ â†’ Vector Store\n",
            "âœ… ì›ë³¸ 3ê°œ â†’ Document Store\n"
          ]
        }
      ],
      "source": [
        "# ê° ì²­í¬ì— ê³ ìœ  ID ë¶€ì—¬\n",
        "doc_ids = [str(uuid.uuid4()) for _ in chunks]\n",
        "\n",
        "# ìš”ì•½ ë¬¸ì„œ ìƒì„± (doc_idë¡œ ì›ë³¸ê³¼ ì—°ê²°)\n",
        "summary_docs = [\n",
        "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
        "    for i, s in enumerate(summaries)\n",
        "]\n",
        "\n",
        "# Vector Storeì— ìš”ì•½ ì €ì¥\n",
        "retriever.vectorstore.add_documents(summary_docs)\n",
        "\n",
        "# Document Storeì— ì›ë³¸ ì €ì¥\n",
        "retriever.docstore.mset(list(zip(doc_ids, chunks)))\n",
        "\n",
        "print(f\"âœ… ìš”ì•½ {len(summary_docs)}ê°œ â†’ Vector Store\")\n",
        "print(f\"âœ… ì›ë³¸ {len(chunks)}ê°œ â†’ Document Store\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfbMuuc94-x3"
      },
      "source": [
        "# 8. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {
        "id": "HHqT7Z3z4-x3",
        "outputId": "168491c9-ba74-49ac-d451-141464a812c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Vector Store ê²€ìƒ‰ ê²°ê³¼ (ìš”ì•½) ===\n",
            "[1] RAG(Retrieval-Augmented Generation)ëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„± ê¸°ìˆ ë¡œ, ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•˜ì—¬ Large Language Model (LLM)ì˜ ì‘ë‹µì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
            "    ê¸¸ì´: 107ì\n",
            "[2] RAG(Retrieval-Augmented Generation)ëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„± ê¸°ìˆ ë¡œ, ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•˜ì—¬ Large Language Model (LLM)ì˜ ì‘ë‹µì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
            "    ê¸¸ì´: 107ì\n"
          ]
        }
      ],
      "source": [
        "query = 'RAGê°€ ë­”ê°€ìš”?'\n",
        "\n",
        "# Vector Storeì—ì„œ ìš”ì•½ ê²€ìƒ‰\n",
        "sub_docs = retriever.vectorstore.similarity_search(query, k=2)\n",
        "\n",
        "print(\"=== Vector Store ê²€ìƒ‰ ê²°ê³¼ (ìš”ì•½) ===\")\n",
        "for i, doc in enumerate(sub_docs):\n",
        "    print(f\"[{i+1}] {doc.page_content}\")\n",
        "    print(f\"    ê¸¸ì´: {len(doc.page_content)}ì\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {
        "id": "yhKXqIe84-x3",
        "outputId": "e2a95763-808d-4dd6-d040-403c33bd1c8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Retriever ê²€ìƒ‰ ê²°ê³¼ (ì›ë³¸) ===\n"
          ]
        }
      ],
      "source": [
        "# MultiVectorRetrieverë¡œ ê²€ìƒ‰ (ì›ë³¸ ë°˜í™˜)\n",
        "retrieved_docs = retriever.invoke(query)\n",
        "\n",
        "print(\"\\n=== Retriever ê²€ìƒ‰ ê²°ê³¼ (ì›ë³¸) ===\")\n",
        "for i, doc in enumerate(retrieved_docs):\n",
        "    print(f\"\\n[{i+1}] {doc.page_content}\")\n",
        "    print(f\"    ê¸¸ì´: {len(doc.page_content)}ì\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSNridUu4-x3"
      },
      "source": [
        "## ì½”ë“œ ë³€ê²½ì  (OpenAI â†’ Ollama)\n",
        "\n",
        "```python\n",
        "# ì›ë³¸ (OpenAI)\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "embeddings_model = OpenAIEmbeddings()\n",
        "llm = ChatOpenAI(temperature=0, model='gpt-4o-mini')\n",
        "\n",
        "# ë³€ê²½ (Ollama)\n",
        "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
        "embeddings_model = OllamaEmbeddings(model='nomic-embed-text')\n",
        "llm = ChatOllama(model='llama3.2', temperature=0)\n",
        "```\n",
        "\n",
        "## MultiVectorRetriever í™œìš© íŒ¨í„´\n",
        "\n",
        "| íŒ¨í„´ | Vector Store ì €ì¥ | Document Store ì €ì¥ |\n",
        "|------|------------------|--------------------|\n",
        "| **ìš”ì•½ ê¸°ë°˜** | ë¬¸ì„œ ìš”ì•½ | ì›ë³¸ ë¬¸ì„œ |\n",
        "| **ì§ˆë¬¸ ê¸°ë°˜** | ê°€ìƒ ì§ˆë¬¸ë“¤ | ì›ë³¸ ë¬¸ì„œ |\n",
        "| **ì‘ì€ ì²­í¬** | ì‘ì€ ì²­í¬ | í° ì²­í¬/ì „ì²´ ë¬¸ì„œ |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnnkMP9O4-x3"
      },
      "source": [
        "## ì½”ë“œ 2-15 RAGatouille + ColBERTë¡œ ê³ ê¸‰ ê²€ìƒ‰ êµ¬í˜„í•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJvg2Jwe4-x3"
      },
      "source": [
        "# RAGatouille + ColBERTë¡œ ê³ ê¸‰ ê²€ìƒ‰ êµ¬í˜„í•˜ê¸°\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **RAGatouille**ê³¼ **ColBERT** ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê³ ê¸‰ ê²€ìƒ‰ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤.\n",
        "\n",
        "## ColBERTë€?\n",
        "\n",
        "**ColBERT**(Contextualized Late Interaction over BERT)ëŠ” íš¨ìœ¨ì ì¸ ë¬¸ì„œ ê²€ìƒ‰ì„ ìœ„í•œ ì‹ ê²½ë§ ëª¨ë¸ì…ë‹ˆë‹¤.\n",
        "\n",
        "### ì¼ë°˜ ì„ë² ë”© vs ColBERT\n",
        "\n",
        "| ë°©ì‹ | ì„ë² ë”© | ê²€ìƒ‰ ë°©ì‹ |\n",
        "|------|--------|----------|\n",
        "| **ì¼ë°˜** | ë¬¸ì„œ â†’ ë‹¨ì¼ ë²¡í„° | ë²¡í„° ìœ ì‚¬ë„ |\n",
        "| **ColBERT** | ë¬¸ì„œ â†’ í† í°ë³„ ë²¡í„° | Late Interaction |\n",
        "\n",
        "### ColBERTì˜ ì¥ì \n",
        "\n",
        "1. **ë†’ì€ ì •í™•ë„**: í† í° ìˆ˜ì¤€ ë§¤ì¹­ìœ¼ë¡œ ì„¸ë°€í•œ ê²€ìƒ‰\n",
        "2. **íš¨ìœ¨ì„±**: ì‚¬ì „ ê³„ì‚°ëœ ì„ë² ë”©ìœ¼ë¡œ ë¹ ë¥¸ ê²€ìƒ‰\n",
        "3. **ì„¤ëª… ê°€ëŠ¥ì„±**: ì–´ë–¤ í† í°ì´ ë§¤ì¹­ë˜ì—ˆëŠ”ì§€ í™•ì¸ ê°€ëŠ¥\n",
        "\n",
        "## RAGatouilleì´ë€?\n",
        "\n",
        "ColBERTë¥¼ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” Python ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\n",
        "\n",
        "```python\n",
        "from ragatouille import RAGPretrainedModel\n",
        "\n",
        "RAG = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
        "```\n",
        "\n",
        "## ì£¼ì˜ì‚¬í•­\n",
        "\n",
        "- **Windows ë¯¸ì§€ì›**\n",
        "- Python ì „ìš©\n",
        "- GPU ê¶Œì¥ (CPUë„ ê°€ëŠ¥í•˜ì§€ë§Œ ëŠë¦¼)\n",
        "\n",
        "\n",
        "# 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JG-5dmZ4-x3"
      },
      "source": [
        "# 2. ColBERT ëª¨ë¸ ë¡œë“œ"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ragatouille ì„¤ì¹˜\n",
        "!pip install -q ragatouille\n",
        "\n",
        "# [ì¶”ê°€] langchain ë²„ì „ ì¬ê³ ì • (ragatouilleê°€ ë‹¤ìš´ê·¸ë ˆì´ë“œí•œ ê²½ìš° ë³µì›)\n",
        "!pip install -q \\\n",
        "    langchain==0.3.25 \\\n",
        "    langchain-community==0.3.25 \\\n",
        "    langchain-core==0.3.83"
      ],
      "metadata": {
        "id": "y0PM8SdNMjRj"
      },
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {
        "id": "1tL1nqXg4-x3",
        "outputId": "70808476-f7fc-4de2-d8bd-e2573aa1bb67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482,
          "referenced_widgets": [
            "2c86afdf31d14eabbd18d82e960875ac",
            "aa7f744022db4cf08b0d21fac5fee7f5",
            "780ab5593f124efe8b7519ccc80c9764",
            "f1c41cd5249e4582b6d02ba80057913b",
            "f0ad5b08787f41029ea2eec8b59e6ce4",
            "fb50060fe9014c2a8a7777345ff3d7d9",
            "81d45f5dab8042a39236b39e78b195f7",
            "8601a170577f4223b0a6463e894931a9",
            "6efa39216f364e3da7b3da047e371af3",
            "115c1b38426f476f8ca8927c66dbcf9d",
            "aaa851529fee496d900cae06f021abc9",
            "80327176e4bd4631971883a8660e291a",
            "ff5af81b7ba54e39baba1cefce8ca0ef",
            "7e79a2f2632240d0ad888985516b35c6",
            "b42b70ebea1e497b9334d2b5f5b1ea51",
            "370515ffecdf4d95adf331485d7f1704",
            "f8f3c06cb34c45f0a78c343daa67f858",
            "8b3da599406341d3a00aedce583329eb",
            "a0f598a84a9549eb89addc430bf9e656",
            "8048d34ffe15410f99b2bf9e5dd2d6a5",
            "3ba9621dfdd04ffcb3a740ed855b1140",
            "25b5a9e2a8e84e1fa0fe0e8cd05faac7"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c86afdf31d14eabbd18d82e960875ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80327176e4bd4631971883a8660e291a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'keys'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2963506495.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mRAG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRAGPretrainedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"colbert-ir/colbertv2.0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ragatouille/RAGPretrainedModel.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, n_gpu, verbose, index_root)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         instance.model = ColBERT(\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ragatouille/models/colbert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pretrained_model_name_or_path, n_gpu, index_name, verbose, load_from_index, training_mode, index_root, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtraining_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             self.inference_ckpt = Checkpoint(\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolbert_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/colbert/modeling/checkpoint.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, colbert_config, verbose)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolbert_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolbert_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/colbert/modeling/colbert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, colbert_config)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolbert_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolbert_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolbert_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_visible_gpus\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/colbert/modeling/base_colbert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_path, colbert_config)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHF_ColBERT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolbert_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolbert_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/colbert/modeling/hf_colbert.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, name_or_path, colbert_config)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolbert_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolbert_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4109\u001b[0m             \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4110\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_safetensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4111\u001b[0m             \u001b[0mparam_device_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_device_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_loaded_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_finalize_load_state_dict\u001b[0;34m(model, load_config, load_info)\u001b[0m\n\u001b[1;32m   4263\u001b[0m                     \u001b[0;34m\"\\n\\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4264\u001b[0;31m                 )\n\u001b[0m\u001b[1;32m   4265\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error(s) in loading state_dict for {model.__class__.__name__}:\\n\\t{error_msg}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mmark_tied_weights_as_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4586\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstart_positions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4587\u001b[0;31m             \u001b[0mslen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhsz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4588\u001b[0m             \u001b[0mstart_positions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_positions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhsz\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape (bsz, 1, hsz)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1963\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1965\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'HF_ColBERT' object has no attribute 'all_tied_weights_keys'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2963506495.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPreTrainedModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'all_tied_weights_keys'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPreTrainedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_tied_weights_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mRAG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRAGPretrainedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"colbert-ir/colbertv2.0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âœ… ColBERT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ragatouille/RAGPretrainedModel.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, n_gpu, verbose, index_root)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \"\"\"\n\u001b[1;32m     70\u001b[0m         \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         instance.model = ColBERT(\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ragatouille/models/colbert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pretrained_model_name_or_path, n_gpu, index_name, verbose, load_from_index, training_mode, index_root, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtraining_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             self.inference_ckpt = Checkpoint(\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolbert_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/colbert/modeling/checkpoint.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, colbert_config, verbose)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolbert_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolbert_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/colbert/modeling/colbert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, colbert_config)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolbert_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolbert_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolbert_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_visible_gpus\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/colbert/modeling/base_colbert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_path, colbert_config)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# HF_ColBERT = class_factory(self.name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHF_ColBERT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolbert_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolbert_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/colbert/modeling/hf_colbert.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, name_or_path, colbert_config)\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolbert_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolbert_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4108\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4109\u001b[0m             \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4110\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_safetensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4111\u001b[0m             \u001b[0mparam_device_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_device_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_loaded_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4112\u001b[0m             \u001b[0mstr_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torch.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_finalize_load_state_dict\u001b[0;34m(model, load_config, load_info)\u001b[0m\n\u001b[1;32m   4262\u001b[0m                 error_msg += (\n\u001b[1;32m   4263\u001b[0m                     \u001b[0;34m\"\\n\\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4264\u001b[0;31m                 )\n\u001b[0m\u001b[1;32m   4265\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error(s) in loading state_dict for {model.__class__.__name__}:\\n\\t{error_msg}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mmark_tied_weights_as_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4585\u001b[0m         ), \"One of start_states, start_positions should be not None\"\n\u001b[1;32m   4586\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstart_positions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4587\u001b[0;31m             \u001b[0mslen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhsz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4588\u001b[0m             \u001b[0mstart_positions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_positions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhsz\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape (bsz, 1, hsz)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4589\u001b[0m             \u001b[0mstart_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_positions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape (bsz, 1, hsz)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"
          ]
        }
      ],
      "source": [
        "from ragatouille import RAGPretrainedModel\n",
        "\n",
        "# ColBERT v2 ëª¨ë¸ ë¡œë“œ\n",
        "try:\n",
        "    RAG = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
        "except AttributeError:\n",
        "    # [ìˆ˜ì •] transformers ë²„ì „ í˜¸í™˜ì„± ë¬¸ì œ í•´ê²° (ë¶€ëª¨ í´ë˜ìŠ¤ì— ëˆ„ë½ ì†ì„± ì¶”ê°€)\n",
        "    import transformers\n",
        "    if not hasattr(transformers.PreTrainedModel, 'all_tied_weights_keys'):\n",
        "        transformers.PreTrainedModel.all_tied_weights_keys = []\n",
        "    RAG = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
        "\n",
        "print(\"âœ… ColBERT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nznCY8j24-x3"
      },
      "source": [
        "# 3. ìœ„í‚¤ë°±ê³¼ì—ì„œ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nq0mVG_X4-x3"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def get_wikipedia_page(title: str):\n",
        "    \"\"\"\n",
        "    ìœ„í‚¤ë°±ê³¼ì˜ í˜ì´ì§€ë¥¼ ë¶ˆëŸ¬ì˜¨ë‹¤.\n",
        "\n",
        "    :param title: ìœ„í‚¤ë°±ê³¼ í˜ì´ì§€ì˜ ì œëª©\n",
        "    :return: í˜ì´ì§€ì˜ ì „ì²´ í…ìŠ¤íŠ¸\n",
        "    \"\"\"\n",
        "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
        "\n",
        "    params = {\n",
        "        \"action\": \"query\",\n",
        "        \"format\": \"json\",\n",
        "        \"titles\": title,\n",
        "        \"prop\": \"extracts\",\n",
        "        \"explaintext\": True,\n",
        "    }\n",
        "\n",
        "    headers = {\"User-Agent\": \"RAGatouille_tutorial/0.0.1\"}\n",
        "\n",
        "    response = requests.get(URL, params=params, headers=headers)\n",
        "    data = response.json()\n",
        "\n",
        "    page = next(iter(data[\"query\"][\"pages\"].values()))\n",
        "    return page[\"extract\"] if \"extract\" in page else None\n",
        "\n",
        "# ë¯¸ì•¼ìí‚¤ í•˜ì•¼ì˜¤ ìœ„í‚¤ë°±ê³¼ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°\n",
        "full_document = get_wikipedia_page(\"Hayao_Miyazaki\")\n",
        "\n",
        "print(f\"ë¬¸ì„œ ê¸¸ì´: {len(full_document)}ì\")\n",
        "print(f\"\\në¯¸ë¦¬ë³´ê¸°:\\n{full_document[:500]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLQG03Fr4-x3"
      },
      "source": [
        "# 4. ì¸ë±ìŠ¤ ìƒì„±\n",
        "\n",
        "**ì½”ë“œ ì„¤ëª…:**\n",
        "\n",
        "```python\n",
        "RAG.index(\n",
        "    collection=[document],     # ì¸ë±ì‹±í•  ë¬¸ì„œë“¤\n",
        "    index_name=\"index_name\",   # ì¸ë±ìŠ¤ ì´ë¦„\n",
        "    max_document_length=180,   # ì²­í¬ ìµœëŒ€ ê¸¸ì´\n",
        "    split_documents=True,      # ìë™ ë¶„í•  ì—¬ë¶€\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2aFnGav4-x3"
      },
      "outputs": [],
      "source": [
        "# ColBERT ì¸ë±ìŠ¤ ìƒì„±\n",
        "RAG.index(\n",
        "    collection=[full_document],\n",
        "    index_name=\"Miyazaki-index\",\n",
        "    max_document_length=180,\n",
        "    split_documents=True,\n",
        ")\n",
        "\n",
        "print(\"âœ… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QAUGAs34-x3"
      },
      "source": [
        "# 5. ColBERTë¡œ ê²€ìƒ‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFFZCirG4-x3"
      },
      "outputs": [],
      "source": [
        "# ê²€ìƒ‰ ìˆ˜í–‰\n",
        "query = \"What animation studio did Miyazaki found?\"\n",
        "results = RAG.search(query=query, k=3)\n",
        "\n",
        "print(f\"ì¿¼ë¦¬: '{query}'\\n\")\n",
        "print(\"=== ê²€ìƒ‰ ê²°ê³¼ ===\")\n",
        "for i, result in enumerate(results):\n",
        "    print(f\"\\n[{i+1}] Score: {result['score']:.4f}\")\n",
        "    print(f\"    {result['content'][:200]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y14Mq3Gu4-x3"
      },
      "source": [
        "# 6. LangChain Retrieverë¡œ ë³€í™˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bg5TzdJg4-x3"
      },
      "outputs": [],
      "source": [
        "# LangChain Retrieverë¡œ ë³€í™˜\n",
        "retriever = RAG.as_langchain_retriever(k=3)\n",
        "\n",
        "# Retriever ì‚¬ìš©\n",
        "docs = retriever.invoke(\"What animation studio did Miyazaki found?\")\n",
        "\n",
        "print(\"=== LangChain Retriever ê²°ê³¼ ===\")\n",
        "for i, doc in enumerate(docs):\n",
        "    print(f\"\\n[{i+1}] {doc.page_content[:150]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scAdhDlm4-x3"
      },
      "source": [
        "# 7. RAG ì²´ì¸ì—ì„œ ì‚¬ìš©"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4PGBtNc4-x3"
      },
      "outputs": [],
      "source": [
        "# OllamaëŠ” ìœ„ ì½”ë“œ 2-7ì—ì„œ ì´ë¯¸ ì„¤ì¹˜ ë° ì‹¤í–‰ ì™„ë£Œ\n",
        "# llama3.2 ëª¨ë¸ë„ ì´ë¯¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\n",
        "# (Colab ëŸ°íƒ€ì„ì´ ì¬ì‹œì‘ëœ ê²½ìš° ì½”ë“œ 2-7ì˜ Ollama ì„¤ì¹˜ ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9geCwZo4-x3"
      },
      "outputs": [],
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# RAG ì²´ì¸ êµ¬ì„±\n",
        "llm = ChatOllama(model='llama3.2')\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template('''Answer the question based on the context:\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:''')\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# RAG ì²´ì¸ ì‹¤í–‰\n",
        "answer = rag_chain.invoke(\"What animation studio did Miyazaki found?\")\n",
        "\n",
        "print(\"=== RAG ì‘ë‹µ ===\")\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54kWhpyn4-x3"
      },
      "source": [
        "## RAGatouille ì£¼ìš” ë©”ì„œë“œ\n",
        "\n",
        "| ë©”ì„œë“œ | ì„¤ëª… |\n",
        "|--------|------|\n",
        "| `from_pretrained()` | ì‚¬ì „í›ˆë ¨ ëª¨ë¸ ë¡œë“œ |\n",
        "| `index()` | ë¬¸ì„œ ì¸ë±ì‹± |\n",
        "| `search()` | ê²€ìƒ‰ ìˆ˜í–‰ |\n",
        "| `as_langchain_retriever()` | LangChain Retriever ë³€í™˜ |\n",
        "\n",
        "## ì¼ë°˜ ì„ë² ë”© vs ColBERT ë¹„êµ\n",
        "\n",
        "| íŠ¹ì„± | ì¼ë°˜ ì„ë² ë”© | ColBERT |\n",
        "|------|------------|--------|\n",
        "| ì„ë² ë”© ì°¨ì› | ë¬¸ì„œë‹¹ 1ê°œ ë²¡í„° | í† í°ë‹¹ 1ê°œ ë²¡í„° |\n",
        "| ê²€ìƒ‰ ì •í™•ë„ | ë³´í†µ | ë†’ìŒ |\n",
        "| ì¸ë±ìŠ¤ í¬ê¸° | ì‘ìŒ | í¼ |\n",
        "| ê²€ìƒ‰ ì†ë„ | ë¹ ë¦„ | ì•½ê°„ ëŠë¦¼ |\n",
        "\n",
        "## ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤\n",
        "\n",
        "- **ë†’ì€ ì •í™•ë„ í•„ìš”**: ë²•ë¥ , ì˜ë£Œ ë¬¸ì„œ ê²€ìƒ‰\n",
        "- **ì„¸ë°€í•œ ë§¤ì¹­ í•„ìš”**: ê¸°ìˆ  ë¬¸ì„œ, ì½”ë“œ ê²€ìƒ‰\n",
        "- **ì„¤ëª… ê°€ëŠ¥ì„± í•„ìš”**: ê²€ìƒ‰ ê²°ê³¼ ê·¼ê±° ì œì‹œ"
      ]
    }
  ]
}