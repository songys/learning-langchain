{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddingsë¡œ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ê¸°\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **Embeddings**ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°(ìˆ«ì ë°°ì—´)ë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤.\n",
    "\n",
    "## RAG íŒŒì´í”„ë¼ì¸ì—ì„œì˜ ìœ„ì¹˜\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  ğŸ“„ Load    â”‚ â”€â”€â–¶ â”‚  âœ‚ï¸ Split   â”‚ â”€â”€â–¶ â”‚  ğŸ”¢ Embed   â”‚ â”€â”€â–¶ â”‚  ğŸ’¾ Store   â”‚\n",
    "â”‚  (ë¡œë“œ)     â”‚     â”‚  (ë¶„í• )     â”‚     â”‚  (ì„ë² ë”©)    â”‚     â”‚  (ì €ì¥)     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                              â†‘\n",
    "                                           í˜„ì¬ ë‹¨ê³„\n",
    "```\n",
    "\n",
    "## Embeddingì´ë€?\n",
    "\n",
    "í…ìŠ¤íŠ¸ì˜ **ì˜ë¯¸**ë¥¼ ìˆ«ì ë²¡í„°ë¡œ í‘œí˜„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "\"ì•ˆë…•í•˜ì„¸ìš”\" â†’ [0.12, -0.34, 0.56, ..., 0.78]  (1536ì°¨ì›)\n",
    "```\n",
    "\n",
    "**íŠ¹ì§•:**\n",
    "- ì˜ë¯¸ê°€ ë¹„ìŠ·í•œ í…ìŠ¤íŠ¸ â†’ ë²¡í„°ê°€ ê°€ê¹Œì›€\n",
    "- ë²¡í„° ê°„ ê±°ë¦¬/ìœ ì‚¬ë„ë¡œ ê²€ìƒ‰ ê°€ëŠ¥\n",
    "\n",
    "## ì£¼ìš” Embedding ëª¨ë¸\n",
    "\n",
    "| ëª¨ë¸ | íŠ¹ì§• |\n",
    "|------|------|\n",
    "| OpenAI `text-embedding-3-small` | ë¹ ë¥´ê³  ì €ë ´ |\n",
    "| OpenAI `text-embedding-3-large` | ë†’ì€ ì •í™•ë„ |\n",
    "| Ollama (nomic-embed-text) | ë¡œì»¬, ë¬´ë£Œ |\n",
    "| HuggingFace | ë‹¤ì–‘í•œ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ |\n",
    "\n",
    "---\n",
    "\n",
    "# 1. Ollama ì„¤ì¹˜ ë° ì„œë²„ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "!apt-get install -y zstd\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "subprocess.Popen(['ollama', 'serve'])\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ì„ë² ë”© ëª¨ë¸ ë‹¤ìš´ë¡œë“œ & íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nomic-embed-text: Ollamaì˜ ì„ë² ë”© ëª¨ë¸\n",
    "!ollama pull nomic-embed-text\n",
    "!pip install -q langchain-ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Embeddings ìƒì„±\n",
    "\n",
    "**ì½”ë“œ ì„¤ëª…:**\n",
    "\n",
    "```python\n",
    "model = OllamaEmbeddings(model='nomic-embed-text')\n",
    "embeddings = model.embed_documents(['í…ìŠ¤íŠ¸1', 'í…ìŠ¤íŠ¸2', ...])\n",
    "```\n",
    "\n",
    "- `embed_documents()` - ì—¬ëŸ¬ ë¬¸ì„œë¥¼ ë²¡í„°ë¡œ ë³€í™˜\n",
    "- `embed_query()` - ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ ìƒì„±\n",
    "model = OllamaEmbeddings(model='nomic-embed-text')\n",
    "\n",
    "# ì—¬ëŸ¬ ë¬¸ì„œ ì„ë² ë”©\n",
    "texts = [\n",
    "    'Hi there!',\n",
    "    'Oh, hello!',\n",
    "    \"What's your name?\",\n",
    "    'My friends call me World',\n",
    "    'Hello World!'\n",
    "]\n",
    "\n",
    "embeddings = model.embed_documents(texts)\n",
    "\n",
    "print(f\"ì„ë² ë”©ëœ ë¬¸ì„œ ìˆ˜: {len(embeddings)}\")\n",
    "print(f\"ê° ë²¡í„°ì˜ ì°¨ì›: {len(embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ì„ë² ë”© ë²¡í„° í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ì˜ ë²¡í„° (ì¼ë¶€ë§Œ ì¶œë ¥)\n",
    "print(f\"í…ìŠ¤íŠ¸: '{texts[0]}'\")\n",
    "print(f\"ë²¡í„° (ì²˜ìŒ 10ê°œ): {embeddings[0][:10]}\")\n",
    "print(f\"...\")\n",
    "print(f\"ë²¡í„° (ë§ˆì§€ë§‰ 5ê°œ): {embeddings[0][-5:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ìœ ì‚¬ë„ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "# ê° í…ìŠ¤íŠ¸ ìŒì˜ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "print(\"=== í…ìŠ¤íŠ¸ ê°„ ìœ ì‚¬ë„ ===\")\n",
    "for i in range(len(texts)):\n",
    "    for j in range(i+1, len(texts)):\n",
    "        sim = cosine_similarity(embeddings[i], embeddings[j])\n",
    "        print(f\"'{texts[i]}' vs '{texts[j]}': {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. ì¿¼ë¦¬ ì„ë² ë”© (ê²€ìƒ‰ìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ìƒ‰ ì¿¼ë¦¬ ì„ë² ë”©\n",
    "query = \"greeting\"\n",
    "query_embedding = model.embed_query(query)\n",
    "\n",
    "print(f\"ì¿¼ë¦¬: '{query}'\")\n",
    "print(f\"ì¿¼ë¦¬ ë²¡í„° ì°¨ì›: {len(query_embedding)}\")\n",
    "\n",
    "# ì¿¼ë¦¬ì™€ ê° ë¬¸ì„œì˜ ìœ ì‚¬ë„\n",
    "print(\"\\n=== ì¿¼ë¦¬ì™€ ë¬¸ì„œ ìœ ì‚¬ë„ ===\")\n",
    "for i, text in enumerate(texts):\n",
    "    sim = cosine_similarity(query_embedding, embeddings[i])\n",
    "    print(f\"'{text}': {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì½”ë“œ ë³€ê²½ì  (OpenAI â†’ Ollama)\n",
    "\n",
    "```python\n",
    "# ì›ë³¸ (OpenAI)\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "model = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "\n",
    "# ë³€ê²½ (Ollama)\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "model = OllamaEmbeddings(model='nomic-embed-text')\n",
    "```\n",
    "\n",
    "## Embedding ë©”ì„œë“œ\n",
    "\n",
    "| ë©”ì„œë“œ | ìš©ë„ |\n",
    "|--------|------|\n",
    "| `embed_documents([texts])` | ë¬¸ì„œë“¤ì„ ë²¡í„°ë¡œ ë³€í™˜ (ì €ì¥ìš©) |\n",
    "| `embed_query(text)` | ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ |\n",
    "\n",
    "## ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "ì„ë² ë”©ëœ ë²¡í„°ëŠ” **Vector Store**ì— ì €ì¥í•˜ì—¬ ìœ ì‚¬ë„ ê²€ìƒ‰ì— ì‚¬ìš©í•©ë‹ˆë‹¤. (09ë²ˆ ë…¸íŠ¸ë¶)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
