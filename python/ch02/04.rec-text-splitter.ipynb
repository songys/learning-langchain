{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RecursiveCharacterTextSplitterë¡œ ë¬¸ì„œ ë¶„í• í•˜ê¸°\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **RecursiveCharacterTextSplitter**ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ì ì ˆí•œ í¬ê¸°ì˜ ì²­í¬ë¡œ ë¶„í• í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤.\n",
    "\n",
    "## RAG íŒŒì´í”„ë¼ì¸ì—ì„œì˜ ìœ„ì¹˜\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  ğŸ“„ Load    â”‚ â”€â”€â–¶ â”‚  âœ‚ï¸ Split   â”‚ â”€â”€â–¶ â”‚  ğŸ”¢ Embed   â”‚ â”€â”€â–¶ â”‚  ğŸ’¾ Store   â”‚\n",
    "â”‚  (ë¡œë“œ)     â”‚     â”‚  (ë¶„í• )     â”‚     â”‚  (ì„ë² ë”©)    â”‚     â”‚  (ì €ì¥)     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                          â†‘\n",
    "                       í˜„ì¬ ë‹¨ê³„\n",
    "```\n",
    "\n",
    "## ì™œ ë¬¸ì„œë¥¼ ë¶„í• í•´ì•¼ í• ê¹Œ?\n",
    "\n",
    "1. **LLM ì»¨í…ìŠ¤íŠ¸ ì œí•œ**: ëª¨ë¸ì˜ ìµœëŒ€ í† í° ìˆ˜ ì œí•œ\n",
    "2. **ê²€ìƒ‰ ì •í™•ë„**: ì‘ì€ ì²­í¬ê°€ ë” ì •í™•í•œ ê²€ìƒ‰ ê²°ê³¼\n",
    "3. **ë¹„ìš© íš¨ìœ¨**: í•„ìš”í•œ ë¶€ë¶„ë§Œ LLMì— ì „ë‹¬\n",
    "\n",
    "## RecursiveCharacterTextSplitterë€?\n",
    "\n",
    "**ì¬ê·€ì **ìœ¼ë¡œ ì—¬ëŸ¬ êµ¬ë¶„ìë¥¼ ì‹œë„í•˜ì—¬ ì˜ë¯¸ ìˆëŠ” ë‹¨ìœ„ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê¸°ë³¸ êµ¬ë¶„ì ìˆœì„œ:\n",
    "1. `\\n\\n` (ë‹¨ë½)\n",
    "2. `\\n` (ì¤„ë°”ê¿ˆ)\n",
    "3. ` ` (ê³µë°±)\n",
    "4. `` (ë¬¸ì)\n",
    "\n",
    "---\n",
    "\n",
    "# 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-community langchain-text-splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. í…ŒìŠ¤íŠ¸ íŒŒì¼ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ìš© í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±\n",
    "sample_text = '''LangChainì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì£¼ìš” ê¸°ëŠ¥:\n",
    "1. í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ë° ìµœì í™”\n",
    "2. ì²´ì¸ êµ¬ì„±ì„ í†µí•œ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ìƒì„±\n",
    "3. ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì™€ì˜ ì—°ë™\n",
    "4. ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ í†µí•œ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€\n",
    "\n",
    "LangChainì„ ì‚¬ìš©í•˜ë©´ RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì„ ì‰½ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. RAGëŠ” ì™¸ë¶€ ì§€ì‹ì„ ê²€ìƒ‰í•˜ì—¬ LLMì˜ ì‘ë‹µì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
    "\n",
    "Vector StoreëŠ” ì„ë² ë”©ëœ ë¬¸ì„œë¥¼ ì €ì¥í•˜ê³  ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤. ëŒ€í‘œì ìœ¼ë¡œ Chroma, Pinecone, Weaviate ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n",
    "'''\n",
    "\n",
    "with open('./test.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(sample_text)\n",
    "\n",
    "print(f\"test.txt ìƒì„± ì™„ë£Œ (ì´ {len(sample_text)}ì)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• \n",
    "\n",
    "**í•µì‹¬ íŒŒë¼ë¯¸í„°:**\n",
    "\n",
    "```python\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,    # ì²­í¬ ìµœëŒ€ í¬ê¸° (ë¬¸ì ìˆ˜)\n",
    "    chunk_overlap=200   # ì²­í¬ ê°„ ì¤‘ë³µ (ë¬¸ë§¥ ìœ ì§€)\n",
    ")\n",
    "```\n",
    "\n",
    "| íŒŒë¼ë¯¸í„° | ì„¤ëª… |\n",
    "|----------|------|\n",
    "| `chunk_size` | ê° ì²­í¬ì˜ ìµœëŒ€ ë¬¸ì ìˆ˜ |\n",
    "| `chunk_overlap` | ì¸ì ‘ ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¬¸ì ìˆ˜ (ë¬¸ë§¥ ìœ ì§€ìš©) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. ë¬¸ì„œ ë¡œë“œ\n",
    "loader = TextLoader('./test.txt', encoding='utf-8')\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"ì›ë³¸ ë¬¸ì„œ ìˆ˜: {len(docs)}\")\n",
    "print(f\"ì›ë³¸ ë¬¸ì„œ ê¸¸ì´: {len(docs[0].page_content)}ì\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Text Splitter ìƒì„±\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,     # ì˜ˆì‹œë¥¼ ìœ„í•´ ì‘ì€ ê°’ ì‚¬ìš©\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "# 3. ë¬¸ì„œ ë¶„í• \n",
    "splitted_docs = splitter.split_documents(docs)\n",
    "\n",
    "print(f\"ë¶„í• ëœ ë¬¸ì„œ ìˆ˜: {len(splitted_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ë¶„í•  ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê° ì²­í¬ í™•ì¸\n",
    "for i, doc in enumerate(splitted_docs):\n",
    "    print(f\"\\n=== ì²­í¬ {i+1} ({len(doc.page_content)}ì) ===\")\n",
    "    print(doc.page_content)\n",
    "    print(f\"metadata: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## chunk_overlapì˜ ì—­í• \n",
    "\n",
    "```\n",
    "ì²­í¬ 1: [    í…ìŠ¤íŠ¸ A    ][ì¤‘ë³µ]\n",
    "ì²­í¬ 2:              [ì¤‘ë³µ][    í…ìŠ¤íŠ¸ B    ]\n",
    "```\n",
    "\n",
    "- ë¬¸ë§¥ì´ ì²­í¬ ê²½ê³„ì—ì„œ ëŠê¸°ëŠ” ê²ƒì„ ë°©ì§€\n",
    "- ê²€ìƒ‰ ì‹œ ê´€ë ¨ ì •ë³´ê°€ ëˆ„ë½ë˜ì§€ ì•Šë„ë¡ ë³´ì¥\n",
    "\n",
    "## ì ì ˆí•œ chunk_size ì„ íƒ\n",
    "\n",
    "| chunk_size | ì¥ì  | ë‹¨ì  |\n",
    "|------------|------|------|\n",
    "| ì‘ìŒ (200-500) | ì •í™•í•œ ê²€ìƒ‰ | ë¬¸ë§¥ ì†ì‹¤ ê°€ëŠ¥ |\n",
    "| ì¤‘ê°„ (500-1000) | ê· í˜• ì¡í˜ | - |\n",
    "| í¼ (1000-2000) | í’ë¶€í•œ ë¬¸ë§¥ | ê²€ìƒ‰ ì •í™•ë„ ì €í•˜ |\n",
    "\n",
    "## ë‹¤ë¥¸ Text Splitter\n",
    "\n",
    "```python\n",
    "# í† í° ê¸°ë°˜ ë¶„í• \n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "splitter = TokenTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "# ë¬¸ì¥ ê¸°ë°˜ ë¶„í• \n",
    "from langchain_text_splitters import SentenceTransformersTokenTextSplitter\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
