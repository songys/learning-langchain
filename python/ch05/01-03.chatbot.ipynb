{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph로 기본 챗봇 만들기\n",
    "\n",
    "이 노트북에서는 **LangGraph**를 사용하여 **기본적인 챗봇 아키텍처**를 구현합니다.\n",
    "\n",
    "## ch04 복습: LangGraph의 구성요소\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────┐\n",
    "│                 LangGraph의 3가지 핵심 요소                         │\n",
    "├────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                    │\n",
    "│   1️⃣ State (상태)                                                 │\n",
    "│      • 그래프 전체에서 공유되는 데이터                              │\n",
    "│      • 대화 기록, 중간 결과 등 저장                                │\n",
    "│                                                                    │\n",
    "│   2️⃣ Node (노드)                                                  │\n",
    "│      • 실제 작업을 수행하는 함수                                   │\n",
    "│      • LLM 호출, 데이터 처리 등                                    │\n",
    "│                                                                    │\n",
    "│   3️⃣ Edge (엣지)                                                  │\n",
    "│      • 노드 간의 연결                                              │\n",
    "│      • 실행 순서 결정                                              │\n",
    "│                                                                    │\n",
    "└────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "## 이 노트북에서 만들 챗봇 구조\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────┐\n",
    "│                    기본 챗봇 아키텍처                               │\n",
    "├────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                    │\n",
    "│          ┌─────────┐      ┌─────────┐      ┌─────────┐            │\n",
    "│          │  START  │ ───▶ │ chatbot │ ───▶ │   END   │            │\n",
    "│          └─────────┘      └─────────┘      └─────────┘            │\n",
    "│                                │                                   │\n",
    "│                                ▼                                   │\n",
    "│                        ┌─────────────┐                             │\n",
    "│                        │    LLM      │                             │\n",
    "│                        │   호출      │                             │\n",
    "│                        └─────────────┘                             │\n",
    "│                                                                    │\n",
    "│   가장 단순한 형태의 챗봇:                                          │\n",
    "│   사용자 입력 → LLM 처리 → 응답 반환                               │\n",
    "│                                                                    │\n",
    "└────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-ollama langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "!apt-get install -y zstd\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "subprocess.Popen(['ollama', 'serve'])\n",
    "time.sleep(3)\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. State (상태) 정의\n",
    "\n",
    "챗봇이 관리할 데이터 구조를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    챗봇의 상태를 정의합니다.\n",
    "    \n",
    "    messages: 대화 기록 리스트\n",
    "    - Annotated[list, add_messages]: \n",
    "      새 메시지가 오면 덮어쓰지 않고 추가함\n",
    "    \"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "print(\"✅ State 정의 완료\")\n",
    "print(\"   messages: 대화 기록을 저장하는 리스트\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Node (노드) 정의\n",
    "\n",
    "LLM을 호출하는 챗봇 노드를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# LLM 모델\n",
    "model = ChatOllama(model='llama3.2')\n",
    "\n",
    "def chatbot(state: State):\n",
    "    \"\"\"\n",
    "    챗봇 노드\n",
    "    \n",
    "    1. 현재 상태에서 메시지 기록을 가져옴\n",
    "    2. LLM에게 전달하여 응답 생성\n",
    "    3. 응답을 메시지 리스트에 추가하여 반환\n",
    "    \"\"\"\n",
    "    # LLM 호출\n",
    "    answer = model.invoke(state['messages'])\n",
    "    \n",
    "    # 응답을 메시지에 추가\n",
    "    return {'messages': [answer]}\n",
    "\n",
    "print(\"✅ chatbot 노드 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Graph (그래프) 구성\n",
    "\n",
    "노드와 엣지를 연결하여 그래프를 완성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# 그래프 빌더 생성\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# 노드 추가\n",
    "# 첫 번째 인자: 노드 이름 (고유해야 함)\n",
    "# 두 번째 인자: 실행할 함수\n",
    "builder.add_node('chatbot', chatbot)\n",
    "\n",
    "# 엣지 추가\n",
    "builder.add_edge(START, 'chatbot')  # 시작 → 챗봇\n",
    "builder.add_edge('chatbot', END)     # 챗봇 → 종료\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = builder.compile()\n",
    "\n",
    "print(\"✅ 그래프 컴파일 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 그래프 구조 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 구조를 Mermaid 형식으로 출력\n",
    "print(\"=== 그래프 구조 (Mermaid) ===\")\n",
    "print(graph.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 그래프 실행\n",
    "\n",
    "## stream vs invoke\n",
    "\n",
    "| 메서드 | 동작 | 사용 시나리오 |\n",
    "|--------|------|---------------|\n",
    "| **invoke** | 최종 결과만 반환 | 결과만 필요할 때 |\n",
    "| **stream** | 단계별 결과 반환 | 진행 상황을 보고 싶을 때 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 입력 준비\n",
    "input_data = {'messages': [HumanMessage(content='안녕하세요!')]}\n",
    "\n",
    "print(\"=== stream으로 실행 ===\")\n",
    "print(f\"입력: {input_data['messages'][0].content}\\n\")\n",
    "\n",
    "# stream으로 실행 (단계별 출력)\n",
    "for chunk in graph.stream(input_data):\n",
    "    print(f\"chunk: {chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke로 실행 (최종 결과만)\n",
    "result = graph.invoke(input_data)\n",
    "\n",
    "print(\"\\n=== invoke로 실행 ===\")\n",
    "print(f\"응답: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 다양한 질문으로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = [\n",
    "    \"파이썬이란 무엇인가요?\",\n",
    "    \"오늘 날씨가 어때요?\",\n",
    "    \"간단한 인사말을 알려주세요.\",\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"사용자: {question}\")\n",
    "    \n",
    "    result = graph.invoke({'messages': [HumanMessage(content=question)]})\n",
    "    \n",
    "    print(f\"\\nAI: {result['messages'][-1].content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 정리: 기본 챗봇 아키텍처\n",
    "\n",
    "### 구현 단계\n",
    "\n",
    "```python\n",
    "# 1. State 정의\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# 2. Node 정의\n",
    "def chatbot(state: State):\n",
    "    answer = model.invoke(state['messages'])\n",
    "    return {'messages': [answer]}\n",
    "\n",
    "# 3. Graph 구성\n",
    "builder = StateGraph(State)\n",
    "builder.add_node('chatbot', chatbot)\n",
    "builder.add_edge(START, 'chatbot')\n",
    "builder.add_edge('chatbot', END)\n",
    "\n",
    "# 4. 컴파일 및 실행\n",
    "graph = builder.compile()\n",
    "result = graph.invoke({'messages': [...]})\n",
    "```\n",
    "\n",
    "### 핵심 개념\n",
    "\n",
    "| 개념 | 역할 | 비유 |\n",
    "|------|------|------|\n",
    "| **State** | 공유 데이터 | 공유 메모장 |\n",
    "| **Node** | 작업 수행 | 작업자 |\n",
    "| **Edge** | 노드 연결 | 작업 순서표 |\n",
    "| **START/END** | 시작/종료점 | 출발/도착 |\n",
    "\n",
    "## 코드 변경점 (OpenAI → Ollama)\n",
    "\n",
    "```python\n",
    "# 원본\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "# 변경\n",
    "from langchain_ollama import ChatOllama\n",
    "model = ChatOllama(model='llama3.2')\n",
    "```\n",
    "\n",
    "## 다음 단계\n",
    "\n",
    "**여러 노드를 연결**하여 SQL 쿼리를 생성하고 설명하는 시스템을 만듭니다. (04-05번 노트북)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
