{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Output: ë…¸ë“œë³„ ìŠ¤íŠ¸ë¦¬ë°\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **ê·¸ë˜í”„ ì‹¤í–‰ ì¤‘ ë…¸ë“œë³„ë¡œ ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¬ë°**í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n",
    "\n",
    "## Streamingì´ë€?\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    Streamingì˜ ê°œë…                                â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   ì¼ë°˜ ì‹¤í–‰ (invoke):                                              â”‚\n",
    "â”‚   ì…ë ¥ â†’ [ì²˜ë¦¬ ì¤‘...] â†’ ì „ì²´ ê²°ê³¼ ë°˜í™˜                             â”‚\n",
    "â”‚   (ëª¨ë“  ì²˜ë¦¬ê°€ ëë‚  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¼)                                 â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰ (stream):                                          â”‚\n",
    "â”‚   ì…ë ¥ â†’ ë…¸ë“œ1 ê²°ê³¼ â†’ ë…¸ë“œ2 ê²°ê³¼ â†’ ë…¸ë“œ3 ê²°ê³¼ â†’ ...               â”‚\n",
    "â”‚   (ê° ë…¸ë“œ ì™„ë£Œ ì‹œë§ˆë‹¤ ì¦‰ì‹œ ê²°ê³¼ ë°˜í™˜)                             â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   ì¥ì :                                                            â”‚\n",
    "â”‚   â€¢ ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© í™•ì¸                                          â”‚\n",
    "â”‚   â€¢ ì‚¬ìš©ì ê²½í—˜ í–¥ìƒ (ì‘ë‹µì„±)                                      â”‚\n",
    "â”‚   â€¢ ë””ë²„ê¹… ìš©ì´                                                    â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## stream_mode ì˜µì…˜\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    stream_mode ë¹„êµ                                â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   stream_mode='values' (ê¸°ë³¸):                                     â”‚\n",
    "â”‚   â†’ ê° ë…¸ë“œ í›„ ì „ì²´ State ë°˜í™˜                                    â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   stream_mode='updates':                                           â”‚\n",
    "â”‚   â†’ ê° ë…¸ë“œê°€ ë³€ê²½í•œ ë¶€ë¶„ë§Œ ë°˜í™˜                                  â”‚\n",
    "â”‚   â†’ ë” íš¨ìœ¨ì , ë³€ê²½ ì‚¬í•­ ì¶”ì  ìš©ì´                                â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-ollama langgraph duckduckgo-search langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "!apt-get install -y zstd\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "subprocess.Popen(['ollama', 'serve'])\n",
    "time.sleep(3)\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculator(query: str) -> str:\n",
    "    '''ê³„ì‚°ê¸°. ìˆ˜ì‹ë§Œ ì…ë ¥ë°›ìŠµë‹ˆë‹¤.'''\n",
    "    return ast.literal_eval(query)\n",
    "\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "tools = [search, calculator]\n",
    "model = ChatOllama(model='llama3.2', temperature=0.1).bind_tools(tools)\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "def model_node(state: State) -> State:\n",
    "    res = model.invoke(state['messages'])\n",
    "    return {'messages': res}\n",
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node('model', model_node)\n",
    "builder.add_node('tools', ToolNode(tools))\n",
    "builder.add_edge(START, 'model')\n",
    "builder.add_conditional_edges('model', tools_condition)\n",
    "builder.add_edge('tools', 'model')\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "print(\"âœ… ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ê¸°ë³¸ ìŠ¤íŠ¸ë¦¬ë° (values ëª¨ë“œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {\n",
    "    'messages': [\n",
    "        HumanMessage(\n",
    "            'ë¯¸êµ­ì˜ ì œ30ëŒ€ ëŒ€í†µë ¹ì´ ì‚¬ë§í–ˆì„ ë•Œ ëª‡ ì‚´ì´ì—ˆë‚˜ìš”?'\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"=== stream_mode='values' (ê¸°ë³¸) ===\")\n",
    "print(\"ê° ë…¸ë“œ í›„ ì „ì²´ State ë°˜í™˜\\n\")\n",
    "\n",
    "for i, chunk in enumerate(graph.stream(input_data)):\n",
    "    print(f\"--- Chunk {i+1} ---\")\n",
    "    for node_name, node_output in chunk.items():\n",
    "        print(f\"ë…¸ë“œ: {node_name}\")\n",
    "        if 'messages' in node_output:\n",
    "            last_msg = node_output['messages'][-1] if isinstance(node_output['messages'], list) else node_output['messages']\n",
    "            content = str(last_msg.content)[:100] if hasattr(last_msg, 'content') else str(last_msg)[:100]\n",
    "            print(f\"ë‚´ìš©: {content}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. updates ëª¨ë“œ ìŠ¤íŠ¸ë¦¬ë°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== stream_mode='updates' ===\")\n",
    "print(\"ê° ë…¸ë“œê°€ ë³€ê²½í•œ ë¶€ë¶„ë§Œ ë°˜í™˜\\n\")\n",
    "\n",
    "for i, chunk in enumerate(graph.stream(input_data, stream_mode='updates')):\n",
    "    print(f\"--- Update {i+1} ---\")\n",
    "    for node_name, node_output in chunk.items():\n",
    "        print(f\"ë…¸ë“œ: {node_name}\")\n",
    "        print(f\"ë³€ê²½ ë‚´ìš©: {str(node_output)[:200]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© í‘œì‹œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"=== ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ===\")\n",
    "print(f\"ì§ˆë¬¸: {input_data['messages'][0].content}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for chunk in graph.stream(input_data, stream_mode='updates'):\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    for node_name, node_output in chunk.items():\n",
    "        if node_name == 'model':\n",
    "            msg = node_output.get('messages', [])[-1] if node_output.get('messages') else None\n",
    "            if msg and hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "                print(f\"[{elapsed:.1f}s] ğŸ”§ ë„êµ¬ í˜¸ì¶œ ê²°ì •: {[tc['name'] for tc in msg.tool_calls]}\")\n",
    "            elif msg and hasattr(msg, 'content') and msg.content:\n",
    "                print(f\"[{elapsed:.1f}s] ğŸ’¬ ìµœì¢… ì‘ë‹µ ìƒì„± ì¤‘...\")\n",
    "        elif node_name == 'tools':\n",
    "            print(f\"[{elapsed:.1f}s] âš¡ ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ\")\n",
    "\n",
    "print(f\"\\nì´ ì†Œìš” ì‹œê°„: {time.time() - start_time:.1f}ì´ˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì •ë¦¬: Streaming Output\n",
    "\n",
    "### í•µì‹¬ ì½”ë“œ\n",
    "\n",
    "```python\n",
    "# ê¸°ë³¸ ìŠ¤íŠ¸ë¦¬ë° (ì „ì²´ State)\n",
    "for chunk in graph.stream(input_data):\n",
    "    print(chunk)\n",
    "\n",
    "# updates ëª¨ë“œ (ë³€ê²½ ì‚¬í•­ë§Œ)\n",
    "for chunk in graph.stream(input_data, stream_mode='updates'):\n",
    "    print(chunk)\n",
    "```\n",
    "\n",
    "### stream_mode ë¹„êµ\n",
    "\n",
    "| ëª¨ë“œ | ë°˜í™˜ ë‚´ìš© | ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ |\n",
    "|------|----------|---------------|\n",
    "| **values** | ì „ì²´ State | ì „ì²´ ìƒíƒœ í•„ìš” ì‹œ |\n",
    "| **updates** | ë³€ê²½ëœ ë¶€ë¶„ë§Œ | íš¨ìœ¨ì ì¸ ì²˜ë¦¬, ë³€ê²½ ì¶”ì  |\n",
    "\n",
    "## ì½”ë“œ ë³€ê²½ì  (OpenAI â†’ Ollama)\n",
    "\n",
    "```python\n",
    "# ì›ë³¸\n",
    "model = ChatOpenAI(model='gpt-4o-mini', temperature=0.1).bind_tools(tools)\n",
    "\n",
    "# ë³€ê²½\n",
    "model = ChatOllama(model='llama3.2', temperature=0.1).bind_tools(tools)\n",
    "```\n",
    "\n",
    "## ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "**í† í° ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°**ìœ¼ë¡œ ë” ì„¸ë°€í•œ ì‹¤ì‹œê°„ ì¶œë ¥ì„ êµ¬í˜„í•©ë‹ˆë‹¤. (04ë²ˆ ë…¸íŠ¸ë¶)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
