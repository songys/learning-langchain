{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 메시지 자르기 (Trim Messages)\n",
    "\n",
    "이 노트북에서는 **대화가 길어질 때 메시지를 자르는** 방법을 배웁니다.\n",
    "\n",
    "## 왜 메시지를 잘라야 할까요?\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────┐\n",
    "│                    토큰 제한 문제                                  │\n",
    "├────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                    │\n",
    "│   LLM의 한계:                                                      │\n",
    "│   • 한 번에 처리할 수 있는 토큰 수가 제한됨                         │\n",
    "│   • GPT-4: ~128K 토큰, Llama: ~8K 토큰                             │\n",
    "│   • 대화가 길어지면 한도 초과!                                      │\n",
    "│                                                                    │\n",
    "│   해결책:                                                          │\n",
    "│   • 오래된 메시지 삭제                                              │\n",
    "│   • 최근 메시지만 유지                                              │\n",
    "│   • 시스템 메시지는 항상 유지                                       │\n",
    "│                                                                    │\n",
    "└────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "## trim_messages의 전략\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────┐\n",
    "│                 trim_messages 전략 비교                            │\n",
    "├────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                    │\n",
    "│   strategy='last' (기본):                                          │\n",
    "│   [시스템] [메시지1] [메시지2] [메시지3] [메시지4] [메시지5]        │\n",
    "│              ↓         ↓                                          │\n",
    "│            삭제       삭제                                         │\n",
    "│   결과: [시스템] [메시지3] [메시지4] [메시지5]                      │\n",
    "│   → 최근 메시지 유지                                               │\n",
    "│                                                                    │\n",
    "│   strategy='first':                                                │\n",
    "│   [시스템] [메시지1] [메시지2] [메시지3] [메시지4] [메시지5]        │\n",
    "│                                         ↓         ↓               │\n",
    "│                                       삭제       삭제              │\n",
    "│   결과: [시스템] [메시지1] [메시지2] [메시지3]                      │\n",
    "│   → 초기 메시지 유지                                               │\n",
    "│                                                                    │\n",
    "└────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-ollama tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "!apt-get install -y zstd\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "subprocess.Popen(['ollama', 'serve'])\n",
    "time.sleep(3)\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 샘플 메시지 준비\n",
    "\n",
    "긴 대화 기록을 만들어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage,\n",
    ")\n",
    "\n",
    "# 긴 대화 기록 (11개 메시지)\n",
    "messages = [\n",
    "    SystemMessage(content='당신은 친절한 어시스턴트입니다.'),\n",
    "    HumanMessage(content='안녕하세요! 나는 민혁입니다.'),\n",
    "    AIMessage(content='안녕하세요!'),\n",
    "    HumanMessage(content='바닐라 아이스크림을 좋아해요.'),\n",
    "    AIMessage(content='좋네요!'),\n",
    "    HumanMessage(content='2 + 2는 얼마죠?'),\n",
    "    AIMessage(content='4입니다.'),\n",
    "    HumanMessage(content='고마워요.'),\n",
    "    AIMessage(content='천만에요!'),\n",
    "    HumanMessage(content='즐거운가요?'),\n",
    "    AIMessage(content='예!'),\n",
    "]\n",
    "\n",
    "print(f\"총 메시지 수: {len(messages)}개\\n\")\n",
    "print(\"=== 전체 대화 기록 ===\")\n",
    "for i, msg in enumerate(messages):\n",
    "    role = msg.type\n",
    "    print(f\"[{i+1}] {role}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. trim_messages 사용하기\n",
    "\n",
    "## 주요 옵션 설명\n",
    "\n",
    "| 옵션 | 설명 | 예시 |\n",
    "|------|------|------|\n",
    "| **max_tokens** | 최대 토큰 수 | 65 |\n",
    "| **strategy** | 자르기 전략 | 'last' (최근 유지) |\n",
    "| **token_counter** | 토큰 계산 모델 | LLM 모델 |\n",
    "| **include_system** | 시스템 메시지 포함 | True |\n",
    "| **allow_partial** | 메시지 부분 자르기 허용 | False |\n",
    "| **start_on** | 시작 메시지 유형 | 'human' |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import trim_messages\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# LLM 모델 (토큰 계산용)\n",
    "model = ChatOllama(model='llama3.2')\n",
    "\n",
    "# trimmer 설정\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=65,              # 최대 65 토큰만 유지\n",
    "    strategy='last',            # 최근 메시지 우선 유지\n",
    "    token_counter=model,        # 토큰 계산에 사용할 모델\n",
    "    include_system=True,        # 시스템 메시지는 항상 포함\n",
    "    allow_partial=False,        # 메시지를 중간에 자르지 않음\n",
    "    start_on='human',           # human 메시지로 시작\n",
    ")\n",
    "\n",
    "print(\"✅ trimmer 설정 완료\")\n",
    "print(\"   - 최대 65 토큰\")\n",
    "print(\"   - 최근 메시지 유지 전략\")\n",
    "print(\"   - 시스템 메시지 항상 포함\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 메시지 자르기 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim 적용\n",
    "trimmed = trimmer.invoke(messages)\n",
    "\n",
    "print(f\"원본 메시지 수: {len(messages)}개\")\n",
    "print(f\"자른 후 메시지 수: {len(trimmed)}개\\n\")\n",
    "\n",
    "print(\"=== 자른 후 대화 기록 ===\")\n",
    "for i, msg in enumerate(trimmed):\n",
    "    role = msg.type\n",
    "    print(f\"[{i+1}] {role}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 다양한 설정 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 더 많은 토큰 허용\n",
    "trimmer_large = trim_messages(\n",
    "    max_tokens=100,\n",
    "    strategy='last',\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    ")\n",
    "\n",
    "trimmed_large = trimmer_large.invoke(messages)\n",
    "\n",
    "print(\"=== max_tokens=100 ===\")\n",
    "print(f\"메시지 수: {len(trimmed_large)}개\")\n",
    "for msg in trimmed_large:\n",
    "    print(f\"  {msg.type}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy='first' 테스트 (초기 메시지 유지)\n",
    "trimmer_first = trim_messages(\n",
    "    max_tokens=65,\n",
    "    strategy='first',           # 초기 메시지 유지\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    ")\n",
    "\n",
    "trimmed_first = trimmer_first.invoke(messages)\n",
    "\n",
    "print(\"\\n=== strategy='first' ===\")\n",
    "print(f\"메시지 수: {len(trimmed_first)}개\")\n",
    "for msg in trimmed_first:\n",
    "    print(f\"  {msg.type}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 체인에서 trimmer 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# trimmer를 체인의 일부로 사용\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('placeholder', '{messages}'),\n",
    "])\n",
    "\n",
    "# 체인: trimmer → prompt → model\n",
    "chain = trimmer | prompt | model\n",
    "\n",
    "print(\"✅ trimmer가 포함된 체인 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 실행\n",
    "result = chain.invoke(messages)\n",
    "\n",
    "print(\"=== 체인 실행 결과 ===\")\n",
    "print(f\"AI 응답: {result.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 정리: 메시지 자르기 (trim_messages)\n",
    "\n",
    "### 주요 옵션\n",
    "\n",
    "| 옵션 | 기본값 | 설명 |\n",
    "|------|--------|------|\n",
    "| **max_tokens** | 필수 | 유지할 최대 토큰 수 |\n",
    "| **strategy** | 'last' | 'last': 최근 유지, 'first': 초기 유지 |\n",
    "| **token_counter** | 필수 | 토큰 계산에 사용할 모델/함수 |\n",
    "| **include_system** | False | 시스템 메시지 항상 포함 여부 |\n",
    "| **allow_partial** | False | 메시지 중간 자르기 허용 |\n",
    "| **start_on** | None | 시작해야 할 메시지 유형 |\n",
    "\n",
    "### 핵심 코드\n",
    "\n",
    "```python\n",
    "from langchain_core.messages import trim_messages\n",
    "\n",
    "# 1. trimmer 생성\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=100,\n",
    "    strategy='last',\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    ")\n",
    "\n",
    "# 2. 메시지 자르기\n",
    "trimmed = trimmer.invoke(messages)\n",
    "\n",
    "# 3. 체인에서 사용\n",
    "chain = trimmer | prompt | model\n",
    "```\n",
    "\n",
    "### 전략 선택 가이드\n",
    "\n",
    "| 상황 | 추천 전략 |\n",
    "|------|----------|\n",
    "| 일반 대화 | `strategy='last'` (최근 맥락 중요) |\n",
    "| 문서 요약 | `strategy='first'` (초기 내용 중요) |\n",
    "| 시스템 지시 중요 | `include_system=True` |\n",
    "\n",
    "## 코드 변경점 (OpenAI → Ollama)\n",
    "\n",
    "```python\n",
    "# 원본\n",
    "from langchain_openai import ChatOpenAI\n",
    "token_counter = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "# 변경\n",
    "from langchain_ollama import ChatOllama\n",
    "token_counter = ChatOllama(model='llama3.2')\n",
    "```\n",
    "\n",
    "## 다음 단계\n",
    "\n",
    "**메시지를 유형별로 필터링**하는 방법을 배웁니다. (12-14번 노트북)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
