{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4ì¥. ë©”ëª¨ë¦¬ì™€ ëŒ€í™” ê´€ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-openai langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata\nimport os\n\nos.environ['OPENAI_API_KEY']=userdata.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## ì½”ë“œ 4-1 ê°„ë‹¨í•œ ë©”ëª¨ë¦¬: ëŒ€í™” ê¸°ë¡ ìœ ì§€í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ê°„ë‹¨í•œ ë©”ëª¨ë¦¬: ëŒ€í™” ê¸°ë¡ ìœ ì§€í•˜ê¸°\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **AIì™€ì˜ ëŒ€í™” ê¸°ë¡ì„ ìœ ì§€**í•˜ëŠ” ê°€ì¥ ê¸°ë³¸ì ì¸ ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n",
    "\n",
    "## ì™œ ë©”ëª¨ë¦¬ê°€ í•„ìš”í• ê¹Œìš”?\n",
    "\n",
    "### AIì˜ ê¸°ë³¸ íŠ¹ì„±: ê¸°ì–µì„ ëª»í•¨\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    AIëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ê¸°ì–µì´ ì—†ë‹¤!                     â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   ëŒ€í™” 1:                                                          â”‚\n",
    "â”‚   ì‚¬ìš©ì: \"ë‚´ ì´ë¦„ì€ ë¯¼í˜ì´ì•¼\"                                     â”‚\n",
    "â”‚   AI: \"ì•ˆë…•í•˜ì„¸ìš” ë¯¼í˜ë‹˜!\"                                         â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   ëŒ€í™” 2 (ìƒˆë¡œìš´ ìš”ì²­):                                            â”‚\n",
    "â”‚   ì‚¬ìš©ì: \"ë‚´ ì´ë¦„ì´ ë­ì•¼?\"                                        â”‚\n",
    "â”‚   AI: \"ì£„ì†¡í•©ë‹ˆë‹¤, ì €ëŠ” ë‹¹ì‹ ì˜ ì´ë¦„ì„ ëª¨ë¦…ë‹ˆë‹¤\" ğŸ˜“                 â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   â†’ ê° ìš”ì²­ì€ ì™„ì „íˆ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬ë¨!                            â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### ë©”ëª¨ë¦¬ì˜ ì—­í• \n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    ë©”ëª¨ë¦¬ê°€ ìˆìœ¼ë©´                                  â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   ëŒ€í™” ê¸°ë¡ ì €ì¥:                                                  â”‚\n",
    "â”‚   [                                                                â”‚\n",
    "â”‚     {\"user\": \"ë‚´ ì´ë¦„ì€ ë¯¼í˜ì´ì•¼\"},                                â”‚\n",
    "â”‚     {\"ai\": \"ì•ˆë…•í•˜ì„¸ìš” ë¯¼í˜ë‹˜!\"},                                   â”‚\n",
    "â”‚     {\"user\": \"ë‚´ ì´ë¦„ì´ ë­ì•¼?\"}   â† ìƒˆ ì§ˆë¬¸                        â”‚\n",
    "â”‚   ]                                                                â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   AIì—ê²Œ ì „ì²´ ê¸°ë¡ ì „ë‹¬ â†’ AIê°€ ë§¥ë½ íŒŒì•…                           â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   AI: \"ë‹¹ì‹ ì˜ ì´ë¦„ì€ ë¯¼í˜ì…ë‹ˆë‹¤!\" âœ…                               â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "!apt-get install -y zstd\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "subprocess.Popen(['ollama', 'serve'])\n",
    "time.sleep(3)\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. placeholderë¥¼ ì‚¬ìš©í•œ ë©”ëª¨ë¦¬ êµ¬í˜„\n",
    "\n",
    "## placeholderë€?\n",
    "\n",
    "**placeholder**ëŠ” \"ìë¦¬ í‘œì‹œì\"ì…ë‹ˆë‹¤. ëŒ€í™” ê¸°ë¡ì´ ë“¤ì–´ê°ˆ ìë¦¬ë¥¼ ë¯¸ë¦¬ ë§Œë“¤ì–´ë‘¡ë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    placeholderì˜ ì—­í•                               â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿:                                                 â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚\n",
    "â”‚   â”‚ System: ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤  â”‚                       â”‚\n",
    "â”‚   â”‚                                        â”‚                       â”‚\n",
    "â”‚   â”‚ â–¼â–¼â–¼ {messages} placeholder â–¼â–¼â–¼        â”‚  â† ì—¬ê¸°ì— ëŒ€í™” ê¸°ë¡    â”‚\n",
    "â”‚   â”‚                                        â”‚                       â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   ì‹¤í–‰ ì‹œ:                                                         â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚\n",
    "â”‚   â”‚ System: ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤  â”‚                       â”‚\n",
    "â”‚   â”‚ Human: ë‚˜ëŠ” í”„ë¡œê·¸ë˜ë°ì„ ì¢‹ì•„í•´ìš”      â”‚                       â”‚\n",
    "â”‚   â”‚ AI: J'adore programmer.               â”‚                       â”‚\n",
    "â”‚   â”‚ Human: ë­ë¼ê³  ë§í–ˆì£ ?                 â”‚  â† ëŒ€í™” ê¸°ë¡ì´ ì±„ì›Œì§  â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "# 'placeholder'ëŠ” ëŒ€í™” ê¸°ë¡ì´ ë“¤ì–´ê°ˆ ìë¦¬ë¥¼ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ëª¨ë“  ì§ˆë¬¸ì— ìµœì„ ì„ ë‹¤í•´ ë‹µí•˜ì„¸ìš”.'),\n",
    "    ('placeholder', '{messages}'),  # ì—¬ê¸°ì— ëŒ€í™” ê¸°ë¡ì´ ë“¤ì–´ê°\n",
    "])\n",
    "\n",
    "# LLM ëª¨ë¸\n",
    "model = ChatOllama(model='llama3.2')\n",
    "\n",
    "# ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model\n",
    "\n",
    "print(\"âœ… ë©”ëª¨ë¦¬ ì²´ì¸ ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ëŒ€í™” ê¸°ë¡ì„ í¬í•¨í•œ ì‹¤í–‰\n",
    "\n",
    "ì´ì „ ëŒ€í™” ë‚´ìš©ì„ í•¨ê»˜ ì „ë‹¬í•˜ì—¬ AIê°€ ë§¥ë½ì„ ì´í•´í•˜ê²Œ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëŒ€í™” ê¸°ë¡ê³¼ í•¨ê»˜ ì‹¤í–‰\n",
    "response = chain.invoke({\n",
    "    'messages': [\n",
    "        ('human', 'ë‹¤ìŒ í•œêµ­ì–´ ë¬¸ì¥ì„ í”„ë‘ìŠ¤ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”: ë‚˜ëŠ” í”„ë¡œê·¸ë˜ë°ì„ ì¢‹ì•„í•´ìš”.'),\n",
    "        ('ai', \"J'adore programmer.\"),\n",
    "        ('human', 'ë­ë¼ê³  ë§í–ˆì£ ?'),  # ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•´ì•¼ ë‹µí•  ìˆ˜ ìˆìŒ\n",
    "    ],\n",
    "})\n",
    "\n",
    "print(\"=== AI ì‘ë‹µ ===\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ë©”ëª¨ë¦¬ì˜ íš¨ê³¼ í™•ì¸\n",
    "\n",
    "ëŒ€í™” ê¸°ë¡ ì—†ì´ ê°™ì€ ì§ˆë¬¸ì„ í•˜ë©´ ì–´ë–»ê²Œ ë ê¹Œìš”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëŒ€í™” ê¸°ë¡ ì—†ì´ ì‹¤í–‰ (ë©”ëª¨ë¦¬ ì—†ìŒ)\n",
    "response_no_memory = chain.invoke({\n",
    "    'messages': [\n",
    "        ('human', 'ë­ë¼ê³  ë§í–ˆì£ ?'),  # ë§¥ë½ ì—†ì´ ì§ˆë¬¸\n",
    "    ],\n",
    "})\n",
    "\n",
    "print(\"=== ë©”ëª¨ë¦¬ ì—†ì´ ì‘ë‹µ ===\")\n",
    "print(response_no_memory.content)\n",
    "print(\"\\nâ†’ ë§¥ë½ì„ ëª¨ë¥´ë‹ˆê¹Œ ë­˜ ë¬¼ì–´ë³´ëŠ”ì§€ ëª¨ë¦„!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "conversation_history = []\n",
    "\n",
    "def chat(user_message):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë°›ì•„ì„œ AI ì‘ë‹µì„ ë°˜í™˜í•˜ê³ \n",
    "    ëŒ€í™” ê¸°ë¡ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€\n",
    "    conversation_history.append(('human', user_message))\n",
    "    \n",
    "    # AI ì‘ë‹µ ìƒì„± (ì „ì²´ ëŒ€í™” ê¸°ë¡ ì „ë‹¬)\n",
    "    response = chain.invoke({'messages': conversation_history})\n",
    "    \n",
    "    # AI ì‘ë‹µì„ ê¸°ë¡ì— ì¶”ê°€\n",
    "    conversation_history.append(('ai', response.content))\n",
    "    \n",
    "    return response.content\n",
    "\n",
    "print(\"âœ… ëŒ€í™” í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜\n",
    "print(\"=== ëŒ€í™” ì‹œì‘ ===\")\n",
    "\n",
    "# ì²« ë²ˆì§¸ ëŒ€í™”\n",
    "print(\"\\nì‚¬ìš©ì: ì•ˆë…•í•˜ì„¸ìš”! ì œ ì´ë¦„ì€ ë¯¼í˜ì…ë‹ˆë‹¤.\")\n",
    "response1 = chat(\"ì•ˆë…•í•˜ì„¸ìš”! ì œ ì´ë¦„ì€ ë¯¼í˜ì…ë‹ˆë‹¤.\")\n",
    "print(f\"AI: {response1}\")\n",
    "\n",
    "# ë‘ ë²ˆì§¸ ëŒ€í™”\n",
    "print(\"\\nì‚¬ìš©ì: ì €ëŠ” íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë°ì„ ë°°ìš°ê³  ìˆì–´ìš”.\")\n",
    "response2 = chat(\"ì €ëŠ” íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë°ì„ ë°°ìš°ê³  ìˆì–´ìš”.\")\n",
    "print(f\"AI: {response2}\")\n",
    "\n",
    "# ì„¸ ë²ˆì§¸ ëŒ€í™” (ì´ì „ ë‚´ìš© ê¸°ì–µ í™•ì¸)\n",
    "print(\"\\nì‚¬ìš©ì: ì œ ì´ë¦„ì´ ë­ì˜€ì£ ?\")\n",
    "response3 = chat(\"ì œ ì´ë¦„ì´ ë­ì˜€ì£ ?\")\n",
    "print(f\"AI: {response3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜„ì¬ ëŒ€í™” ê¸°ë¡ í™•ì¸\n",
    "print(\"=== í˜„ì¬ ëŒ€í™” ê¸°ë¡ ===\")\n",
    "for i, (role, content) in enumerate(conversation_history):\n",
    "    role_name = \"ì‚¬ìš©ì\" if role == \"human\" else \"AI\"\n",
    "    print(f\"[{i+1}] {role_name}: {content[:50]}...\" if len(content) > 50 else f\"[{i+1}] {role_name}: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì •ë¦¬: ê°„ë‹¨í•œ ë©”ëª¨ë¦¬\n",
    "\n",
    "### í•µì‹¬ ì›ë¦¬\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    ë©”ëª¨ë¦¬ì˜ í•µì‹¬ ì›ë¦¬                              â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   AIëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ê¸°ì–µì´ ì—†ë‹¤                                      â”‚\n",
    "â”‚   â†’ ìš°ë¦¬ê°€ ëŒ€í™” ê¸°ë¡ì„ ì§ì ‘ ê´€ë¦¬í•´ì•¼ í•œë‹¤                          â”‚\n",
    "â”‚   â†’ ë§¤ë²ˆ ìš”ì²­í•  ë•Œ ì „ì²´ ëŒ€í™” ê¸°ë¡ì„ í•¨ê»˜ ì „ë‹¬                      â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### í•µì‹¬ ì½”ë“œ\n",
    "\n",
    "```python\n",
    "# 1. placeholderë¡œ ëŒ€í™” ê¸°ë¡ ìë¦¬ ë§Œë“¤ê¸°\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'ì‹œìŠ¤í…œ ë©”ì‹œì§€'),\n",
    "    ('placeholder', '{messages}'),  # ëŒ€í™” ê¸°ë¡ì´ ë“¤ì–´ê°ˆ ìë¦¬\n",
    "])\n",
    "\n",
    "# 2. ëŒ€í™” ê¸°ë¡ê³¼ í•¨ê»˜ ì‹¤í–‰\n",
    "response = chain.invoke({\n",
    "    'messages': [\n",
    "        ('human', 'ì²« ë²ˆì§¸ ì§ˆë¬¸'),\n",
    "        ('ai', 'ì²« ë²ˆì§¸ ë‹µë³€'),\n",
    "        ('human', 'ë‘ ë²ˆì§¸ ì§ˆë¬¸'),\n",
    "    ]\n",
    "})\n",
    "```\n",
    "\n",
    "### í•œê³„ì \n",
    "\n",
    "| í•œê³„ | ì„¤ëª… |\n",
    "|------|------|\n",
    "| **ìˆ˜ë™ ê´€ë¦¬** | ëŒ€í™” ê¸°ë¡ì„ ì§ì ‘ ê´€ë¦¬í•´ì•¼ í•¨ |\n",
    "| **í† í° ì œí•œ** | ëŒ€í™”ê°€ ê¸¸ì–´ì§€ë©´ í† í° í•œë„ ì´ˆê³¼ |\n",
    "| **ì˜ì†ì„± ì—†ìŒ** | í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ ê¸°ë¡ ì‚¬ë¼ì§ |\n",
    "\n",
    "## ì½”ë“œ ë³€ê²½ì  (OpenAI â†’ Ollama)\n",
    "\n",
    "```python\n",
    "# ì›ë³¸\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "# ë³€ê²½\n",
    "from langchain_ollama import ChatOllama\n",
    "model = ChatOllama(model='llama3.2')\n",
    "```\n",
    "\n",
    "## ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "**LangGraphì˜ StateGraph**ë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ì²´ê³„ì ìœ¼ë¡œ ëŒ€í™” ìƒíƒœë¥¼ ê´€ë¦¬í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤. (02-06ë²ˆ ë…¸íŠ¸ë¶)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## ì½”ë“œ 4-2~4-6 LangGraph StateGraphë¡œ ì±—ë´‡ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph StateGraphë¡œ ì±—ë´‡ ë§Œë“¤ê¸°\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **LangGraph**ë¥¼ ì‚¬ìš©í•˜ì—¬ **ìƒíƒœ(State)ë¥¼ ê´€ë¦¬í•˜ëŠ” ì±—ë´‡**ì„ ë§Œë“œëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n",
    "\n",
    "## LangGraphë€?\n",
    "\n",
    "**LangGraph**ëŠ” LangChain íŒ€ì´ ë§Œë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, **ê·¸ë˜í”„ êµ¬ì¡°**ë¡œ AI ì›Œí¬í”Œë¡œìš°ë¥¼ ë§Œë“¤ ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.\n",
    "\n",
    "### ì™œ LangGraphë¥¼ ì‚¬ìš©í• ê¹Œìš”?\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                LangChain vs LangGraph                             â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   LangChain (ì²´ì¸):                                                â”‚\n",
    "â”‚   ì…ë ¥ â†’ ì²˜ë¦¬1 â†’ ì²˜ë¦¬2 â†’ ì²˜ë¦¬3 â†’ ì¶œë ¥                             â”‚\n",
    "â”‚   (ì¼ì§ì„ ìœ¼ë¡œ íë¦„)                                                â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   LangGraph (ê·¸ë˜í”„):                                              â”‚\n",
    "â”‚                 â”Œâ”€â”€â†’ ì²˜ë¦¬A â”€â”€â”                                     â”‚\n",
    "â”‚   ì…ë ¥ â†’ ë¶„ê¸°ì  â”€â”¼â”€â”€â†’ ì²˜ë¦¬B â”€â”€â”¼â†’ í•©ë¥˜ì  â†’ ì¶œë ¥                     â”‚\n",
    "â”‚                 â””â”€â”€â†’ ì²˜ë¦¬C â”€â”€â”˜                                     â”‚\n",
    "â”‚   (ë³µì¡í•œ íë¦„, ì¡°ê±´ ë¶„ê¸°, ë°˜ë³µ ê°€ëŠ¥)                              â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### StateGraphì˜ êµ¬ì„± ìš”ì†Œ\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                  StateGraphì˜ 3ê°€ì§€ ìš”ì†Œ                           â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   1ï¸âƒ£ State (ìƒíƒœ):                                                â”‚\n",
    "â”‚      â€¢ ê·¸ë˜í”„ ì „ì²´ì—ì„œ ê³µìœ ë˜ëŠ” ë°ì´í„°                              â”‚\n",
    "â”‚      â€¢ ì˜ˆ: ëŒ€í™” ê¸°ë¡, ì‚¬ìš©ì ì •ë³´ ë“±                               â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   2ï¸âƒ£ Node (ë…¸ë“œ):                                                 â”‚\n",
    "â”‚      â€¢ ì‹¤ì œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜                                   â”‚\n",
    "â”‚      â€¢ ì˜ˆ: LLM í˜¸ì¶œ, ê²€ìƒ‰, ê³„ì‚° ë“±                                 â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   3ï¸âƒ£ Edge (ì—£ì§€):                                                 â”‚\n",
    "â”‚      â€¢ ë…¸ë“œ ê°„ì˜ ì—°ê²°                                              â”‚\n",
    "â”‚      â€¢ ì–´ë–¤ ìˆœì„œë¡œ ì‹¤í–‰ë ì§€ ê²°ì •                                   â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "!apt-get install -y zstd\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "subprocess.Popen(['ollama', 'serve'])\n",
    "time.sleep(3)\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. State (ìƒíƒœ) ì •ì˜í•˜ê¸°\n",
    "\n",
    "## TypedDictë€?\n",
    "\n",
    "**TypedDict**ëŠ” ë”•ì…”ë„ˆë¦¬ì˜ í‚¤ì™€ ê°’ íƒ€ì…ì„ ë¯¸ë¦¬ ì •ì˜í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    TypedDict ì‰¬ìš´ ì„¤ëª…                             â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   ì¼ë°˜ ë”•ì…”ë„ˆë¦¬:                                                   â”‚\n",
    "â”‚   data = {\"name\": \"ë¯¼í˜\", \"age\": 25}                              â”‚\n",
    "â”‚   â†’ ì–´ë–¤ í‚¤ê°€ ìˆëŠ”ì§€, ê°’ íƒ€ì…ì´ ë­”ì§€ ëª¨ë¦„                          â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   TypedDict:                                                       â”‚\n",
    "â”‚   class Person(TypedDict):                                         â”‚\n",
    "â”‚       name: str                                                    â”‚\n",
    "â”‚       age: int                                                     â”‚\n",
    "â”‚   â†’ \"nameì€ ë¬¸ìì—´, ageëŠ” ìˆ«ì\"ë¼ê³  ëª…ì‹œ                           â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## add_messagesë€?\n",
    "\n",
    "**add_messages**ëŠ” ë©”ì‹œì§€ë¥¼ **ë®ì–´ì“°ì§€ ì•Šê³  ì¶”ê°€**í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    add_messagesì˜ ì—­í•                              â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   ì¼ë°˜ì ì¸ ë”•ì…”ë„ˆë¦¬ ì—…ë°ì´íŠ¸:                                       â”‚\n",
    "â”‚   state = {\"messages\": [\"ì•ˆë…•\"]}                                   â”‚\n",
    "â”‚   state = {\"messages\": [\"ë°˜ê°€ì›Œ\"]}  # ë®ì–´ì”€!                      â”‚\n",
    "â”‚   ê²°ê³¼: [\"ë°˜ê°€ì›Œ\"] âŒ                                              â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   add_messages ì‚¬ìš©:                                               â”‚\n",
    "â”‚   state = {\"messages\": [\"ì•ˆë…•\"]}                                   â”‚\n",
    "â”‚   state = add_messages([\"ë°˜ê°€ì›Œ\"])  # ì¶”ê°€!                        â”‚\n",
    "â”‚   ê²°ê³¼: [\"ì•ˆë…•\", \"ë°˜ê°€ì›Œ\"] âœ…                                      â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph import add_messages\n",
    "\n",
    "# ìƒíƒœ ì •ì˜\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    ì±—ë´‡ì˜ ìƒíƒœë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    messages: ëŒ€í™” ê¸°ë¡ ë¦¬ìŠ¤íŠ¸\n",
    "    - Annotated[list, add_messages]: ìƒˆ ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì—…ë°ì´íŠ¸\n",
    "    \"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "print(\"âœ… State ì •ì˜ ì™„ë£Œ\")\n",
    "print(\"   - messages: ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Node (ë…¸ë“œ) ì •ì˜í•˜ê¸°\n",
    "\n",
    "ë…¸ë“œëŠ” ì‹¤ì œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. ì±—ë´‡ ë…¸ë“œëŠ” LLMì„ í˜¸ì¶œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# LLM ëª¨ë¸\n",
    "model = ChatOllama(model='llama3.2')\n",
    "\n",
    "def chatbot(state: State):\n",
    "    \"\"\"\n",
    "    ì±—ë´‡ ë…¸ë“œ: LLMì„ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    ì…ë ¥: state (í˜„ì¬ ìƒíƒœ, ëŒ€í™” ê¸°ë¡ í¬í•¨)\n",
    "    ì¶œë ¥: {\"messages\": [ì‘ë‹µ]} (ìƒˆ ë©”ì‹œì§€ë¥¼ ì¶”ê°€)\n",
    "    \"\"\"\n",
    "    # í˜„ì¬ê¹Œì§€ì˜ ëŒ€í™” ê¸°ë¡ìœ¼ë¡œ LLM í˜¸ì¶œ\n",
    "    answer = model.invoke(state['messages'])\n",
    "    \n",
    "    # ì‘ë‹µì„ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    return {'messages': [answer]}\n",
    "\n",
    "print(\"âœ… chatbot ë…¸ë“œ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Graph (ê·¸ë˜í”„) êµ¬ì„±í•˜ê¸°\n",
    "\n",
    "ë…¸ë“œì™€ ì—£ì§€ë¥¼ ì—°ê²°í•˜ì—¬ ê·¸ë˜í”„ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    ì±—ë´‡ ê·¸ë˜í”„ êµ¬ì¡°                                â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                    â”‚\n",
    "â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚\n",
    "â”‚          â”‚  START  â”‚ â”€â”€â”€â–¶ â”‚ chatbot â”‚ â”€â”€â”€â–¶ â”‚   END   â”‚            â”‚\n",
    "â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   START: ê·¸ë˜í”„ ì‹œì‘ì                                              â”‚\n",
    "â”‚   chatbot: LLM í˜¸ì¶œ ë…¸ë“œ                                          â”‚\n",
    "â”‚   END: ê·¸ë˜í”„ ì¢…ë£Œì                                                â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# ê·¸ë˜í”„ ë¹Œë” ìƒì„±\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "# ì²« ë²ˆì§¸ ì¸ì: ë…¸ë“œ ì´ë¦„ (ê³ ìœ í•´ì•¼ í•¨)\n",
    "# ë‘ ë²ˆì§¸ ì¸ì: ì‹¤í–‰í•  í•¨ìˆ˜\n",
    "builder.add_node('chatbot', chatbot)\n",
    "\n",
    "# ì—£ì§€ ì¶”ê°€ (ë…¸ë“œ ê°„ ì—°ê²°)\n",
    "builder.add_edge(START, 'chatbot')  # ì‹œì‘ â†’ ì±—ë´‡\n",
    "builder.add_edge('chatbot', END)     # ì±—ë´‡ â†’ ì¢…ë£Œ\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "graph = builder.compile()\n",
    "\n",
    "print(\"âœ… ê·¸ë˜í”„ êµ¬ì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ê·¸ë˜í”„ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ Mermaid í˜•ì‹ìœ¼ë¡œ ì¶œë ¥\n",
    "print(\"=== ê·¸ë˜í”„ êµ¬ì¡° (Mermaid) ===\")\n",
    "print(graph.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. ê·¸ë˜í”„ ì‹¤í–‰\n",
    "\n",
    "## stream vs invoke\n",
    "\n",
    "| ë©”ì„œë“œ | ë™ì‘ | ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ |\n",
    "|--------|------|---------------|\n",
    "| **invoke** | ìµœì¢… ê²°ê³¼ë§Œ ë°˜í™˜ | ê²°ê³¼ë§Œ í•„ìš”í•  ë•Œ |\n",
    "| **stream** | ë‹¨ê³„ë³„ ê²°ê³¼ ë°˜í™˜ | ì§„í–‰ ìƒí™©ì„ ë³´ê³  ì‹¶ì„ ë•Œ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# ì…ë ¥ ì¤€ë¹„\n",
    "input_message = {'messages': [HumanMessage(content='ì•ˆë…•í•˜ì„¸ìš”!')]}\n",
    "\n",
    "print(\"=== ê·¸ë˜í”„ ì‹¤í–‰ (stream) ===\")\n",
    "print(f\"ì…ë ¥: {input_message}\\n\")\n",
    "\n",
    "# streamìœ¼ë¡œ ì‹¤í–‰ (ë‹¨ê³„ë³„ ì¶œë ¥)\n",
    "for chunk in graph.stream(input_message):\n",
    "    print(f\"ì¶œë ¥: {chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invokeë¡œ ì‹¤í–‰ (ìµœì¢… ê²°ê³¼ë§Œ)\n",
    "result = graph.invoke(input_message)\n",
    "\n",
    "print(\"=== ê·¸ë˜í”„ ì‹¤í–‰ (invoke) ===\")\n",
    "print(f\"\\nìµœì¢… ì‘ë‹µ: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. ì—¬ëŸ¬ ë²ˆ ëŒ€í™”í•´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ëŸ¬ ì§ˆë¬¸ìœ¼ë¡œ í…ŒìŠ¤íŠ¸\n",
    "test_messages = [\n",
    "    \"íŒŒì´ì¬ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë•Œìš”?\",\n",
    "    \"ê°„ë‹¨í•œ íŒŒì´ì¬ ì½”ë“œë¥¼ ë³´ì—¬ì£¼ì„¸ìš”.\",\n",
    "]\n",
    "\n",
    "for msg in test_messages:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ì‚¬ìš©ì: {msg}\")\n",
    "    \n",
    "    result = graph.invoke({'messages': [HumanMessage(content=msg)]})\n",
    "    \n",
    "    print(f\"\\nAI: {result['messages'][-1].content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì •ë¦¬: LangGraph StateGraph\n",
    "\n",
    "### í•µì‹¬ êµ¬ì„±ìš”ì†Œ\n",
    "\n",
    "| êµ¬ì„±ìš”ì†Œ | ì—­í•  | ì˜ˆì‹œ |\n",
    "|----------|------|------|\n",
    "| **State** | ê³µìœ  ë°ì´í„° ì •ì˜ | `messages: list` |\n",
    "| **Node** | ì‘ì—… ìˆ˜í–‰ í•¨ìˆ˜ | `chatbot()` |\n",
    "| **Edge** | ë…¸ë“œ ê°„ ì—°ê²° | `START â†’ chatbot â†’ END` |\n",
    "\n",
    "### í•µì‹¬ ì½”ë“œ\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph, START, END, add_messages\n",
    "\n",
    "# 1. ìƒíƒœ ì •ì˜\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# 2. ë…¸ë“œ í•¨ìˆ˜ ì •ì˜\n",
    "def chatbot(state: State):\n",
    "    answer = model.invoke(state['messages'])\n",
    "    return {'messages': [answer]}\n",
    "\n",
    "# 3. ê·¸ë˜í”„ êµ¬ì„±\n",
    "builder = StateGraph(State)\n",
    "builder.add_node('chatbot', chatbot)\n",
    "builder.add_edge(START, 'chatbot')\n",
    "builder.add_edge('chatbot', END)\n",
    "\n",
    "# 4. ì»´íŒŒì¼ ë° ì‹¤í–‰\n",
    "graph = builder.compile()\n",
    "result = graph.invoke({'messages': [...]})\n",
    "```\n",
    "\n",
    "### LangGraphì˜ ì¥ì \n",
    "\n",
    "| ì¥ì  | ì„¤ëª… |\n",
    "|------|------|\n",
    "| **ìƒíƒœ ê´€ë¦¬** | Stateë¡œ ë°ì´í„° íë¦„ ëª…í™•íˆ ê´€ë¦¬ |\n",
    "| **í™•ì¥ì„±** | ë…¸ë“œ ì¶”ê°€ë¡œ ê¸°ëŠ¥ í™•ì¥ ìš©ì´ |\n",
    "| **ì‹œê°í™”** | ê·¸ë˜í”„ êµ¬ì¡° ì‹œê°ì  í™•ì¸ ê°€ëŠ¥ |\n",
    "| **ìœ ì—°ì„±** | ì¡°ê±´ ë¶„ê¸°, ë°˜ë³µ ë“± ë³µì¡í•œ íë¦„ êµ¬í˜„ |\n",
    "\n",
    "## ì½”ë“œ ë³€ê²½ì  (OpenAI â†’ Ollama)\n",
    "\n",
    "```python\n",
    "# ì›ë³¸\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "# ë³€ê²½\n",
    "from langchain_ollama import ChatOllama\n",
    "model = ChatOllama(model='llama3.2')\n",
    "```\n",
    "\n",
    "## ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "**MemorySaver**ë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ê¸°ë¡ì„ **ì˜êµ¬ ì €ì¥**í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤. (07-10ë²ˆ ë…¸íŠ¸ë¶)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## ì½”ë“œ 4-7~4-10 ì˜ì†ì  ë©”ëª¨ë¦¬: ëŒ€í™” ê¸°ë¡ ì €ì¥í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì˜ì†ì  ë©”ëª¨ë¦¬: ëŒ€í™” ê¸°ë¡ ì €ì¥í•˜ê¸°\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **MemorySaver**ë¥¼ ì‚¬ìš©í•˜ì—¬ **ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ê³  ë³µì›**í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n",
    "\n",
    "## ì˜ì†ì„±(Persistence)ì´ë€?\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚               ì˜ì†ì„± ì—†ìŒ vs ì˜ì†ì„± ìˆìŒ                           â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   ì˜ì†ì„± ì—†ìŒ (ì´ì „ ë…¸íŠ¸ë¶):                                        â”‚\n",
    "â”‚   â€¢ í”„ë¡œê·¸ë¨ ì¢…ë£Œ â†’ ëŒ€í™” ê¸°ë¡ ì‚¬ë¼ì§ ğŸ’¨                            â”‚\n",
    "â”‚   â€¢ ë‹¤ì‹œ ì‹œì‘í•˜ë©´ ì²˜ìŒë¶€í„°                                         â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   ì˜ì†ì„± ìˆìŒ (ì´ ë…¸íŠ¸ë¶):                                          â”‚\n",
    "â”‚   â€¢ í”„ë¡œê·¸ë¨ ì¢…ë£Œ â†’ ëŒ€í™” ê¸°ë¡ ì €ì¥ë¨ ğŸ’¾                            â”‚\n",
    "â”‚   â€¢ ë‹¤ì‹œ ì‹œì‘í•´ë„ ì´ì „ ëŒ€í™” ê¸°ì–µ                                   â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## Thread IDë€?\n",
    "\n",
    "**Thread ID**ëŠ” ëŒ€í™”ë¥¼ êµ¬ë¶„í•˜ëŠ” ê³ ìœ  ì‹ë³„ìì…ë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    Thread IDì˜ ì—­í•                                 â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   ì¹´ì¹´ì˜¤í†¡ ì±„íŒ…ë°©ì²˜ëŸ¼ ìƒê°í•˜ì„¸ìš”!                                   â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   Thread 1 (ì¹œêµ¬Aì™€ ëŒ€í™”):                                         â”‚\n",
    "â”‚   â”œâ”€ \"ì˜¤ëŠ˜ ë­í•´?\"                                                  â”‚\n",
    "â”‚   â”œâ”€ \"ì˜í™” ë³´ëŸ¬ ê°€ì\"                                              â”‚\n",
    "â”‚   â””â”€ \"ì¢‹ì•„!\"                                                       â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   Thread 2 (ì¹œêµ¬Bì™€ ëŒ€í™”):                                         â”‚\n",
    "â”‚   â”œâ”€ \"ìˆ™ì œ í–ˆì–´?\"                                                  â”‚\n",
    "â”‚   â””â”€ \"ì•„ì§...\"                                                     â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   â†’ ê° ThreadëŠ” ë…ë¦½ì ì¸ ëŒ€í™” ê¸°ë¡ì„ ê°€ì§                          â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "!apt-get install -y zstd\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "subprocess.Popen(['ollama', 'serve'])\n",
    "time.sleep(3)\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ê·¸ë˜í”„ êµ¬ì„± (ì´ì „ ë…¸íŠ¸ë¶ê³¼ ë™ì¼)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, START, END, add_messages\n",
    "\n",
    "# ìƒíƒœ ì •ì˜\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# ê·¸ë˜í”„ ë¹Œë”\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# LLM ëª¨ë¸\n",
    "model = ChatOllama(model='llama3.2')\n",
    "\n",
    "# ì±—ë´‡ ë…¸ë“œ\n",
    "def chatbot(state: State):\n",
    "    answer = model.invoke(state['messages'])\n",
    "    return {'messages': [answer]}\n",
    "\n",
    "# ë…¸ë“œì™€ ì—£ì§€ ì¶”ê°€\n",
    "builder.add_node('chatbot', chatbot)\n",
    "builder.add_edge(START, 'chatbot')\n",
    "builder.add_edge('chatbot', END)\n",
    "\n",
    "print(\"âœ… ê·¸ë˜í”„ êµ¬ì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MemorySaverë¡œ ì˜ì†ì„± ì¶”ê°€\n",
    "\n",
    "**MemorySaver**ëŠ” ëŒ€í™” ìƒíƒœë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    MemorySaverì˜ ì—­í•                               â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   ê·¸ë˜í”„ ì‹¤í–‰ ì‹œ:                                                  â”‚\n",
    "â”‚   1. ì…ë ¥ ë©”ì‹œì§€ ì²˜ë¦¬                                              â”‚\n",
    "â”‚   2. ë…¸ë“œ ì‹¤í–‰                                                     â”‚\n",
    "â”‚   3. ê²°ê³¼ë¥¼ MemorySaverì— ì €ì¥ â† ì—¬ê¸°ê°€ í•µì‹¬!                      â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   ë‹¤ìŒ ì‹¤í–‰ ì‹œ:                                                    â”‚\n",
    "â”‚   1. MemorySaverì—ì„œ ì´ì „ ìƒíƒœ ë¶ˆëŸ¬ì˜¤ê¸°                            â”‚\n",
    "â”‚   2. ìƒˆ ë©”ì‹œì§€ì™€ í•©ì³ì„œ ì²˜ë¦¬                                       â”‚\n",
    "â”‚   3. ê²°ê³¼ ë‹¤ì‹œ ì €ì¥                                                â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# MemorySaver ìƒì„±\n",
    "memory = MemorySaver()\n",
    "\n",
    "# checkpointer ì˜µì…˜ê³¼ í•¨ê»˜ ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "print(\"âœ… ì˜ì†ì„±ì´ ì¶”ê°€ëœ ê·¸ë˜í”„ ì»´íŒŒì¼ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Thread IDë¥¼ ì‚¬ìš©í•œ ëŒ€í™”\n",
    "\n",
    "ê°™ì€ Thread IDë¥¼ ì‚¬ìš©í•˜ë©´ ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thread ì„¤ì • (ëŒ€í™”ë°© IDë¼ê³  ìƒê°í•˜ì„¸ìš”)\n",
    "thread1 = {'configurable': {'thread_id': '1'}}\n",
    "\n",
    "print(\"=== Thread 1ì—ì„œ ëŒ€í™” ===\")\n",
    "\n",
    "# ì²« ë²ˆì§¸ ëŒ€í™”\n",
    "print(\"\\n[ëŒ€í™” 1]\")\n",
    "print(\"ì‚¬ìš©ì: ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ë¯¼í˜ì…ë‹ˆë‹¤!\")\n",
    "result1 = graph.invoke(\n",
    "    {'messages': [HumanMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ë¯¼í˜ì…ë‹ˆë‹¤!')]},\n",
    "    thread1  # Thread ID ì „ë‹¬\n",
    ")\n",
    "print(f\"AI: {result1['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‘ ë²ˆì§¸ ëŒ€í™” (ê°™ì€ Thread)\n",
    "print(\"\\n[ëŒ€í™” 2]\")\n",
    "print(\"ì‚¬ìš©ì: ì œ ì´ë¦„ì´ ë­ì£ ?\")\n",
    "result2 = graph.invoke(\n",
    "    {'messages': [HumanMessage(content='ì œ ì´ë¦„ì´ ë­ì£ ?')]},\n",
    "    thread1  # ê°™ì€ Thread ID\n",
    ")\n",
    "print(f\"AI: {result2['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\nâœ… ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•©ë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ìƒíƒœ í™•ì¸í•˜ê¸°\n",
    "\n",
    "í˜„ì¬ ì €ì¥ëœ ëŒ€í™” ìƒíƒœë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜„ì¬ ìƒíƒœ í™•ì¸\n",
    "state = graph.get_state(thread1)\n",
    "\n",
    "print(\"=== í˜„ì¬ Thread 1ì˜ ìƒíƒœ ===\")\n",
    "print(f\"\\në©”ì‹œì§€ ìˆ˜: {len(state.values['messages'])}ê°œ\\n\")\n",
    "\n",
    "for i, msg in enumerate(state.values['messages']):\n",
    "    role = \"ì‚¬ìš©ì\" if msg.type == \"human\" else \"AI\"\n",
    "    content = msg.content[:50] + \"...\" if len(msg.content) > 50 else msg.content\n",
    "    print(f\"[{i+1}] {role}: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. ìƒíƒœ ì—…ë°ì´íŠ¸í•˜ê¸°\n",
    "\n",
    "ëŒ€í™” ê¸°ë¡ì„ ìˆ˜ë™ìœ¼ë¡œ ìˆ˜ì •í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒíƒœ ì—…ë°ì´íŠ¸ (ìƒˆ ë©”ì‹œì§€ ì¶”ê°€)\n",
    "graph.update_state(\n",
    "    thread1,\n",
    "    {'messages': [HumanMessage(content='ì €ëŠ” LLMì´ ì¢‹ì•„ìš”!')]}\n",
    ")\n",
    "\n",
    "print(\"âœ… ìƒíƒœ ì—…ë°ì´íŠ¸ ì™„ë£Œ\")\n",
    "\n",
    "# ì—…ë°ì´íŠ¸ëœ ìƒíƒœ í™•ì¸\n",
    "state = graph.get_state(thread1)\n",
    "print(f\"\\nì—…ë°ì´íŠ¸ í›„ ë©”ì‹œì§€ ìˆ˜: {len(state.values['messages'])}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. ë‹¤ë¥¸ Threadì—ì„œ ëŒ€í™”\n",
    "\n",
    "Thread IDê°€ ë‹¤ë¥´ë©´ ì™„ì „íˆ ë…ë¦½ì ì¸ ëŒ€í™”ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ë¥¸ Thread\n",
    "thread2 = {'configurable': {'thread_id': '2'}}\n",
    "\n",
    "print(\"=== Thread 2ì—ì„œ ëŒ€í™” (ìƒˆë¡œìš´ ëŒ€í™”) ===\")\n",
    "\n",
    "print(\"\\nì‚¬ìš©ì: ì œ ì´ë¦„ì´ ë­ì£ ?\")\n",
    "result = graph.invoke(\n",
    "    {'messages': [HumanMessage(content='ì œ ì´ë¦„ì´ ë­ì£ ?')]},\n",
    "    thread2  # ë‹¤ë¥¸ Thread ID\n",
    ")\n",
    "print(f\"AI: {result['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\nâ†’ Thread 2ëŠ” Thread 1ì˜ ëŒ€í™”ë¥¼ ëª¨ë¦…ë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thread 1ë¡œ ëŒì•„ê°€ë©´ ì—¬ì „íˆ ê¸°ì–µí•¨\n",
    "print(\"=== ë‹¤ì‹œ Thread 1ë¡œ ëŒì•„ê°€ê¸° ===\")\n",
    "\n",
    "print(\"\\nì‚¬ìš©ì: ì œê°€ ì¢‹ì•„í•˜ëŠ” ê²Œ ë­ë¼ê³  í–ˆì£ ?\")\n",
    "result = graph.invoke(\n",
    "    {'messages': [HumanMessage(content='ì œê°€ ì¢‹ì•„í•˜ëŠ” ê²Œ ë­ë¼ê³  í–ˆì£ ?')]},\n",
    "    thread1  # ë‹¤ì‹œ Thread 1\n",
    ")\n",
    "print(f\"AI: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì •ë¦¬: ì˜ì†ì  ë©”ëª¨ë¦¬\n",
    "\n",
    "### í•µì‹¬ ê°œë…\n",
    "\n",
    "| ê°œë… | ì„¤ëª… | ë¹„ìœ  |\n",
    "|------|------|------|\n",
    "| **MemorySaver** | ìƒíƒœë¥¼ ì €ì¥í•˜ëŠ” ë„êµ¬ | ì €ì¥ ë²„íŠ¼ |\n",
    "| **Thread ID** | ëŒ€í™”ë¥¼ êµ¬ë¶„í•˜ëŠ” ID | ì±„íŒ…ë°© ë²ˆí˜¸ |\n",
    "| **checkpointer** | ì €ì¥ ë„êµ¬ ì—°ê²° ì˜µì…˜ | ìë™ ì €ì¥ ì„¤ì • |\n",
    "| **get_state** | ì €ì¥ëœ ìƒíƒœ ì¡°íšŒ | ê¸°ë¡ ë³´ê¸° |\n",
    "| **update_state** | ìƒíƒœ ìˆ˜ë™ ìˆ˜ì • | ê¸°ë¡ í¸ì§‘ |\n",
    "\n",
    "### í•µì‹¬ ì½”ë“œ\n",
    "\n",
    "```python\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 1. MemorySaver ìƒì„±\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 2. checkpointerì™€ í•¨ê»˜ ì»´íŒŒì¼\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "# 3. Thread IDì™€ í•¨ê»˜ ì‹¤í–‰\n",
    "thread = {'configurable': {'thread_id': '1'}}\n",
    "result = graph.invoke({'messages': [...]}, thread)\n",
    "\n",
    "# 4. ìƒíƒœ ì¡°íšŒ\n",
    "state = graph.get_state(thread)\n",
    "\n",
    "# 5. ìƒíƒœ ì—…ë°ì´íŠ¸\n",
    "graph.update_state(thread, {'messages': [...]})\n",
    "```\n",
    "\n",
    "### ì£¼ì˜ì‚¬í•­\n",
    "\n",
    "| í•­ëª© | MemorySaver íŠ¹ì„± |\n",
    "|------|------------------|\n",
    "| **ì €ì¥ ìœ„ì¹˜** | ë©”ëª¨ë¦¬ (RAM) |\n",
    "| **í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ** | ë°ì´í„° ì‚¬ë¼ì§ |\n",
    "| **ì˜êµ¬ ì €ì¥ í•„ìš” ì‹œ** | SQLite, PostgreSQL ë“± ì‚¬ìš© |\n",
    "\n",
    "## ì½”ë“œ ë³€ê²½ì  (OpenAI â†’ Ollama)\n",
    "\n",
    "```python\n",
    "# ì›ë³¸\n",
    "model = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "# ë³€ê²½\n",
    "model = ChatOllama(model='llama3.2')\n",
    "```\n",
    "\n",
    "## ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "ëŒ€í™”ê°€ ê¸¸ì–´ì§ˆ ë•Œ **ë©”ì‹œì§€ë¥¼ ìë¥´ëŠ”(Trim)** ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤. (11ë²ˆ ë…¸íŠ¸ë¶)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## ì½”ë“œ 4-11 ë©”ì‹œì§€ ìë¥´ê¸° (Trim Messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë©”ì‹œì§€ ìë¥´ê¸° (Trim Messages)\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **ëŒ€í™”ê°€ ê¸¸ì–´ì§ˆ ë•Œ ë©”ì‹œì§€ë¥¼ ìë¥´ëŠ”** ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n",
    "\n",
    "## ì™œ ë©”ì‹œì§€ë¥¼ ì˜ë¼ì•¼ í• ê¹Œìš”?\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    í† í° ì œí•œ ë¬¸ì œ                                  â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   LLMì˜ í•œê³„:                                                      â”‚\n",
    "â”‚   â€¢ í•œ ë²ˆì— ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í† í° ìˆ˜ê°€ ì œí•œë¨                         â”‚\n",
    "â”‚   â€¢ GPT-4: ~128K í† í°, Llama: ~8K í† í°                             â”‚\n",
    "â”‚   â€¢ ëŒ€í™”ê°€ ê¸¸ì–´ì§€ë©´ í•œë„ ì´ˆê³¼!                                      â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   í•´ê²°ì±…:                                                          â”‚\n",
    "â”‚   â€¢ ì˜¤ë˜ëœ ë©”ì‹œì§€ ì‚­ì œ                                              â”‚\n",
    "â”‚   â€¢ ìµœê·¼ ë©”ì‹œì§€ë§Œ ìœ ì§€                                              â”‚\n",
    "â”‚   â€¢ ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” í•­ìƒ ìœ ì§€                                       â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## trim_messagesì˜ ì „ëµ\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                 trim_messages ì „ëµ ë¹„êµ                            â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   strategy='last' (ê¸°ë³¸):                                          â”‚\n",
    "â”‚   [ì‹œìŠ¤í…œ] [ë©”ì‹œì§€1] [ë©”ì‹œì§€2] [ë©”ì‹œì§€3] [ë©”ì‹œì§€4] [ë©”ì‹œì§€5]        â”‚\n",
    "â”‚              â†“         â†“                                          â”‚\n",
    "â”‚            ì‚­ì œ       ì‚­ì œ                                         â”‚\n",
    "â”‚   ê²°ê³¼: [ì‹œìŠ¤í…œ] [ë©”ì‹œì§€3] [ë©”ì‹œì§€4] [ë©”ì‹œì§€5]                      â”‚\n",
    "â”‚   â†’ ìµœê·¼ ë©”ì‹œì§€ ìœ ì§€                                               â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   strategy='first':                                                â”‚\n",
    "â”‚   [ì‹œìŠ¤í…œ] [ë©”ì‹œì§€1] [ë©”ì‹œì§€2] [ë©”ì‹œì§€3] [ë©”ì‹œì§€4] [ë©”ì‹œì§€5]        â”‚\n",
    "â”‚                                         â†“         â†“               â”‚\n",
    "â”‚                                       ì‚­ì œ       ì‚­ì œ              â”‚\n",
    "â”‚   ê²°ê³¼: [ì‹œìŠ¤í…œ] [ë©”ì‹œì§€1] [ë©”ì‹œì§€2] [ë©”ì‹œì§€3]                      â”‚\n",
    "â”‚   â†’ ì´ˆê¸° ë©”ì‹œì§€ ìœ ì§€                                               â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "!apt-get install -y zstd\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "subprocess.Popen(['ollama', 'serve'])\n",
    "time.sleep(3)\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ìƒ˜í”Œ ë©”ì‹œì§€ ì¤€ë¹„\n",
    "\n",
    "ê¸´ ëŒ€í™” ê¸°ë¡ì„ ë§Œë“¤ì–´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage,\n",
    ")\n",
    "\n",
    "# ê¸´ ëŒ€í™” ê¸°ë¡ (11ê°œ ë©”ì‹œì§€)\n",
    "messages = [\n",
    "    SystemMessage(content='ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.'),\n",
    "    HumanMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ë‚˜ëŠ” ë¯¼í˜ì…ë‹ˆë‹¤.'),\n",
    "    AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”!'),\n",
    "    HumanMessage(content='ë°”ë‹ë¼ ì•„ì´ìŠ¤í¬ë¦¼ì„ ì¢‹ì•„í•´ìš”.'),\n",
    "    AIMessage(content='ì¢‹ë„¤ìš”!'),\n",
    "    HumanMessage(content='2 + 2ëŠ” ì–¼ë§ˆì£ ?'),\n",
    "    AIMessage(content='4ì…ë‹ˆë‹¤.'),\n",
    "    HumanMessage(content='ê³ ë§ˆì›Œìš”.'),\n",
    "    AIMessage(content='ì²œë§Œì—ìš”!'),\n",
    "    HumanMessage(content='ì¦ê±°ìš´ê°€ìš”?'),\n",
    "    AIMessage(content='ì˜ˆ!'),\n",
    "]\n",
    "\n",
    "print(f\"ì´ ë©”ì‹œì§€ ìˆ˜: {len(messages)}ê°œ\\n\")\n",
    "print(\"=== ì „ì²´ ëŒ€í™” ê¸°ë¡ ===\")\n",
    "for i, msg in enumerate(messages):\n",
    "    role = msg.type\n",
    "    print(f\"[{i+1}] {role}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. trim_messages ì‚¬ìš©í•˜ê¸°\n",
    "\n",
    "## ì£¼ìš” ì˜µì…˜ ì„¤ëª…\n",
    "\n",
    "| ì˜µì…˜ | ì„¤ëª… | ì˜ˆì‹œ |\n",
    "|------|------|------|\n",
    "| **max_tokens** | ìµœëŒ€ í† í° ìˆ˜ | 65 |\n",
    "| **strategy** | ìë¥´ê¸° ì „ëµ | 'last' (ìµœê·¼ ìœ ì§€) |\n",
    "| **token_counter** | í† í° ê³„ì‚° ëª¨ë¸ | LLM ëª¨ë¸ |\n",
    "| **include_system** | ì‹œìŠ¤í…œ ë©”ì‹œì§€ í¬í•¨ | True |\n",
    "| **allow_partial** | ë©”ì‹œì§€ ë¶€ë¶„ ìë¥´ê¸° í—ˆìš© | False |\n",
    "| **start_on** | ì‹œì‘ ë©”ì‹œì§€ ìœ í˜• | 'human' |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import trim_messages\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# LLM ëª¨ë¸ (í† í° ê³„ì‚°ìš©)\n",
    "model = ChatOllama(model='llama3.2')\n",
    "\n",
    "# trimmer ì„¤ì •\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=65,              # ìµœëŒ€ 65 í† í°ë§Œ ìœ ì§€\n",
    "    strategy='last',            # ìµœê·¼ ë©”ì‹œì§€ ìš°ì„  ìœ ì§€\n",
    "    token_counter=model,        # í† í° ê³„ì‚°ì— ì‚¬ìš©í•  ëª¨ë¸\n",
    "    include_system=True,        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” í•­ìƒ í¬í•¨\n",
    "    allow_partial=False,        # ë©”ì‹œì§€ë¥¼ ì¤‘ê°„ì— ìë¥´ì§€ ì•ŠìŒ\n",
    "    start_on='human',           # human ë©”ì‹œì§€ë¡œ ì‹œì‘\n",
    ")\n",
    "\n",
    "print(\"âœ… trimmer ì„¤ì • ì™„ë£Œ\")\n",
    "print(\"   - ìµœëŒ€ 65 í† í°\")\n",
    "print(\"   - ìµœê·¼ ë©”ì‹œì§€ ìœ ì§€ ì „ëµ\")\n",
    "print(\"   - ì‹œìŠ¤í…œ ë©”ì‹œì§€ í•­ìƒ í¬í•¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ë©”ì‹œì§€ ìë¥´ê¸° ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim ì ìš©\n",
    "trimmed = trimmer.invoke(messages)\n",
    "\n",
    "print(f\"ì›ë³¸ ë©”ì‹œì§€ ìˆ˜: {len(messages)}ê°œ\")\n",
    "print(f\"ìë¥¸ í›„ ë©”ì‹œì§€ ìˆ˜: {len(trimmed)}ê°œ\\n\")\n",
    "\n",
    "print(\"=== ìë¥¸ í›„ ëŒ€í™” ê¸°ë¡ ===\")\n",
    "for i, msg in enumerate(trimmed):\n",
    "    role = msg.type\n",
    "    print(f\"[{i+1}] {role}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ë‹¤ì–‘í•œ ì„¤ì • í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë” ë§ì€ í† í° í—ˆìš©\n",
    "trimmer_large = trim_messages(\n",
    "    max_tokens=100,\n",
    "    strategy='last',\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    ")\n",
    "\n",
    "trimmed_large = trimmer_large.invoke(messages)\n",
    "\n",
    "print(\"=== max_tokens=100 ===\")\n",
    "print(f\"ë©”ì‹œì§€ ìˆ˜: {len(trimmed_large)}ê°œ\")\n",
    "for msg in trimmed_large:\n",
    "    print(f\"  {msg.type}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy='first' í…ŒìŠ¤íŠ¸ (ì´ˆê¸° ë©”ì‹œì§€ ìœ ì§€)\n",
    "trimmer_first = trim_messages(\n",
    "    max_tokens=65,\n",
    "    strategy='first',           # ì´ˆê¸° ë©”ì‹œì§€ ìœ ì§€\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    ")\n",
    "\n",
    "trimmed_first = trimmer_first.invoke(messages)\n",
    "\n",
    "print(\"\\n=== strategy='first' ===\")\n",
    "print(f\"ë©”ì‹œì§€ ìˆ˜: {len(trimmed_first)}ê°œ\")\n",
    "for msg in trimmed_first:\n",
    "    print(f\"  {msg.type}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. ì²´ì¸ì—ì„œ trimmer ì‚¬ìš©í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# trimmerë¥¼ ì²´ì¸ì˜ ì¼ë¶€ë¡œ ì‚¬ìš©\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('placeholder', '{messages}'),\n",
    "])\n",
    "\n",
    "# ì²´ì¸: trimmer â†’ prompt â†’ model\n",
    "chain = trimmer | prompt | model\n",
    "\n",
    "print(\"âœ… trimmerê°€ í¬í•¨ëœ ì²´ì¸ ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´ì¸ ì‹¤í–‰\n",
    "result = chain.invoke(messages)\n",
    "\n",
    "print(\"=== ì²´ì¸ ì‹¤í–‰ ê²°ê³¼ ===\")\n",
    "print(f\"AI ì‘ë‹µ: {result.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì •ë¦¬: ë©”ì‹œì§€ ìë¥´ê¸° (trim_messages)\n",
    "\n",
    "### ì£¼ìš” ì˜µì…˜\n",
    "\n",
    "| ì˜µì…˜ | ê¸°ë³¸ê°’ | ì„¤ëª… |\n",
    "|------|--------|------|\n",
    "| **max_tokens** | í•„ìˆ˜ | ìœ ì§€í•  ìµœëŒ€ í† í° ìˆ˜ |\n",
    "| **strategy** | 'last' | 'last': ìµœê·¼ ìœ ì§€, 'first': ì´ˆê¸° ìœ ì§€ |\n",
    "| **token_counter** | í•„ìˆ˜ | í† í° ê³„ì‚°ì— ì‚¬ìš©í•  ëª¨ë¸/í•¨ìˆ˜ |\n",
    "| **include_system** | False | ì‹œìŠ¤í…œ ë©”ì‹œì§€ í•­ìƒ í¬í•¨ ì—¬ë¶€ |\n",
    "| **allow_partial** | False | ë©”ì‹œì§€ ì¤‘ê°„ ìë¥´ê¸° í—ˆìš© |\n",
    "| **start_on** | None | ì‹œì‘í•´ì•¼ í•  ë©”ì‹œì§€ ìœ í˜• |\n",
    "\n",
    "### í•µì‹¬ ì½”ë“œ\n",
    "\n",
    "```python\n",
    "from langchain_core.messages import trim_messages\n",
    "\n",
    "# 1. trimmer ìƒì„±\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=100,\n",
    "    strategy='last',\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    ")\n",
    "\n",
    "# 2. ë©”ì‹œì§€ ìë¥´ê¸°\n",
    "trimmed = trimmer.invoke(messages)\n",
    "\n",
    "# 3. ì²´ì¸ì—ì„œ ì‚¬ìš©\n",
    "chain = trimmer | prompt | model\n",
    "```\n",
    "\n",
    "### ì „ëµ ì„ íƒ ê°€ì´ë“œ\n",
    "\n",
    "| ìƒí™© | ì¶”ì²œ ì „ëµ |\n",
    "|------|----------|\n",
    "| ì¼ë°˜ ëŒ€í™” | `strategy='last'` (ìµœê·¼ ë§¥ë½ ì¤‘ìš”) |\n",
    "| ë¬¸ì„œ ìš”ì•½ | `strategy='first'` (ì´ˆê¸° ë‚´ìš© ì¤‘ìš”) |\n",
    "| ì‹œìŠ¤í…œ ì§€ì‹œ ì¤‘ìš” | `include_system=True` |\n",
    "\n",
    "## ì½”ë“œ ë³€ê²½ì  (OpenAI â†’ Ollama)\n",
    "\n",
    "```python\n",
    "# ì›ë³¸\n",
    "from langchain_openai import ChatOpenAI\n",
    "token_counter = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "# ë³€ê²½\n",
    "from langchain_ollama import ChatOllama\n",
    "token_counter = ChatOllama(model='llama3.2')\n",
    "```\n",
    "\n",
    "## ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "**ë©”ì‹œì§€ë¥¼ ìœ í˜•ë³„ë¡œ í•„í„°ë§**í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤. (12-14ë²ˆ ë…¸íŠ¸ë¶)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## ì½”ë“œ 4-12~4-14 ë©”ì‹œì§€ í•„í„°ë§ (Filter Messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë©”ì‹œì§€ í•„í„°ë§ (Filter Messages)\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **íŠ¹ì • ì¡°ê±´ì— ë§ëŠ” ë©”ì‹œì§€ë§Œ ì„ íƒ**í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n",
    "\n",
    "## í•„í„°ë§ì´ë€?\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    í•„í„°ë§ì˜ ë‹¤ì–‘í•œ ê¸°ì¤€                            â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   í•„í„°ë§ ê¸°ì¤€:                                                     â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   1ï¸âƒ£ ìœ í˜•(Type)ìœ¼ë¡œ í•„í„°ë§                                        â”‚\n",
    "â”‚      â€¢ human ë©”ì‹œì§€ë§Œ ì¶”ì¶œ                                         â”‚\n",
    "â”‚      â€¢ AI ë©”ì‹œì§€ë§Œ ì¶”ì¶œ                                            â”‚\n",
    "â”‚      â€¢ system ë©”ì‹œì§€ ì œì™¸                                          â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   2ï¸âƒ£ ì´ë¦„(Name)ìœ¼ë¡œ í•„í„°ë§                                        â”‚\n",
    "â”‚      â€¢ íŠ¹ì • ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë§Œ                                      â”‚\n",
    "â”‚      â€¢ ì˜ˆì‹œ ë©”ì‹œì§€ ì œì™¸                                            â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   3ï¸âƒ£ IDë¡œ í•„í„°ë§                                                  â”‚\n",
    "â”‚      â€¢ íŠ¹ì • IDì˜ ë©”ì‹œì§€ í¬í•¨/ì œì™¸                                  â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## ì–¸ì œ í•„í„°ë§ì´ í•„ìš”í• ê¹Œìš”?\n",
    "\n",
    "| ìƒí™© | í•„í„°ë§ ë°©ë²• |\n",
    "|------|------------|\n",
    "| Few-shot ì˜ˆì‹œ ì œê±° | ì˜ˆì‹œ ì´ë¦„ìœ¼ë¡œ ì œì™¸ |\n",
    "| ì‚¬ìš©ì ë°œì–¸ë§Œ ë¶„ì„ | human ìœ í˜•ë§Œ í¬í•¨ |\n",
    "| íŠ¹ì • ëŒ€í™” ì œì™¸ | IDë¡œ ì œì™¸ |\n",
    "\n",
    "---\n",
    "\n",
    "# 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "!apt-get install -y zstd\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "subprocess.Popen(['ollama', 'serve'])\n",
    "time.sleep(3)\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ìƒ˜í”Œ ë©”ì‹œì§€ ì¤€ë¹„\n",
    "\n",
    "ë‹¤ì–‘í•œ ì†ì„±ì„ ê°€ì§„ ë©”ì‹œì§€ë“¤ì„ ì¤€ë¹„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "\n",
    "# ë‹¤ì–‘í•œ ì†ì„±ì„ ê°€ì§„ ë©”ì‹œì§€ë“¤\n",
    "messages = [\n",
    "    SystemMessage(content='ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.', id='1'),\n",
    "    HumanMessage(content='ì˜ˆì‹œ ì…ë ¥', id='2', name='example_user'),      # ì˜ˆì‹œ ë©”ì‹œì§€\n",
    "    AIMessage(content='ì˜ˆì‹œ ì¶œë ¥', id='3', name='example_assistant'),    # ì˜ˆì‹œ ë©”ì‹œì§€\n",
    "    HumanMessage(content='ì‹¤ì œ ì…ë ¥', id='4', name='bob'),               # ì‹¤ì œ ì‚¬ìš©ì\n",
    "    AIMessage(content='ì‹¤ì œ ì¶œë ¥', id='5', name='alice'),                # ì‹¤ì œ AI\n",
    "]\n",
    "\n",
    "print(\"=== ì „ì²´ ë©”ì‹œì§€ ===\")\n",
    "for msg in messages:\n",
    "    name = f\" (name={msg.name})\" if hasattr(msg, 'name') and msg.name else \"\"\n",
    "    print(f\"[{msg.id}] {msg.type}{name}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ìœ í˜•(Type)ìœ¼ë¡œ í•„í„°ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import filter_messages\n",
    "\n",
    "# Human ë©”ì‹œì§€ë§Œ ì¶”ì¶œ\n",
    "human_messages = filter_messages(messages, include_types='human')\n",
    "\n",
    "print(\"=== Human ë©”ì‹œì§€ë§Œ ===\")\n",
    "for msg in human_messages:\n",
    "    print(f\"[{msg.id}] {msg.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI ë©”ì‹œì§€ë§Œ ì¶”ì¶œ\n",
    "ai_messages = filter_messages(messages, include_types='ai')\n",
    "\n",
    "print(\"=== AI ë©”ì‹œì§€ë§Œ ===\")\n",
    "for msg in ai_messages:\n",
    "    print(f\"[{msg.id}] {msg.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ëŸ¬ ìœ í˜• í¬í•¨ (Human + AI)\n",
    "human_ai_messages = filter_messages(messages, include_types=['human', 'ai'])\n",
    "\n",
    "print(\"=== Human + AI ë©”ì‹œì§€ (System ì œì™¸) ===\")\n",
    "for msg in human_ai_messages:\n",
    "    print(f\"[{msg.id}] {msg.type}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ì´ë¦„(Name)ìœ¼ë¡œ í•„í„°ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠ¹ì • ì´ë¦„ ì œì™¸ (ì˜ˆì‹œ ë©”ì‹œì§€ ì œì™¸)\n",
    "excluded_examples = filter_messages(\n",
    "    messages, \n",
    "    exclude_names=['example_user', 'example_assistant']\n",
    ")\n",
    "\n",
    "print(\"=== ì˜ˆì‹œ ë©”ì‹œì§€ ì œì™¸ ===\")\n",
    "for msg in excluded_examples:\n",
    "    name = f\" (name={msg.name})\" if hasattr(msg, 'name') and msg.name else \"\"\n",
    "    print(f\"[{msg.id}] {msg.type}{name}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠ¹ì • ì´ë¦„ë§Œ í¬í•¨\n",
    "bob_messages = filter_messages(\n",
    "    messages,\n",
    "    include_names=['bob']\n",
    ")\n",
    "\n",
    "print(\"=== bobì˜ ë©”ì‹œì§€ë§Œ ===\")\n",
    "for msg in bob_messages:\n",
    "    print(f\"[{msg.id}] {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. IDë¡œ í•„í„°ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠ¹ì • ID ì œì™¸\n",
    "without_id3 = filter_messages(\n",
    "    messages,\n",
    "    exclude_ids=['3']  # IDê°€ '3'ì¸ ë©”ì‹œì§€ ì œì™¸\n",
    ")\n",
    "\n",
    "print(\"=== ID '3' ì œì™¸ ===\")\n",
    "for msg in without_id3:\n",
    "    print(f\"[{msg.id}] {msg.type}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. ë³µí•© ì¡°ê±´ í•„í„°ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœ í˜• + ID ì¡°í•© í•„í„°ë§\n",
    "filtered = filter_messages(\n",
    "    messages,\n",
    "    include_types=['human', 'ai'],  # humanê³¼ aië§Œ\n",
    "    exclude_ids=['3']               # ID '3' ì œì™¸\n",
    ")\n",
    "\n",
    "print(\"=== human/ai ìœ í˜• ì¤‘ ID '3' ì œì™¸ ===\")\n",
    "for msg in filtered:\n",
    "    print(f\"[{msg.id}] {msg.type}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. ì²´ì¸ì—ì„œ í•„í„° ì‚¬ìš©í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# LLM ëª¨ë¸\n",
    "model = ChatOllama(model='llama3.2')\n",
    "\n",
    "# ì˜ˆì‹œ ë©”ì‹œì§€ë¥¼ ì œì™¸í•˜ëŠ” í•„í„°\n",
    "filter_ = filter_messages(exclude_names=['example_user', 'example_assistant'])\n",
    "\n",
    "# ì²´ì¸: í•„í„° â†’ ëª¨ë¸\n",
    "chain = filter_ | model\n",
    "\n",
    "print(\"âœ… í•„í„°ê°€ í¬í•¨ëœ ì²´ì¸ ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´ì¸ ì‹¤í–‰\n",
    "# ì „ì²´ ë©”ì‹œì§€ë¥¼ ì „ë‹¬í•˜ì§€ë§Œ, í•„í„°ê°€ ì˜ˆì‹œ ë©”ì‹œì§€ë¥¼ ì œì™¸í•¨\n",
    "result = chain.invoke(messages)\n",
    "\n",
    "print(\"=== í•„í„° ì²´ì¸ ì‹¤í–‰ ê²°ê³¼ ===\")\n",
    "print(f\"ì…ë ¥: ì „ì²´ {len(messages)}ê°œ ë©”ì‹œì§€\")\n",
    "print(f\"í•„í„° í›„: ì˜ˆì‹œ ë©”ì‹œì§€ ì œì™¸\")\n",
    "print(f\"\\nAI ì‘ë‹µ: {result.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì •ë¦¬: ë©”ì‹œì§€ í•„í„°ë§ (filter_messages)\n",
    "\n",
    "### ì£¼ìš” ì˜µì…˜\n",
    "\n",
    "| ì˜µì…˜ | ì„¤ëª… | ì˜ˆì‹œ |\n",
    "|------|------|------|\n",
    "| **include_types** | í¬í•¨í•  ë©”ì‹œì§€ ìœ í˜• | `'human'`, `['human', 'ai']` |\n",
    "| **exclude_types** | ì œì™¸í•  ë©”ì‹œì§€ ìœ í˜• | `'system'` |\n",
    "| **include_names** | í¬í•¨í•  ì´ë¦„ | `['bob']` |\n",
    "| **exclude_names** | ì œì™¸í•  ì´ë¦„ | `['example_user']` |\n",
    "| **include_ids** | í¬í•¨í•  ID | `['1', '2']` |\n",
    "| **exclude_ids** | ì œì™¸í•  ID | `['3']` |\n",
    "\n",
    "### í•µì‹¬ ì½”ë“œ\n",
    "\n",
    "```python\n",
    "from langchain_core.messages import filter_messages\n",
    "\n",
    "# 1. ìœ í˜•ìœ¼ë¡œ í•„í„°ë§\n",
    "human_msgs = filter_messages(messages, include_types='human')\n",
    "\n",
    "# 2. ì´ë¦„ìœ¼ë¡œ í•„í„°ë§\n",
    "filtered = filter_messages(messages, exclude_names=['example'])\n",
    "\n",
    "# 3. ë³µí•© ì¡°ê±´\n",
    "filtered = filter_messages(\n",
    "    messages,\n",
    "    include_types=['human', 'ai'],\n",
    "    exclude_ids=['3']\n",
    ")\n",
    "\n",
    "# 4. ì²´ì¸ì—ì„œ ì‚¬ìš©\n",
    "filter_ = filter_messages(exclude_names=[...])\n",
    "chain = filter_ | model\n",
    "```\n",
    "\n",
    "### í™œìš© ì‚¬ë¡€\n",
    "\n",
    "| ì‚¬ë¡€ | í•„í„°ë§ ë°©ë²• |\n",
    "|------|------------|\n",
    "| Few-shot ì˜ˆì‹œ ì œê±° | `exclude_names=['example_*']` |\n",
    "| ì‚¬ìš©ì ë°œì–¸ë§Œ ë¶„ì„ | `include_types='human'` |\n",
    "| ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì œì™¸ | `exclude_types='system'` |\n",
    "| íŠ¹ì • ëŒ€í™” ì œì™¸ | `exclude_ids=['id']` |\n",
    "\n",
    "## ì½”ë“œ ë³€ê²½ì  (OpenAI â†’ Ollama)\n",
    "\n",
    "```python\n",
    "# ì›ë³¸\n",
    "model = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "# ë³€ê²½\n",
    "model = ChatOllama(model='llama3.2')\n",
    "```\n",
    "\n",
    "## ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "**ì—°ì†ëœ ê°™ì€ ìœ í˜•ì˜ ë©”ì‹œì§€ë¥¼ ë³‘í•©**í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤. (15-16ë²ˆ ë…¸íŠ¸ë¶)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## ì½”ë“œ 4-15~4-16 ë©”ì‹œì§€ ë³‘í•© (Merge Messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë©”ì‹œì§€ ë³‘í•© (Merge Messages)\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **ì—°ì†ëœ ê°™ì€ ìœ í˜•ì˜ ë©”ì‹œì§€ë¥¼ í•˜ë‚˜ë¡œ ë³‘í•©**í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n",
    "\n",
    "## ì™œ ë©”ì‹œì§€ë¥¼ ë³‘í•©í• ê¹Œìš”?\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    ë©”ì‹œì§€ ë³‘í•©ì´ í•„ìš”í•œ ìƒí™©                        â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   ë¬¸ì œ ìƒí™©:                                                       â”‚\n",
    "â”‚   [System] ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.                         â”‚\n",
    "â”‚   [System] í•­ìƒ ë†ë‹´ìœ¼ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”.      â† ì—°ì†ëœ System ë©”ì‹œì§€   â”‚\n",
    "â”‚   [Human] ì–´ë–¤ í”¼ìê°€ ë§›ìˆë‚˜ìš”?                                    â”‚\n",
    "â”‚   [Human] ì–´ë–¤ í–„ë²„ê±°ê°€ ë§›ìˆë‚˜ìš”?         â† ì—°ì†ëœ Human ë©”ì‹œì§€    â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   ì¼ë¶€ LLMì€ ì—°ì†ëœ ê°™ì€ ìœ í˜•ì˜ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬ ëª»í•¨!                â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   í•´ê²°:                                                            â”‚\n",
    "â”‚   [System] ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. í•­ìƒ ë†ë‹´ìœ¼ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”.â”‚\n",
    "â”‚   [Human] ì–´ë–¤ í”¼ìê°€ ë§›ìˆë‚˜ìš”? ì–´ë–¤ í–„ë²„ê±°ê°€ ë§›ìˆë‚˜ìš”?            â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   â†’ ê°™ì€ ìœ í˜•ì˜ ì—°ì† ë©”ì‹œì§€ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹¨!                         â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "!apt-get install -y zstd\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "subprocess.Popen(['ollama', 'serve'])\n",
    "time.sleep(3)\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ì—°ì†ëœ ë©”ì‹œì§€ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "\n",
    "# ì—°ì†ëœ ê°™ì€ ìœ í˜•ì˜ ë©”ì‹œì§€ê°€ ìˆëŠ” ëŒ€í™”\n",
    "messages = [\n",
    "    SystemMessage(content='ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.'),\n",
    "    SystemMessage(content='í•­ìƒ ë†ë‹´ìœ¼ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”.'),  # ì—°ì†ëœ System\n",
    "    HumanMessage(\n",
    "        content=[{'type': 'text', 'text': 'ì–´ë–¤ í”¼ìê°€ ì œì¼ ë§›ìˆë‚˜ìš”?'}]\n",
    "    ),\n",
    "    HumanMessage(content='ì–´ë–¤ í–„ë²„ê±°ê°€ ê°€ì¥ ë§›ìˆë‚˜ìš”?'),  # ì—°ì†ëœ Human\n",
    "    AIMessage(content='ë‚˜ëŠ” í•­ìƒ ë„ˆë§Œ \"ê³ ë¥´ê³¤ì¡¸ë¼\"'),\n",
    "    AIMessage(content='ë„ˆê°€ \"ë²„ê±°\" ì‹¶ì–´'),  # ì—°ì†ëœ AI\n",
    "]\n",
    "\n",
    "print(f\"=== ë³‘í•© ì „ ({len(messages)}ê°œ ë©”ì‹œì§€) ===\")\n",
    "for i, msg in enumerate(messages):\n",
    "    content = str(msg.content)[:40]\n",
    "    print(f\"[{i+1}] {msg.type}: {content}...\" if len(str(msg.content)) > 40 else f\"[{i+1}] {msg.type}: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. merge_message_runs ì‚¬ìš©í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import merge_message_runs\n",
    "\n",
    "# ì—°ì†ëœ ë©”ì‹œì§€ ë³‘í•©\n",
    "merged = merge_message_runs(messages)\n",
    "\n",
    "print(f\"=== ë³‘í•© í›„ ({len(merged)}ê°œ ë©”ì‹œì§€) ===\")\n",
    "for i, msg in enumerate(merged):\n",
    "    print(f\"\\n[{i+1}] {msg.type}:\")\n",
    "    print(f\"    {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ë³‘í•© ê²°ê³¼ ìì„¸íˆ ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ë³‘í•© ì „í›„ ë¹„êµ ===\")\n",
    "print(\"\\n[ë³‘í•© ì „]\")\n",
    "print(f\"  System ë©”ì‹œì§€: {len([m for m in messages if m.type == 'system'])}ê°œ\")\n",
    "print(f\"  Human ë©”ì‹œì§€: {len([m for m in messages if m.type == 'human'])}ê°œ\")\n",
    "print(f\"  AI ë©”ì‹œì§€: {len([m for m in messages if m.type == 'ai'])}ê°œ\")\n",
    "\n",
    "print(\"\\n[ë³‘í•© í›„]\")\n",
    "print(f\"  System ë©”ì‹œì§€: {len([m for m in merged if m.type == 'system'])}ê°œ\")\n",
    "print(f\"  Human ë©”ì‹œì§€: {len([m for m in merged if m.type == 'human'])}ê°œ\")\n",
    "print(f\"  AI ë©”ì‹œì§€: {len([m for m in merged if m.type == 'ai'])}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ì²´ì¸ì—ì„œ merger ì‚¬ìš©í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# LLM ëª¨ë¸\n",
    "model = ChatOllama(model='llama3.2')\n",
    "\n",
    "# merger ìƒì„± (ì²´ì¸ì—ì„œ ì‚¬ìš©í•  ë•Œ)\n",
    "merger = merge_message_runs()\n",
    "\n",
    "# ì²´ì¸: ë³‘í•© â†’ ëª¨ë¸\n",
    "chain = merger | model\n",
    "\n",
    "print(\"âœ… mergerê°€ í¬í•¨ëœ ì²´ì¸ ìƒì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´ì¸ ì‹¤í–‰\n",
    "result = chain.invoke(messages)\n",
    "\n",
    "print(\"=== ë³‘í•© ì²´ì¸ ì‹¤í–‰ ê²°ê³¼ ===\")\n",
    "print(f\"ì…ë ¥: {len(messages)}ê°œ ë©”ì‹œì§€\")\n",
    "print(f\"ë³‘í•© í›„: {len(merged)}ê°œ ë©”ì‹œì§€\")\n",
    "print(f\"\\nAI ì‘ë‹µ: {result.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. ë‹¤ì–‘í•œ ìƒí™© í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—°ì†ë˜ì§€ ì•Šì€ ë©”ì‹œì§€ëŠ” ë³‘í•©ë˜ì§€ ì•ŠìŒ\n",
    "alternating_messages = [\n",
    "    HumanMessage(content='ì•ˆë…•í•˜ì„¸ìš”'),\n",
    "    AIMessage(content='ë°˜ê°€ì›Œìš”'),\n",
    "    HumanMessage(content='ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œìš”?'),\n",
    "    AIMessage(content='ì¢‹ì•„ìš”!'),\n",
    "]\n",
    "\n",
    "merged_alternating = merge_message_runs(alternating_messages)\n",
    "\n",
    "print(\"=== ë²ˆê°ˆì•„ ë‚˜ì˜¤ëŠ” ë©”ì‹œì§€ (ë³‘í•© ì•ˆë¨) ===\")\n",
    "print(f\"ë³‘í•© ì „: {len(alternating_messages)}ê°œ\")\n",
    "print(f\"ë³‘í•© í›„: {len(merged_alternating)}ê°œ\")\n",
    "print(\"\\nâ†’ ì—°ì†ë˜ì§€ ì•Šì•„ì„œ ë³‘í•© ì•ˆë¨!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ëŸ¬ ê°œì˜ ì—°ì† ë©”ì‹œì§€ í…ŒìŠ¤íŠ¸\n",
    "many_consecutive = [\n",
    "    HumanMessage(content='ì²« ë²ˆì§¸ ì§ˆë¬¸'),\n",
    "    HumanMessage(content='ë‘ ë²ˆì§¸ ì§ˆë¬¸'),\n",
    "    HumanMessage(content='ì„¸ ë²ˆì§¸ ì§ˆë¬¸'),\n",
    "    HumanMessage(content='ë„¤ ë²ˆì§¸ ì§ˆë¬¸'),\n",
    "]\n",
    "\n",
    "merged_many = merge_message_runs(many_consecutive)\n",
    "\n",
    "print(\"=== 4ê°œ ì—°ì† Human ë©”ì‹œì§€ ===\")\n",
    "print(f\"ë³‘í•© ì „: {len(many_consecutive)}ê°œ\")\n",
    "print(f\"ë³‘í•© í›„: {len(merged_many)}ê°œ\")\n",
    "print(f\"\\në³‘í•©ëœ ë‚´ìš©:\\n{merged_many[0].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì •ë¦¬: ë©”ì‹œì§€ ë³‘í•© (merge_message_runs)\n",
    "\n",
    "### í•µì‹¬ ë™ì‘\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                merge_message_runs ë™ì‘ ì›ë¦¬                        â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   [System] A                                                       â”‚\n",
    "â”‚   [System] B    â†’  [System] A + B                                 â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   [Human] ì§ˆë¬¸1                                                    â”‚\n",
    "â”‚   [Human] ì§ˆë¬¸2  â†’  [Human] ì§ˆë¬¸1 + ì§ˆë¬¸2                          â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   [AI] ë‹µë³€1                                                       â”‚\n",
    "â”‚   [AI] ë‹µë³€2     â†’  [AI] ë‹µë³€1 + ë‹µë³€2                             â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â”‚   â†’ ê°™ì€ ìœ í˜•ì´ ì—°ì†ë˜ë©´ ë‚´ìš©ì„ í•©ì¹¨                               â”‚\n",
    "â”‚                                                                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### í•µì‹¬ ì½”ë“œ\n",
    "\n",
    "```python\n",
    "from langchain_core.messages import merge_message_runs\n",
    "\n",
    "# 1. ì§ì ‘ ì‚¬ìš©\n",
    "merged = merge_message_runs(messages)\n",
    "\n",
    "# 2. ì²´ì¸ì—ì„œ ì‚¬ìš©\n",
    "merger = merge_message_runs()\n",
    "chain = merger | model\n",
    "result = chain.invoke(messages)\n",
    "```\n",
    "\n",
    "### ì–¸ì œ ì‚¬ìš©í• ê¹Œìš”?\n",
    "\n",
    "| ìƒí™© | ì‚¬ìš© ì—¬ë¶€ |\n",
    "|------|----------|\n",
    "| ì—°ì†ëœ ì‹œìŠ¤í…œ ì§€ì‹œ í†µí•© | âœ… ì‚¬ìš© |\n",
    "| ì—¬ëŸ¬ ì‚¬ìš©ì ì…ë ¥ í†µí•© | âœ… ì‚¬ìš© |\n",
    "| API ì œí•œ ìš°íšŒ | âœ… ì‚¬ìš© |\n",
    "| ë²ˆê°ˆì•„ ë‚˜ì˜¤ëŠ” ë©”ì‹œì§€ | âŒ ë¶ˆí•„ìš” |\n",
    "\n",
    "## ì½”ë“œ ë³€ê²½ì  (OpenAI â†’ Ollama)\n",
    "\n",
    "```python\n",
    "# ì›ë³¸\n",
    "model = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "# ë³€ê²½\n",
    "model = ChatOllama(model='llama3.2')\n",
    "```\n",
    "\n",
    "## ch04 ìš”ì•½: ë©”ëª¨ë¦¬ ê´€ë¦¬ ê¸°ë²•\n",
    "\n",
    "| ê¸°ë²• | ìš©ë„ | í•µì‹¬ í•¨ìˆ˜/í´ë˜ìŠ¤ |\n",
    "|------|------|------------------|\n",
    "| **Simple Memory** | ëŒ€í™” ê¸°ë¡ ìœ ì§€ | `placeholder` |\n",
    "| **StateGraph** | ìƒíƒœ ê¸°ë°˜ ì±—ë´‡ | `StateGraph`, `add_messages` |\n",
    "| **Persistent Memory** | ëŒ€í™” ì €ì¥/ë³µì› | `MemorySaver`, Thread ID |\n",
    "| **Trim Messages** | í† í° ì œí•œ ëŒ€ì‘ | `trim_messages` |\n",
    "| **Filter Messages** | ì¡°ê±´ë³„ í•„í„°ë§ | `filter_messages` |\n",
    "| **Merge Messages** | ì—°ì† ë©”ì‹œì§€ ë³‘í•© | `merge_message_runs` |"
   ]
  }
 ]
}