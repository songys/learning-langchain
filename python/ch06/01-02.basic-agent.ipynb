{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 에이전트: 도구를 사용하는 AI\n",
    "\n",
    "이 노트북에서는 **LangGraph**를 사용하여 **도구(Tool)를 사용하는 에이전트**를 만듭니다.\n",
    "\n",
    "## 에이전트(Agent)란?\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────┐\n",
    "│                    에이전트의 개념                                  │\n",
    "├────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                    │\n",
    "│   일반 챗봇:                                                       │\n",
    "│   사용자 질문 → LLM → 답변                                        │\n",
    "│   (LLM이 알고 있는 정보로만 답변)                                  │\n",
    "│                                                                    │\n",
    "│   에이전트:                                                        │\n",
    "│   사용자 질문 → LLM → 도구 호출 → 결과 확인 → 답변                │\n",
    "│   (외부 도구를 사용해서 실시간 정보 획득 가능!)                    │\n",
    "│                                                                    │\n",
    "│   에이전트 = LLM + 도구 사용 능력                                  │\n",
    "│                                                                    │\n",
    "└────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "## 이번에 만들 시스템 (ReAct 패턴)\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────┐\n",
    "│                    ReAct 에이전트 아키텍처                          │\n",
    "├────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                    │\n",
    "│                    ┌─────────┐                                     │\n",
    "│                    │  START  │                                     │\n",
    "│                    └────┬────┘                                     │\n",
    "│                         │                                          │\n",
    "│                         ▼                                          │\n",
    "│                ┌────────────────┐                                  │\n",
    "│                │     model      │ ◄─────────────┐                  │\n",
    "│                │  (LLM + Tools) │               │                  │\n",
    "│                └────────┬───────┘               │                  │\n",
    "│                         │                       │                  │\n",
    "│              tools_condition?                   │                  │\n",
    "│                    ╱    ╲                       │                  │\n",
    "│            도구 필요   도구 불필요              │                  │\n",
    "│                 ╱          ╲                    │                  │\n",
    "│                ▼            ▼                   │                  │\n",
    "│         ┌──────────┐   ┌─────────┐             │                  │\n",
    "│         │  tools   │   │   END   │             │                  │\n",
    "│         │ (도구실행)│   └─────────┘             │                  │\n",
    "│         └─────┬────┘                           │                  │\n",
    "│               │                                │                  │\n",
    "│               └────────────────────────────────┘                  │\n",
    "│                      (결과를 다시 model로)                         │\n",
    "│                                                                    │\n",
    "│   ReAct = Reason + Act (추론하고 행동하기)                         │\n",
    "│   LLM이 스스로 도구가 필요한지 판단하고, 필요하면 사용함           │\n",
    "│                                                                    │\n",
    "└────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-ollama langgraph duckduckgo-search langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "!apt-get install -y zstd\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "subprocess.Popen(['ollama', 'serve'])\n",
    "time.sleep(3)\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 도구(Tool) 정의\n",
    "\n",
    "에이전트가 사용할 도구들을 정의합니다.\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────┐\n",
    "│                    도구(Tool)의 구성요소                           │\n",
    "├────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                    │\n",
    "│   @tool 데코레이터로 함수를 도구로 변환                            │\n",
    "│                                                                    │\n",
    "│   필수 요소:                                                       │\n",
    "│   • 함수 이름: LLM이 도구를 식별하는 데 사용                       │\n",
    "│   • docstring: LLM이 도구의 용도를 이해하는 데 사용 (매우 중요!)   │\n",
    "│   • 파라미터: 도구에 전달할 입력값                                 │\n",
    "│   • 반환값: 도구 실행 결과                                         │\n",
    "│                                                                    │\n",
    "└────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# 도구 1: 계산기\n",
    "@tool\n",
    "def calculator(query: str) -> str:\n",
    "    '''계산기. 수식만 입력받습니다.'''\n",
    "    return ast.literal_eval(query)\n",
    "\n",
    "# 도구 2: 웹 검색 (DuckDuckGo)\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "# 도구 리스트\n",
    "tools = [search, calculator]\n",
    "\n",
    "print(\"✅ 도구 정의 완료\")\n",
    "print(f\"   - search: 웹에서 정보 검색\")\n",
    "print(f\"   - calculator: 수학 계산\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 테스트\n",
    "print(\"=== 도구 테스트 ===\")\n",
    "print(f\"계산기: 2 + 3 * 4 = {calculator.invoke('2 + 3 * 4')}\")\n",
    "print(f\"\\n검색: {search.invoke('Python programming')[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LLM에 도구 연결 (bind_tools)\n",
    "\n",
    "LLM이 도구를 사용할 수 있도록 연결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# LLM 모델에 도구 연결\n",
    "model = ChatOllama(model='llama3.2', temperature=0.1).bind_tools(tools)\n",
    "\n",
    "print(\"✅ LLM에 도구 연결 완료\")\n",
    "print(\"   bind_tools()로 LLM이 도구를 호출할 수 있게 됨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. State 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    에이전트의 상태\n",
    "    \n",
    "    messages: 대화 기록 (사용자 질문, LLM 응답, 도구 결과 등)\n",
    "    \"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "print(\"✅ State 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 노드 정의\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────┐\n",
    "│                    두 가지 핵심 노드                               │\n",
    "├────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                    │\n",
    "│   1️⃣ model_node (직접 구현)                                       │\n",
    "│      • LLM을 호출하여 응답 생성                                    │\n",
    "│      • 도구가 필요하면 tool_calls 포함된 응답 반환                 │\n",
    "│                                                                    │\n",
    "│   2️⃣ ToolNode (LangGraph 제공)                                    │\n",
    "│      • tool_calls를 받아서 실제로 도구 실행                        │\n",
    "│      • 결과를 ToolMessage로 반환                                   │\n",
    "│                                                                    │\n",
    "└────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "def model_node(state: State) -> State:\n",
    "    \"\"\"\n",
    "    LLM 호출 노드\n",
    "    \n",
    "    1. 현재 대화 기록을 LLM에 전달\n",
    "    2. LLM이 응답 생성 (도구 호출 포함 가능)\n",
    "    3. 응답을 State에 추가\n",
    "    \"\"\"\n",
    "    res = model.invoke(state['messages'])\n",
    "    return {'messages': res}\n",
    "\n",
    "# LangGraph가 제공하는 ToolNode 사용\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "print(\"✅ 노드 정의 완료\")\n",
    "print(\"   - model_node: LLM 호출\")\n",
    "print(\"   - tool_node: 도구 실행 (ToolNode 사용)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 그래프 구성\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────────┐\n",
    "│                    tools_condition 이해하기                        │\n",
    "├────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                    │\n",
    "│   tools_condition은 LangGraph가 제공하는 조건 함수                 │\n",
    "│                                                                    │\n",
    "│   LLM 응답에 tool_calls가 있으면:                                  │\n",
    "│   → \"tools\" 노드로 이동 (도구 실행)                                │\n",
    "│                                                                    │\n",
    "│   tool_calls가 없으면:                                             │\n",
    "│   → \"__end__\" 로 이동 (종료)                                       │\n",
    "│                                                                    │\n",
    "└────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# 그래프 빌더 생성\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# 노드 추가\n",
    "builder.add_node('model', model_node)\n",
    "builder.add_node('tools', tool_node)\n",
    "\n",
    "# 엣지 추가\n",
    "builder.add_edge(START, 'model')           # 시작 → 모델\n",
    "builder.add_conditional_edges('model', tools_condition)  # 조건부 분기\n",
    "builder.add_edge('tools', 'model')         # 도구 → 모델 (루프)\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = builder.compile()\n",
    "\n",
    "print(\"✅ 에이전트 그래프 컴파일 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 구조 시각화\n",
    "print(\"=== 에이전트 그래프 구조 ===\")\n",
    "print(graph.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 에이전트 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 테스트: 검색이 필요한 질문\n",
    "input_data = {\n",
    "    'messages': [\n",
    "        HumanMessage(\n",
    "            '미국의 제30대 대통령이 사망했을 때 몇 살이었나요?'\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"=== 에이전트 실행 (스트림) ===\")\n",
    "print(f\"질문: {input_data['messages'][0].content}\\n\")\n",
    "\n",
    "for chunk in graph.stream(input_data):\n",
    "    for node_name, node_output in chunk.items():\n",
    "        print(f\"--- {node_name} ---\")\n",
    "        if 'messages' in node_output:\n",
    "            for msg in node_output['messages'] if isinstance(node_output['messages'], list) else [node_output['messages']]:\n",
    "                print(f\"  유형: {type(msg).__name__}\")\n",
    "                if hasattr(msg, 'content') and msg.content:\n",
    "                    print(f\"  내용: {str(msg.content)[:200]}...\" if len(str(msg.content)) > 200 else f\"  내용: {msg.content}\")\n",
    "                if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "                    print(f\"  도구 호출: {msg.tool_calls}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 결과만 확인\n",
    "result = graph.invoke(input_data)\n",
    "\n",
    "print(\"=== 최종 응답 ===\")\n",
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 다양한 질문으로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = [\n",
    "    \"123 * 456 + 789는 얼마인가요?\",        # 계산기 필요\n",
    "    \"오늘 서울 날씨는 어떤가요?\",           # 검색 필요\n",
    "    \"안녕하세요, 반갑습니다!\",              # 도구 불필요\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"질문: {question}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    result = graph.invoke({'messages': [HumanMessage(question)]})\n",
    "    \n",
    "    # 어떤 도구가 사용되었는지 확인\n",
    "    tools_used = []\n",
    "    for msg in result['messages']:\n",
    "        if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "            tools_used.extend([tc['name'] for tc in msg.tool_calls])\n",
    "    \n",
    "    print(f\"\\n사용된 도구: {tools_used if tools_used else '없음'}\")\n",
    "    print(f\"\\n응답: {result['messages'][-1].content[:300]}...\" if len(result['messages'][-1].content) > 300 else f\"\\n응답: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 정리: 기본 에이전트 (ReAct 패턴)\n",
    "\n",
    "### 아키텍처\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                    ReAct 에이전트 동작 흐름                         │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│   1. 사용자 질문 입력                                               │\n",
    "│   2. LLM이 질문 분석                                                │\n",
    "│   3. 도구가 필요하면 tool_calls 생성                                │\n",
    "│   4. ToolNode가 도구 실행                                           │\n",
    "│   5. 결과를 다시 LLM에 전달                                         │\n",
    "│   6. LLM이 최종 답변 생성 (또는 추가 도구 호출)                     │\n",
    "│   7. 도구 호출이 없으면 종료                                        │\n",
    "│                                                                     │\n",
    "│   핵심: LLM이 스스로 도구 사용 여부를 결정!                         │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### 핵심 코드\n",
    "\n",
    "```python\n",
    "# 1. 도구 정의\n",
    "@tool\n",
    "def my_tool(query: str) -> str:\n",
    "    '''도구 설명 (LLM이 이해할 수 있게)'''\n",
    "    return result\n",
    "\n",
    "# 2. LLM에 도구 연결\n",
    "model = ChatOllama(model='llama3.2').bind_tools(tools)\n",
    "\n",
    "# 3. 조건부 엣지로 루프 구성\n",
    "builder.add_conditional_edges('model', tools_condition)\n",
    "builder.add_edge('tools', 'model')  # 결과를 다시 모델로\n",
    "```\n",
    "\n",
    "### 핵심 컴포넌트\n",
    "\n",
    "| 컴포넌트 | 역할 | 제공 |\n",
    "|----------|------|------|\n",
    "| **@tool** | 함수를 도구로 변환 | LangChain |\n",
    "| **bind_tools()** | LLM에 도구 연결 | LangChain |\n",
    "| **ToolNode** | 도구 실행 노드 | LangGraph |\n",
    "| **tools_condition** | 도구 호출 여부 판단 | LangGraph |\n",
    "\n",
    "## 코드 변경점 (OpenAI → Ollama)\n",
    "\n",
    "```python\n",
    "# 원본\n",
    "model = ChatOpenAI(model='gpt-4o-mini', temperature=0.1).bind_tools(tools)\n",
    "\n",
    "# 변경\n",
    "model = ChatOllama(model='llama3.2', temperature=0.1).bind_tools(tools)\n",
    "```\n",
    "\n",
    "## 다음 단계\n",
    "\n",
    "**첫 번째 도구를 강제로 호출**하는 방법을 배웁니다. (03-04번 노트북)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
